,Section Names,Section Length,Chapter Links,Section Descriptions
0,Welcome ,6,https://www.coursera.org/learn/big-data-introduction?specialization=big-data,"Data -- it's been around (even digitally) for a while.  What makes data ""big"" and where does this big data come from?"
1,Big Data: Why and Where,6,https://www.coursera.org/learn/big-data-introduction?specialization=big-data,"You may have heard of the ""Big Vs"".  We'll give examples and descriptions of the commonly discussed 5.  But, we want to propose a 6th V and we'll ask you to practice writing Big Data questions targeting this V -- value."
2,Characteristics of Big Data and Dimensions of Scalability,6,https://www.coursera.org/learn/big-data-introduction?specialization=big-data,"We love science and we love computing, don't get us wrong.  But the reality is we care about Big Data because it can bring value to our companies, our lives, and the world.  In this module we'll introduce a 5 step process for approaching data science problems."
3,Data Science: Getting Value out of Big Data,6,https://www.coursera.org/learn/big-data-introduction?specialization=big-data,"Big Data requires new programming frameworks and systems.  For this course, we don't  programming knowledge or experience -- but we do want to give you a grounding in some of the key concepts."
4,Foundations for Big Data Systems and Programming,6,https://www.coursera.org/learn/big-data-introduction?specialization=big-data,"Let's look at some details of Hadoop and MapReduce.  Then we'll go ""hands on"" and actually perform a simple MapReduce task in the Cloudera VM.  Pay attention - as we'll guide you in ""learning by doing"" in diagramming a MapReduce task as a Peer Review."
5,Systems: Getting Started with Hadoop,6,https://www.coursera.org/learn/big-data-introduction?specialization=big-data,"UC San Diego is an academic powerhouse and economic engine, recognized as one of the top 10 public universities by U.S. News and World Report. Innovation is central to who we are and what we do. Here, students learn that knowledge isn't just acquired in the classroom—life is their laboratory."
6,Introduction to Big Data Modeling and Management,6,https://www.coursera.org/learn/big-data-management?specialization=big-data,"Modeling big data depends on many factors including data structure, which operations may be performed on the data, and what constraints are placed on the models. In these lessons you will learn the details about big data modeling and you will gain the practical skills you will need for modeling your own big data projects."
7,Big Data Modeling,6,https://www.coursera.org/learn/big-data-management?specialization=big-data,"These lessons continue to shed light on big data modeling with specific approaches including vector space models, graph data models, and more. "
8,Big Data Modeling (Part 2),6,https://www.coursera.org/learn/big-data-management?specialization=big-data,"Data models deal with many different types of data formats. Streaming data is becoming ubiquitous, and working with streaming data requires a different approach from working with static data. In these lessons you will gain practical hands-on experience working with different forms of streaming data including weather data and twitter feeds. "
9,Working With Data Models,6,https://www.coursera.org/learn/big-data-management?specialization=big-data,Managing big data requires a different approach to database management systems because of the wide variation in data structure which does not lend itself to traditional DBMSs. There are many applications available to help with big data management. In these lessons we introduce you to some of these applications and provide insight into how and when they might be appropriate for your own big data management challenges. 
10,"Big Data Management: The ""M"" in DBMS",6,https://www.coursera.org/learn/big-data-management?specialization=big-data,"In these lessons we give you the opportunity to learn about big data modeling and management using a fictitious online game called ""Catch the Pink Flamingo"". "
11,Designing a Big Data Management System for an Online Game,6,https://www.coursera.org/learn/big-data-management?specialization=big-data,"UC San Diego is an academic powerhouse and economic engine, recognized as one of the top 10 public universities by U.S. News and World Report. Innovation is central to who we are and what we do. Here, students learn that knowledge isn't just acquired in the classroom—life is their laboratory."
12,Welcome to Big Data Integration and Processing,7,https://www.coursera.org/learn/big-data-integration-processing?specialization=big-data,This module covers the various aspects of data retrieval and relational querying. You will also be introduced to the Postgres database. 
13,Retrieving Big Data (Part 1),7,https://www.coursera.org/learn/big-data-integration-processing?specialization=big-data,"This module covers the various aspects of data retrieval for NoSQL data, as well as data aggregation and working with data frames. You will be introduced to MongoDB and Aerospike, and you will learn how to use Pandas to retrieve data from them."
14,Retrieving Big Data (Part 2),7,https://www.coursera.org/learn/big-data-integration-processing?specialization=big-data,"In this module you will be introduced to data integration tools including Splunk and Datameer, and you will gain some practical insight into how information integration processes are carried out. "
15,Big Data Integration,7,https://www.coursera.org/learn/big-data-integration-processing?specialization=big-data,This module introduces Learners to big data pipelines and workflows as well as processing and analysis of big data using Apache Spark. 
16,Processing Big Data,7,https://www.coursera.org/learn/big-data-integration-processing?specialization=big-data,"In this module, you will go deeper into big data processing by learning the inner workings of the Spark Core. You will be introduced to two key tools in the Spark toolkit: Spark MLlib and GraphX. "
17,Big Data Analytics using Spark,7,https://www.coursera.org/learn/big-data-integration-processing?specialization=big-data,In this module you will get some practical hands-on experience applying what you learned about Spark and MongoDB to analyze Twitter data. 
18,Learn By Doing: Putting MongoDB and Spark to Work,7,https://www.coursera.org/learn/big-data-integration-processing?specialization=big-data,"UC San Diego is an academic powerhouse and economic engine, recognized as one of the top 10 public universities by U.S. News and World Report. Innovation is central to who we are and what we do. Here, students learn that knowledge isn't just acquired in the classroom—life is their laboratory."
19,Welcome,7,https://www.coursera.org/learn/big-data-machine-learning?specialization=big-data,
20,Introduction to Machine Learning with Big Data,7,https://www.coursera.org/learn/big-data-machine-learning?specialization=big-data,
21,Data Exploration,7,https://www.coursera.org/learn/big-data-machine-learning?specialization=big-data,
22,Data Preparation,7,https://www.coursera.org/learn/big-data-machine-learning?specialization=big-data,
23,Classification,7,https://www.coursera.org/learn/big-data-machine-learning?specialization=big-data,
24,Evaluation of Machine Learning Models,7,https://www.coursera.org/learn/big-data-machine-learning?specialization=big-data,
25,"Regression, Cluster Analysis, and Association Analysis",7,https://www.coursera.org/learn/big-data-machine-learning?specialization=big-data,"UC San Diego is an academic powerhouse and economic engine, recognized as one of the top 10 public universities by U.S. News and World Report. Innovation is central to who we are and what we do. Here, students learn that knowledge isn't just acquired in the classroom—life is their laboratory."
26,Welcome to Graph Analytics,5,https://www.coursera.org/learn/big-data-graph-analytics,"Welcome! This week we will get a first exposure to graphs and their use in everyday life.  By the end of the module you will be able to create a graph applying core mathematical properties of graphs, and identify the kinds of analysis questions one might be able to ask of such a graph.  We hope the you will be inspired as to how graphical representations might enable you to answer new Big Data problems!"
27,Introduction to Graphs,5,https://www.coursera.org/learn/big-data-graph-analytics,
28,Graph Analytics,5,https://www.coursera.org/learn/big-data-graph-analytics,"Welcome to the 4th module in the Graph Analytics course. Last week, we got a glimpse of a number of graph properties and why they are important. This week we will use those properties for analyzing graphs using a free and powerful graph analytics tool called Neo4j. We will demonstrate how to use Cypher, the query language of Neo4j, to perform a wide range of analyses on a variety of graph networks. "
29,Graph Analytics Techniques,5,https://www.coursera.org/learn/big-data-graph-analytics,In the last two modules we have learned about graph analytics and graph data management. This week we will study how they come together. There are programming models and software frameworks created specifically for graph analytics.  In this module we'll give an introductory tour of these models and frameworks.  We will learn to implement what you learned in Week 2 and build on it using GraphX and Giraph.   
30,Computing Platforms for Graph Analytics,5,https://www.coursera.org/learn/big-data-graph-analytics,"UC San Diego is an academic powerhouse and economic engine, recognized as one of the top 10 public universities by U.S. News and World Report. Innovation is central to who we are and what we do. Here, students learn that knowledge isn't just acquired in the classroom—life is their laboratory."
31,Simulating Big Data for an Online Game,7,https://www.coursera.org/learn/big-data-project,"Next, we begin working with the simulated game data by exploring and preparing the data for ingestion into big data analytics applications."
32,"Acquiring, Exploring, and Preparing the Data",7,https://www.coursera.org/learn/big-data-project,This week we do some data classification using KNIME. 
33,Data Classification with KNIME,7,https://www.coursera.org/learn/big-data-project,This week we do some clustering with Spark. 
34,Clustering with Spark,7,https://www.coursera.org/learn/big-data-project,This week we apply what we learned from the 'Graph Analytics With Big Data' course to simulated chat data from Catch the Pink Flamingos using Neo4j. We analyze player chat behavior to find ways of improving the game. 
35,Graph Analytics of Simulated Chat Data With Neo4j,7,https://www.coursera.org/learn/big-data-project,
36,Reporting and Presenting Your Work,7,https://www.coursera.org/learn/big-data-project,
37,Final Submission,7,https://www.coursera.org/learn/big-data-project,"UC San Diego is an academic powerhouse and economic engine, recognized as one of the top 10 public universities by U.S. News and World Report. Innovation is central to who we are and what we do. Here, students learn that knowledge isn't just acquired in the classroom—life is their laboratory."
38,INTRODUCCIÓN,5,https://www.coursera.org/learn/impacto-datos-masivos?specialization=big-data-introduccion,"La digitalización, la informática e Internet han producido lo que se puede denominar una revolución en la acumulación y utilización de datos. Actualmente podemos almacenar y conservar más datos que nunca antes en la historia, y podemos estudiarlos y analizarlos para tomar decisiones y mejorar procesos. Esta nueva capacidad tiene un enorme impacto en todos los ámbitos de la vida social. <br><br> En este módulo exploraremos el crecimiento continuo de datos, analizaremos su impacto potencial en muchos campos de la actividad humana, y nos preguntaremos por los retos y desafíos que suponen en todos los órdenes de la vida social. <br><br><i>Visualiza los vídeos, contesta el cuestionario tantas veces como quieras, y accede a los foros para discutir los temas que te parezcan más interesantes.</i>"
39,Módulo 1: Los datos masivos en la vida cotidiana el siglo XXI,5,https://www.coursera.org/learn/impacto-datos-masivos?specialization=big-data-introduccion,"Un modelo de procesamiento de datos incluye las fases de adquisición y registro, extracción, limpieza y metadatado, integración, agregación y representación, análisis y modelización, visualización e interpretación, aplicación y toma de decisiones (puesta en valor). <br><br>En este módulo profundizaremos algo más en el impacto de los datos masivos en la sociedad actual y nos introduciremos en el procesamiento de datos masivos siguiendo una metodología completa, desde el problema de negocio hasta la puesta en valor de la solución analítica.Como siempre, <br><br><i>Como siempre, visualiza los vídeos, contesta el cuestionario tantas veces como quieras, y accede a los foros para discutir los temas que te parezcan más interesantes.</i>"
40,MÓDULO 2: MODELO DE PROCESAMIENTO Y UTILIZACIÓN DE DATOS,5,https://www.coursera.org/learn/impacto-datos-masivos?specialization=big-data-introduccion,"Los datos masivos se utilizan en muchas y diversas áreas de la actividad humana: en ciencia, en educación,  en las actividades productivas,  en el comercio, en la administración pública y empresarial, en la política, en el cuidado de la salud, etc. Todo ello presenta aspectos positivos, pero también  riesgos considerables.<br><br>En este módulo veremos 5 casos de aplicación del Big Data a sectores tan imbricados en la vida cotidiana como el ""retail"", seguros, banca, telecomunicaciones y transportes., para posteriormente conocer las opiniones de tres expertos sobre el impacto de estos grandes volúmenes de datos en los medios de comunicación, en las ciencias sociales, y en la investigación científica.<br><br><i>Al ser un tema tan aplicado, en este módulo hemos incluído 5 temas de discusión en el foro para que compartas tus conocimientos con el resto de compañeros. En justa compensación, hemos preparado un cuestionario más corto. Visualiza los vídeos, completa el cuestionario, y colabora en los temas de discusión que hemos planteado.</i>"
41,MÓDULO 3: ¿PARA QUÉ SE UTILIZAN ESTOS GRANDES CONJUNTOS DE DATOS?,5,https://www.coursera.org/learn/impacto-datos-masivos?specialization=big-data-introduccion,"La cantidad de datos que podemos adquirir y conservar en la actualidad supera con creces las posibilidades de gestión humana y de los ordenadores convencionales. Han surgido pues, nuevas maquinarias y sistemas de procesamiento de datos que evolucionan continuamente. Se requieren, también, nuevas infraestructuras y nuevos sistemas de compartición y distribución.<br><br>En este módulo estudiaremos las principales tecnologías e infraestructuras Big Data, el sistema Hadoop y otros similares, estudiando sus características y prestaciones más relevantes. Estas herramientas se tratarán con más profundidad y se trabajarán en casos prácticos en los cursos siguientes de la Especializanción en Big Data.<br><br><i>Como es habitual, visualiza los vídeos, contesta el cuestionario tantas veces como quieras, y accede a los foros para discutir los temas que te parezcan más interesantes.</i>"
42,MÓDULO 4: TECNOLOGÍAS E INFRAESTRUCTURAS,5,https://www.coursera.org/learn/impacto-datos-masivos?specialization=big-data-introduccion,"The Universitat Autònoma de Barcelona (UAB) is a public university located in the metropolitan area of Barcelona. International in its outlook, it is fully consolidated within its local surroundings, and offers quality education in close association with research activity, the transfer of scientific, technological, cultural and educational knowledge, the promotion of its human potential and the responsible management of available resources. The UAB currently offers 81 degrees, 130 official Master Programmes and 183 UAB-specific Masters Degrees. In addition, it offers 174 lifelong learning programmes and 65 PhD Programmes, 27 of which have been distinguished through Quality Awards. The UAB has a total of over 3,500 teaching and research staff, over 2,000 administrative staff and over 40,000 students."
43,INTRODUCCIÓN,6,https://www.coursera.org/learn/adquisicion-almacenamiento-de-datos?specialization=big-data-introduccion,"A lo largo de estos cursos vamos a trabajar con un conjunto de herramientas contenidas en la máquina virtual Cloudera. En este apartado te explicamos cómo descargar e instalar dicha máquina virtual en tu ordenador. <br><br>La MV-Cloudera requiere disponer de un equipo con las siguientes características: (1)  máquina de 64 bits, (2) mínimo 6G de memoria (recomendable 8G), y (3) 20G disponibles en disco.<br><br> <i><b>Ten en cuenta que bajar e instalar la máquina virtual te llevará tiempo dado el tamaño y complejidad de la misma</i></b>"
44,LA MÁQUINA VIRTUAL,6,https://www.coursera.org/learn/adquisicion-almacenamiento-de-datos?specialization=big-data-introduccion,"En este módulo se van a introducir los conceptos básicos sobre el uso de Apache Hadoop y su utilización para plantear análisis de grandes conjuntos de datos. Se van a presentar las herramientas principales y la arquitectura del sistema.<br><br><i>Visualiza los vídeos, contesta el cuestionario tantas veces como quieras, realiza el ejercicio práctico sobre Hadoop y HDFS, y accede a los foros para discutir los temas que te parezcan más interesantes.</i>"
45,MÓDULO 1 - Introducción al ecosistema Apache Hadoop,6,https://www.coursera.org/learn/adquisicion-almacenamiento-de-datos?specialization=big-data-introduccion,"En este módulo se introducen conceptos básicos sobre la naturaleza de los datos a tratar y de qué forma los sistemas NoSQL se diferencian de las bases de datos relacionales. Se presenta el teorema CAP y se muestra su importancia en el contexto de los sistemas distribuidos. Finalmente, se muestran una serie de sistemas junto con su uso en la industria actual. <br><br><i>Visualiza los vídeos, contesta el cuestionario tantas veces como quieras, y accede a los foros para discutir los temas que te parezcan más interesantes.</i>"
46,"MÓDULO 2 - Tecnologías SQL y NoSQL. Consistencia, fiabilidad y escalabilidad",6,https://www.coursera.org/learn/adquisicion-almacenamiento-de-datos?specialization=big-data-introduccion,"En este módulo se presentan los desafíos que hay que resolver a la hora de incorporar datos a los sistemas NoSQL  y una breve introducción a las herramientas asociadas al ecosistema Hadoop más importantes. <br><br><i>Visualiza los vídeos, contesta el cuestionario tantas veces como quieras, realiza el ejercicio práctico sobre Apache Scoop,  y accede a los foros para discutir los temas que te parezcan más interesantes.</i>"
47,MÓDULO 3 - Adquisición de datos,6,https://www.coursera.org/learn/adquisicion-almacenamiento-de-datos?specialization=big-data-introduccion,"En este módulo se presenta el análisis industrial de grandes volúmenes de datos y se introducen una serie de herramientas y sistemas de segunda generación dedicados a resolver necesidades específicas de la industria.<br><br><i>Visualiza los vídeos, contesta el cuestionario tantas veces como quieras, realiza los ejercicios prácticos sobre Apache Hive y Sparck, y accede a los foros para discutir los temas que te parezcan más interesantes.</i>"
48,MÓDULO 4 - Herramientas para el análisis de datos industrial,6,https://www.coursera.org/learn/adquisicion-almacenamiento-de-datos?specialization=big-data-introduccion,"The Universitat Autònoma de Barcelona (UAB) is a public university located in the metropolitan area of Barcelona. International in its outlook, it is fully consolidated within its local surroundings, and offers quality education in close association with research activity, the transfer of scientific, technological, cultural and educational knowledge, the promotion of its human potential and the responsible management of available resources. The UAB currently offers 81 degrees, 130 official Master Programmes and 183 UAB-specific Masters Degrees. In addition, it offers 174 lifelong learning programmes and 65 PhD Programmes, 27 of which have been distinguished through Quality Awards. The UAB has a total of over 3,500 teaching and research staff, over 2,000 administrative staff and over 40,000 students."
49,INTRODUCCIÓN,7,https://www.coursera.org/learn/big-data-procesamiento-analisis?specialization=big-data-introduccion,"<b>ATENCIÓN: Si ya te instalaste la máquina virtual en el curso anterior de la Especialización no es necesario que vuelvas a hacerlo. En caso contrario, sigue leyendo.</b><br><br>Los ejercicios y sesiones prácticas pretenden mostrar un caso práctico de procesamiento y análisis de datos en el contexto de Big Data. En este sentido, será necesario trabajar con una máquina virtual que ya trae configuradas e instaladas una serie de componentes habituales al manejar Big Data. En este apartado te explicamos cómo descargar e instalar la máquina virtual Cloudera en tu ordenador. La MV-Cloudera requiere disponer de un equipo con las siguientes características: (1) máquina de 64 bits, (2) mínimo 6G de memoria (recomendable 8G), y (3) 20G disponibles en disco.<br><br> <i><b>Ten en cuenta que bajar e instalar la máquina virtual te llevará tiempo dado el tamaño y complejidad de la misma</i></b>"
50,LA MÁQUINA VIRTUAL,7,https://www.coursera.org/learn/big-data-procesamiento-analisis?specialization=big-data-introduccion,"Para poder seguir la parte aplicada del curso, responder a los cuestionarios y trabajar con las herramientas que te explicamos, necesitarás acceder a una serie de ficheros de código, así como las bases de datos de trabajo, que hemos recopilado y comprimido. Verás que algunos vídeos llevan un código entre paréntesis que coincide con el nombre de alguno de estos ficheros. Esto significa que en el vídeo correspondiente se trabaja con dicho fichero. <br><br>A continuación te explicamos como incorporarlos en la máquina virtual."
51,MATERIAL DE PRÁCTICAS Y FICHEROS DE TRABAJO,7,https://www.coursera.org/learn/big-data-procesamiento-analisis?specialization=big-data-introduccion,"Durante la primera semana del curso se introducen el curso y las herramientas que se emplearán. Además también se presentan las tareas relacionadas con el Análisis Exploratorio de Datos. Cada pocos temas tratados en los vídeos encontrarás un pequeño custionario de 5 preguntas. <br><br><i>Visualiza los vídeos, contesta los cuestionarios tantas veces como quieras, y accede a los foros para discutir los temas que te parezcan más interesantes.</i>"
52,MÓDULO 1 - Análisis Exploratorio de Datos,7,https://www.coursera.org/learn/big-data-procesamiento-analisis?specialization=big-data-introduccion,"En el módulo 2 del curso se introducen conceptos de modelización generales (calibración y validación) y en particular los modelos de regresión lineal y regresión logística. Desde la perspectiva de Big Data, se incluyen aspectos relacionados con la regularización de los modelos para su simplificación. <br><br><i>Como en el módulo anterior, visualiza los vídeos, contesta los cuestionarios tantas veces como quieras, y accede a los foros para discutir los temas que te parezcan más interesantes.</i>"
53,MÓDULO 2 - MODELOS DE REGRESIÓN,7,https://www.coursera.org/learn/big-data-procesamiento-analisis?specialization=big-data-introduccion,"En el módulo 3 del curso se introduce la família de modelos basada en árboles (clasificación, regresión, bosques) y aspectos generales sobre la incertidumbre y el sobreajuste. Después de cada tema, o de unos pocos temas, encontrarás un cuestionario para comprobar tu nivel de comprensión de los mismos.<br><br><i>Visualiza los vídeos, contesta los cuestionarios tantas veces como quieras, y accede a los foros para discutir los temas que te parezcan más interesantes.</i>"
54,MÓDULO 3 - ÁRBOLES DE REGRESIÓN Y CLASIFICACIÓN,7,https://www.coursera.org/learn/big-data-procesamiento-analisis?specialization=big-data-introduccion,"En el módulo 4 del curso se introduce la família de modelos basada en redes neuronales así como se introducen las técnicas básicas no supervisadas, tanto de clasificación automática como de reducción de la dimensionalidad. En este módulo, además de los cuestionarios convencionales, tendrás que realizar un trabajo práctico en el que trabajarás las técnicas aprendidas hasta el momento.<br><br><i>Visualiza los vídeos, contesta los cuestionarios tantas veces como quieras, realiza el ejercicios práctico, y accede a los foros para discutir los temas que te parezcan más interesantes.</i>"
55,MÓDULO 4 - REDES NEURONALES Y TÉCNICAS NO SUPERVISADAS,7,https://www.coursera.org/learn/big-data-procesamiento-analisis?specialization=big-data-introduccion,"The Universitat Autònoma de Barcelona (UAB) is a public university located in the metropolitan area of Barcelona. International in its outlook, it is fully consolidated within its local surroundings, and offers quality education in close association with research activity, the transfer of scientific, technological, cultural and educational knowledge, the promotion of its human potential and the responsible management of available resources. The UAB currently offers 81 degrees, 130 official Master Programmes and 183 UAB-specific Masters Degrees. In addition, it offers 174 lifelong learning programmes and 65 PhD Programmes, 27 of which have been distinguished through Quality Awards. The UAB has a total of over 3,500 teaching and research staff, over 2,000 administrative staff and over 40,000 students."
56,INTRODUCCIÓN,5,https://www.coursera.org/learn/big-data-visualizacion-datos?specialization=big-data-introduccion,"En este módulo fijamos las bases para entender por qué es importante la visualización de datos en la actualidad. Hablaremos de la Sociedad de la Información y de cómo el diseño forma parte emergente de esta sociedad. Analizaremos y describiremos los fundamentos del diseño gráfico. También  repasaremos históricamente la evolución de las visualizaciones de datos más relevantes. Finalmente, propondremos una clasificación de infografias y visualizaciones de datos.<i>Visualiza los vídeos, contesta el cuestionario tantas veces como quieras, y accede a los foros para discutir los temas que te parezcan más interesantes.</i> "
57,MÓDULO 1: Contexto para la Visualización de Datos hoy,5,https://www.coursera.org/learn/big-data-visualizacion-datos?specialization=big-data-introduccion,"En este módulo exploraremos herramientas de análisis  y visualización de datos de tipología diversa: explorativa como R o D3, o otras  de marcado carácter explicativo/ narrativo.<i>Visualiza los vídeos, contesta el cuestionario tantas veces como quieras, y accede a los foros para discutir los temas que te parezcan más interesantes.</i>"
58,MÓDULO 2: Herramientas de análisis y visualización de datos,5,https://www.coursera.org/learn/big-data-visualizacion-datos?specialization=big-data-introduccion,"En este módulo se revisará el proceso de creación de una visualización de datos. El proceso que se sigue es (1) formular el problema de negocio, (2) instalar el programa, (3) cargar y preparar los datos y (4) crear diferentes visualizaciones (gráficos, cuadro de mandos e historias de datos) que permiten alcanzar niveles de conocimiento. A lo largo del módulo se trabajará con un conjunto de datos reales y la herramienta Tableau Public que involucra múltiples principios de visualización y está orientada al usuario final.<i>Visualiza los vídeos, accede a los foros para discutir los temas que te parezcan más interesantes y realiza la actividad que será evaluada por tus colegas.</i>"
59,MÓDULO 3: El Proceso de Creación de una Visualización de Datos,5,https://www.coursera.org/learn/big-data-visualizacion-datos?specialization=big-data-introduccion,"En este bloque se presentarán diferentes conceptos y técnicas del ámbito de la visualización para grandes volúmenes de datos, así como ejemplos específicos para la visualización de mapas y estructuras. También se describirán los aspectos clave del uso de visualizaciones como interfaz a los datos y los posibles problemas derivados del uso de visualizaciones, presentando buenas y malas prácticas así como los principales elementos a tener en cuenta.<i>Visualiza los vídeos, contesta el cuestionario tantas veces como quieras, y accede a los foros para discutir los temas que te parezcan más interesantes.</i>"
60,MÓDULO 4: Otros aspectos de la visualización de datos,5,https://www.coursera.org/learn/big-data-visualizacion-datos?specialization=big-data-introduccion,"The Universitat Autònoma de Barcelona (UAB) is a public university located in the metropolitan area of Barcelona. International in its outlook, it is fully consolidated within its local surroundings, and offers quality education in close association with research activity, the transfer of scientific, technological, cultural and educational knowledge, the promotion of its human potential and the responsible management of available resources. The UAB currently offers 81 degrees, 130 official Master Programmes and 183 UAB-specific Masters Degrees. In addition, it offers 174 lifelong learning programmes and 65 PhD Programmes, 27 of which have been distinguished through Quality Awards. The UAB has a total of over 3,500 teaching and research staff, over 2,000 administrative staff and over 40,000 students."
61,INTRODUCCIÓN,7,https://www.coursera.org/learn/big-data-proyecto,"<b>ATENCIÓN: Si ya te instalaste la máquina virtual en el curso anterior de la Especialización no es necesario que vuelvas a hacerlo.</b> En caso contrario, en este apartado te explicamos cómo descargar e instalar dicha máquina virtual en tu ordenador. <br><br>La MV-Cloudera requiere disponer de un equipo con las siguientes características: (1)  máquina de 64 bits, (2) mínimo 6G de memoria (recomendable 8G), y (3) 20G disponibles en disco.<br><br> <i><b>Ten en cuenta que bajar e instalar la máquina virtual te llevará tiempo dado el tamaño y complejidad de la misma</i></b>"
62,LA MÁQUINA VIRTUAL,7,https://www.coursera.org/learn/big-data-proyecto,En esta semana vamos a conocer el proyecto y a hacer una primera exploración de algunos de los datos con los que iremos trabajando. Nos familiarizamos con el contenido de estos ficheros y  haremos el trabajo preliminar para poderlo luego aplicar a grandes volumenes de datos. 
63,MÓDULO 1 - Exploración de datos,7,https://www.coursera.org/learn/big-data-proyecto,"En esta semana aprenderemos a cargar los datos en Hive, construir su modelo de datos y entender la tarea de clasificar una galaxia según su forma."
64,MÓDULO 2 - MODELO DE DATOS,7,https://www.coursera.org/learn/big-data-proyecto,"Esta semana vamos a normalizar un modelo de datos, estudiaremos con profundidad los votos que nos han proporcionado los usuarios y generaremos la información necesaria para construir un clasificador automàtico."
65,MÓDULO 3 - CLASIFICACIÓN,7,https://www.coursera.org/learn/big-data-proyecto,Esta semana introduciremos el dataset de imágenes galácticas y prepararemos dos algoritmos de Inteligencia Artificial para la clasificación automática de galaxias a partir de una imagen. 
66,MÓDULO 4 - MACHINE LEARNING,7,https://www.coursera.org/learn/big-data-proyecto,Es el momento de preparar el informe final con el trabajo realizado hasta ahora. Necesitaréis tener a mano los trabajos realizados las semanas anteriores.
67,MÓDULO 5 - TRABAJO FINAL,7,https://www.coursera.org/learn/big-data-proyecto,"The Universitat Autònoma de Barcelona (UAB) is a public university located in the metropolitan area of Barcelona. International in its outlook, it is fully consolidated within its local surroundings, and offers quality education in close association with research activity, the transfer of scientific, technological, cultural and educational knowledge, the promotion of its human potential and the responsible management of available resources. The UAB currently offers 81 degrees, 130 official Master Programmes and 183 UAB-specific Masters Degrees. In addition, it offers 174 lifelong learning programmes and 65 PhD Programmes, 27 of which have been distinguished through Quality Awards. The UAB has a total of over 3,500 teaching and research staff, over 2,000 administrative staff and over 40,000 students."
68,Data and Databases,5,https://www.coursera.org/learn/foundations-big-data-analysis-sql,
69,Relational Databases and SQL,5,https://www.coursera.org/learn/foundations-big-data-analysis-sql,
70,Big Data,5,https://www.coursera.org/learn/foundations-big-data-analysis-sql,
71,SQL Tools for Big Data Analysis,5,https://www.coursera.org/learn/foundations-big-data-analysis-sql,
72,Introduction to the Hands-On Environment,5,https://www.coursera.org/learn/foundations-big-data-analysis-sql,"At Cloudera, we believe that data can make what is impossible today, possible tomorrow. We empower people to transform complex data into clear and actionable insights. Cloudera delivers an enterprise data cloud for any data, anywhere, from the Edge to AI. Powered by the relentless innovation of the open source community, Cloudera advances digital transformation for the world’s largest enterprises. "
73,Orientation to SQL on Big Data,6,https://www.coursera.org/learn/cloudera-big-data-analysis-sql-queries,
74,SQL SELECT Essentials,6,https://www.coursera.org/learn/cloudera-big-data-analysis-sql-queries,
75,Filtering Data,6,https://www.coursera.org/learn/cloudera-big-data-analysis-sql-queries,
76,Grouping and Aggregating Data,6,https://www.coursera.org/learn/cloudera-big-data-analysis-sql-queries,
77,Sorting and Limiting Data,6,https://www.coursera.org/learn/cloudera-big-data-analysis-sql-queries,
78,Combining Data,6,https://www.coursera.org/learn/cloudera-big-data-analysis-sql-queries,"At Cloudera, we believe that data can make what is impossible today, possible tomorrow. We empower people to transform complex data into clear and actionable insights. Cloudera delivers an enterprise data cloud for any data, anywhere, from the Edge to AI. Powered by the relentless innovation of the open source community, Cloudera advances digital transformation for the world’s largest enterprises. "
79,Orientation to Data in Clusters and Cloud Storage,5,https://www.coursera.org/learn/cloud-storage-big-data-analysis-sql,
80,"Defining Databases, Tables, and Columns",5,https://www.coursera.org/learn/cloud-storage-big-data-analysis-sql,
81,Data Types and File Types,5,https://www.coursera.org/learn/cloud-storage-big-data-analysis-sql,
82,Managing Datasets in Clusters and Cloud Storage,5,https://www.coursera.org/learn/cloud-storage-big-data-analysis-sql,Honors (Optional)
83,Optimizing Hive and Impala (Honors),5,https://www.coursera.org/learn/cloud-storage-big-data-analysis-sql,"At Cloudera, we believe that data can make what is impossible today, possible tomorrow. We empower people to transform complex data into clear and actionable insights. Cloudera delivers an enterprise data cloud for any data, anywhere, from the Edge to AI. Powered by the relentless innovation of the open source community, Cloudera advances digital transformation for the world’s largest enterprises. "
84,Introduction to the Data and Machine Learning on Google Cloud Platform Specialization .,6,https://www.coursera.org/learn/gcp-big-data-ml-fundamentals?specialization=gcp-data-machine-learning,In this module you will have an existing Apache SparkML recommendation model that is running on-premise. You will learn about recommendation models and how you can run them in the cloud with Cloud Dataproc and Cloud SQL.
85,Recommending Products using Cloud SQL and Spark,6,https://www.coursera.org/learn/gcp-big-data-ml-fundamentals?specialization=gcp-data-machine-learning,"In this module, you will learn the foundations of BigQuery and big data analysis at scale. You will then learn how to build your own custom machine learning model to predict visitor purchases using just SQL with BigQuery ML. "
86,Predict Visitor Purchases with BigQuery ML,6,https://www.coursera.org/learn/gcp-big-data-ml-fundamentals?specialization=gcp-data-machine-learning,"In this module you will engineer and build an auto-scaling streaming data pipeline to ingest, process, and visualize data on a dashboard. Before you build your pipeline you'll learn the foundations of message-oriented architecture and pitfalls to avoid when designing and implementing modern data pipelines."
87,Create Streaming Data Pipelines with Cloud Pub/sub and Cloud Dataflow,6,https://www.coursera.org/learn/gcp-big-data-ml-fundamentals?specialization=gcp-data-machine-learning,Don't want to create a custom ML model from scratch? Learn how to leverage and extend pre-built ML models like the Vision API and Cloud AutoML for image classification.
88,Classify Images with Pre-Built Models using Vision API and Cloud AutoML,6,https://www.coursera.org/learn/gcp-big-data-ml-fundamentals?specialization=gcp-data-machine-learning,"In this final module, we will review the key challenges, solutions, and topics covered as part of this fundamentals course. We will also review additional resources and the steps you can take to get certified as a Google Cloud Data Engineer. "
89,Summary,6,https://www.coursera.org/learn/gcp-big-data-ml-fundamentals?specialization=gcp-data-machine-learning,"We help millions of organizations empower their employees, serve their customers, and build what’s next for their businesses with innovative technology created in—and for—the cloud. Our products are engineered for security, reliability, and scalability, running the full stack from infrastructure to applications to devices and hardware. Our teams are dedicated to helping customers apply our technologies to create success."
90,Introduction,5,https://www.coursera.org/learn/data-lakes-data-warehouses-gcp?specialization=gcp-data-machine-learning,This module describes the role of a data engineer and motivates the claim why data engineering should be done in the Cloud
91,Introduction to Data Engineering,5,https://www.coursera.org/learn/data-lakes-data-warehouses-gcp?specialization=gcp-data-machine-learning,"In this module, we describe what  data lake is and how to use Google Cloud Storage as you data lake on GCP"
92,Building a Data Lake,5,https://www.coursera.org/learn/data-lakes-data-warehouses-gcp?specialization=gcp-data-machine-learning,"In this module, we talk about BigQuery as a data warehousing option on GCP"
93,Building a data warehouse,5,https://www.coursera.org/learn/data-lakes-data-warehouses-gcp?specialization=gcp-data-machine-learning,This module reviews all the topics covered in the course
94,Summary,5,https://www.coursera.org/learn/data-lakes-data-warehouses-gcp?specialization=gcp-data-machine-learning,"We help millions of organizations empower their employees, serve their customers, and build what’s next for their businesses with innovative technology created in—and for—the cloud. Our products are engineered for security, reliability, and scalability, running the full stack from infrastructure to applications to devices and hardware. Our teams are dedicated to helping customers apply our technologies to create success."
95,Introduction,6,https://www.coursera.org/learn/batch-data-pipelines-gcp?specialization=gcp-data-machine-learning,"This module reviews different methods of data loading: EL, ELT and ETL and when to use what"
96,Introduction to Batch Data Pipelines,6,https://www.coursera.org/learn/batch-data-pipelines-gcp?specialization=gcp-data-machine-learning,"This module shows how to run Hadoop on Cloud Dataproc, how to leverage GCS, and how to optimize your Dataproc jobs."
97,Executing Spark on Cloud Dataproc,6,https://www.coursera.org/learn/batch-data-pipelines-gcp?specialization=gcp-data-machine-learning,This module shows how to manage data pipelines with Cloud Data Fusion and Cloud Composer.  
98,Manage Data Pipelines with Cloud Data Fusion and Cloud Composer	,6,https://www.coursera.org/learn/batch-data-pipelines-gcp?specialization=gcp-data-machine-learning,This module covers using Cloud Dataflow to build your data processing pipelines
99,Serverless Data Processing with Cloud Dataflow	,6,https://www.coursera.org/learn/batch-data-pipelines-gcp?specialization=gcp-data-machine-learning,This module reviews the topics covered in this course
100,Summary,6,https://www.coursera.org/learn/batch-data-pipelines-gcp?specialization=gcp-data-machine-learning,"We help millions of organizations empower their employees, serve their customers, and build what’s next for their businesses with innovative technology created in—and for—the cloud. Our products are engineered for security, reliability, and scalability, running the full stack from infrastructure to applications to devices and hardware. Our teams are dedicated to helping customers apply our technologies to create success."
101,Introduction,7,https://www.coursera.org/learn/streaming-analytics-systems-gcp?specialization=gcp-data-machine-learning,This modules talks about challenges with processing streaming data
102,Introduction to Processing Streaming Data,7,https://www.coursera.org/learn/streaming-analytics-systems-gcp?specialization=gcp-data-machine-learning,This module talks about using Cloud Pub/Sub to ingest incoming streaming data
103,Serverless Messaging with Cloud Pub/Sub,7,https://www.coursera.org/learn/streaming-analytics-systems-gcp?specialization=gcp-data-machine-learning,This module revisits Cloud Dataflow and focuses on its streaming data processing capabilities 
104,Cloud Dataflow Streaming Features,7,https://www.coursera.org/learn/streaming-analytics-systems-gcp?specialization=gcp-data-machine-learning,This modules covers BigQuery and Bigtable for streaming data
105,High-Throughput BigQuery and Bigtable Streaming Features,7,https://www.coursera.org/learn/streaming-analytics-systems-gcp?specialization=gcp-data-machine-learning,This module dives into more advanced features of BigQuery
106,Advanced BigQuery Functionality and Performance,7,https://www.coursera.org/learn/streaming-analytics-systems-gcp?specialization=gcp-data-machine-learning,This module recaps the topics covered in course
107,Summary,7,https://www.coursera.org/learn/streaming-analytics-systems-gcp?specialization=gcp-data-machine-learning,"We help millions of organizations empower their employees, serve their customers, and build what’s next for their businesses with innovative technology created in—and for—the cloud. Our products are engineered for security, reliability, and scalability, running the full stack from infrastructure to applications to devices and hardware. Our teams are dedicated to helping customers apply our technologies to create success."
108,Introduction to Machine Learning,6,https://www.coursera.org/learn/machine-learning-with-python?specialization=ai-engineer,"In this week, you will get a brief intro to regression. You learn about Linear, Non-linear, Simple and Multiple regression, and their applications. You apply all these methods on two different datasets, in the lab part. Also, you learn how to evaluate your regression model, and calculate its accuracy."
109,Regression,6,https://www.coursera.org/learn/machine-learning-with-python?specialization=ai-engineer,"In this week, you will learn about classification technique. You practice with different classification algorithms, such as KNN, Decision Trees, Logistic Regression and SVM. Also, you learn about pros and cons of each method, and different classification accuracy metrics."
110,Classification,6,https://www.coursera.org/learn/machine-learning-with-python?specialization=ai-engineer,"In this section, you will learn about different clustering approaches. You learn how to use clustering for customer segmentation, grouping same vehicles, and also clustering of weather stations. You understand 3 main types of clustering, including Partitioned-based Clustering, Hierarchical Clustering, and Density-based Clustering."
111,Clustering,6,https://www.coursera.org/learn/machine-learning-with-python?specialization=ai-engineer,"In this module, you will learn about recommender systems. First, you will get introduced with main idea behind recommendation engines, then you understand two main types of recommendation engines, namely, content-based and collaborative filtering."
112,Recommender Systems,6,https://www.coursera.org/learn/machine-learning-with-python?specialization=ai-engineer,"In this module, you will do a project based of what you have learned so far. You will submit a report of your project for peer evaluation."
113,Final Project,6,https://www.coursera.org/learn/machine-learning-with-python?specialization=ai-engineer,"IBM offers a wide range of technology and consulting services; a broad portfolio of middleware for collaboration, predictive analytics, software development and systems management; and the world's most advanced servers and supercomputers. Utilizing its business consulting, technology and R&D expertise, IBM helps clients become ""smarter"" as the planet becomes more digitally interconnected. IBM invests more than $6 billion a year in R&D, just completing its 21st year of patent leadership. IBM Research has received recognition beyond any commercial technology research organization and is home to 5 Nobel Laureates, 9 US National Medals of Technology, 5 US National Medals of Science, 6 Turing Awards, and 10 Inductees in US Inventors Hall of Fame."
114,Week 1: Introduction,4,https://www.coursera.org/learn/machine-learning-big-data-apache-spark?specialization=ai-engineer,Applying basic statistical calculations using the Apache Spark RDD API in order to experience how parallelization in Apache Spark works
115,Week 2: Scaling Math for Statistics on Apache Spark,4,https://www.coursera.org/learn/machine-learning-big-data-apache-spark?specialization=ai-engineer,Understand the concept of machine learning pipelines in order to understand how Apache SparkML works programmatically
116,Week 3: Introduction to Apache SparkML,4,https://www.coursera.org/learn/machine-learning-big-data-apache-spark?specialization=ai-engineer,Apply Supervised and Unsupervised Machine Learning tasks using SparkML
117,Week 4: Supervised and Unsupervised learning with SparkML,4,https://www.coursera.org/learn/machine-learning-big-data-apache-spark?specialization=ai-engineer,"IBM offers a wide range of technology and consulting services; a broad portfolio of middleware for collaboration, predictive analytics, software development and systems management; and the world's most advanced servers and supercomputers. Utilizing its business consulting, technology and R&D expertise, IBM helps clients become ""smarter"" as the planet becomes more digitally interconnected. IBM invests more than $6 billion a year in R&D, just completing its 21st year of patent leadership. IBM Research has received recognition beyond any commercial technology research organization and is home to 5 Nobel Laureates, 9 US National Medals of Technology, 5 US National Medals of Science, 6 Turing Awards, and 10 Inductees in US Inventors Hall of Fame."
118,Introduction to Neural Networks and Deep Learning,5,https://www.coursera.org/learn/introduction-to-deep-learning-with-keras?specialization=ai-engineer,"In this module, you will learn about the gradient descent algorithm and how variables are optimized with respect to a defined function. You will also learn about backpropagation and how neural networks learn and update their weights and biases. Futhermore, you will learn about the vanishing gradient problem. Finally, you will learn about activation functions."
119,Artificial Neural Networks,5,https://www.coursera.org/learn/introduction-to-deep-learning-with-keras?specialization=ai-engineer,"In this module, you will learn about the diifferent deep learning libraries namely, Keras, PyTorch, and TensorFlow. You will also learn how to build regression and classification models using the Keras library."
120,Keras and Deep Learning Libraries,5,https://www.coursera.org/learn/introduction-to-deep-learning-with-keras?specialization=ai-engineer,"In this module, you will learn about the difference between the shallow and deep neural networks. You will also learn about convolutional networks and how to build them using the Keras library. Finally, you will also learn about recurrent neural networks and autoencoders."
121,Deep Learning Models,5,https://www.coursera.org/learn/introduction-to-deep-learning-with-keras?specialization=ai-engineer,"In this module, you will conclude the course by working on a final assignment where you will use the Keras library to build a regression model and experiment with the depth and the width of the model."
122,Course Project,5,https://www.coursera.org/learn/introduction-to-deep-learning-with-keras?specialization=ai-engineer,"IBM offers a wide range of technology and consulting services; a broad portfolio of middleware for collaboration, predictive analytics, software development and systems management; and the world's most advanced servers and supercomputers. Utilizing its business consulting, technology and R&D expertise, IBM helps clients become ""smarter"" as the planet becomes more digitally interconnected. IBM invests more than $6 billion a year in R&D, just completing its 21st year of patent leadership. IBM Research has received recognition beyond any commercial technology research organization and is home to 5 Nobel Laureates, 9 US National Medals of Technology, 5 US National Medals of Science, 6 Turing Awards, and 10 Inductees in US Inventors Hall of Fame."
123,Tensor and Datasets ,10,https://www.coursera.org/learn/deep-neural-networks-with-pytorch?specialization=ai-engineer,
124,Linear Regression,10,https://www.coursera.org/learn/deep-neural-networks-with-pytorch?specialization=ai-engineer,
125,Linear Regression PyTorch Way,10,https://www.coursera.org/learn/deep-neural-networks-with-pytorch?specialization=ai-engineer,
126,Multiple Input Output Linear Regression ,10,https://www.coursera.org/learn/deep-neural-networks-with-pytorch?specialization=ai-engineer,
127,Logistic Regression for Classification,10,https://www.coursera.org/learn/deep-neural-networks-with-pytorch?specialization=ai-engineer,
128,Softmax Rergresstion ,10,https://www.coursera.org/learn/deep-neural-networks-with-pytorch?specialization=ai-engineer,
129,Shallow Neural Networks,10,https://www.coursera.org/learn/deep-neural-networks-with-pytorch?specialization=ai-engineer,
130,Deep Networks ,10,https://www.coursera.org/learn/deep-neural-networks-with-pytorch?specialization=ai-engineer,
131,Convolutional Neural Network,10,https://www.coursera.org/learn/deep-neural-networks-with-pytorch?specialization=ai-engineer,
132,Peer Review ,10,https://www.coursera.org/learn/deep-neural-networks-with-pytorch?specialization=ai-engineer,"IBM offers a wide range of technology and consulting services; a broad portfolio of middleware for collaboration, predictive analytics, software development and systems management; and the world's most advanced servers and supercomputers. Utilizing its business consulting, technology and R&D expertise, IBM helps clients become ""smarter"" as the planet becomes more digitally interconnected. IBM invests more than $6 billion a year in R&D, just completing its 21st year of patent leadership. IBM Research has received recognition beyond any commercial technology research organization and is home to 5 Nobel Laureates, 9 US National Medals of Technology, 5 US National Medals of Science, 6 Turing Awards, and 10 Inductees in US Inventors Hall of Fame."
133,Python Basics ,5,https://www.coursera.org/learn/python-for-applied-data-science-ai,
134,Python Data Structures ,5,https://www.coursera.org/learn/python-for-applied-data-science-ai,
135,Python Programming Fundamentals ,5,https://www.coursera.org/learn/python-for-applied-data-science-ai,
136,Working with Data in Python ,5,https://www.coursera.org/learn/python-for-applied-data-science-ai,
137,Analyzing US Economic Data and Building a Dashboard ,5,https://www.coursera.org/learn/python-for-applied-data-science-ai,"IBM offers a wide range of technology and consulting services; a broad portfolio of middleware for collaboration, predictive analytics, software development and systems management; and the world's most advanced servers and supercomputers. Utilizing its business consulting, technology and R&D expertise, IBM helps clients become ""smarter"" as the planet becomes more digitally interconnected. IBM invests more than $6 billion a year in R&D, just completing its 21st year of patent leadership. IBM Research has received recognition beyond any commercial technology research organization and is home to 5 Nobel Laureates, 9 US National Medals of Technology, 5 US National Medals of Science, 6 Turing Awards, and 10 Inductees in US Inventors Hall of Fame."
138,Importing Datasets,7,https://www.coursera.org/learn/data-analysis-with-python,
139,Data Wrangling,7,https://www.coursera.org/learn/data-analysis-with-python,
140, Exploratory Data Analysis,7,https://www.coursera.org/learn/data-analysis-with-python,
141,Model Development,7,https://www.coursera.org/learn/data-analysis-with-python,
142, Model Evaluation,7,https://www.coursera.org/learn/data-analysis-with-python,
143,Final Assignment,7,https://www.coursera.org/learn/data-analysis-with-python,
144,IBM Digital Badge,7,https://www.coursera.org/learn/data-analysis-with-python,"IBM offers a wide range of technology and consulting services; a broad portfolio of middleware for collaboration, predictive analytics, software development and systems management; and the world's most advanced servers and supercomputers. Utilizing its business consulting, technology and R&D expertise, IBM helps clients become ""smarter"" as the planet becomes more digitally interconnected. IBM invests more than $6 billion a year in R&D, just completing its 21st year of patent leadership. IBM Research has received recognition beyond any commercial technology research organization and is home to 5 Nobel Laureates, 9 US National Medals of Technology, 5 US National Medals of Science, 6 Turing Awards, and 10 Inductees in US Inventors Hall of Fame."
145,Introduction to Data Visualization Tools,3,https://www.coursera.org/learn/python-for-data-visualization,"In this module, you learn about area plots and how to create them with Matplotlib, histograms and how to create them with Matplotlib, bar charts, and how to create them with Matplotlib, pie charts, and how to create them with Matplotlib, box plots and how to create them with Matplotlib, and scatter plots and bubble plots and how to create them with Matplotlib."
146,Basic and Specialized Visualization Tools,3,https://www.coursera.org/learn/python-for-data-visualization,"In this module, you will learn about advanced visualization tools such as waffle charts and word clouds and how to create them. You will also learn about seaborn, which is another visualization library, and how to use it to generate attractive regression plots. In addition, you will learn about Folium, which is another visualization library, designed especially for visualizing geospatial data. Finally, you will learn how to use Folium to create maps of different regions of the world and how to superimpose markers on top of a map, and how to create choropleth maps."
147,Advanced Visualizations and Geospatial Data,3,https://www.coursera.org/learn/python-for-data-visualization,"IBM offers a wide range of technology and consulting services; a broad portfolio of middleware for collaboration, predictive analytics, software development and systems management; and the world's most advanced servers and supercomputers. Utilizing its business consulting, technology and R&D expertise, IBM helps clients become ""smarter"" as the planet becomes more digitally interconnected. IBM invests more than $6 billion a year in R&D, just completing its 21st year of patent leadership. IBM Research has received recognition beyond any commercial technology research organization and is home to 5 Nobel Laureates, 9 US National Medals of Technology, 5 US National Medals of Science, 6 Turing Awards, and 10 Inductees in US Inventors Hall of Fame."
148,Introduction,5,https://www.coursera.org/learn/applied-data-science-capstone,"In this module, you will learn in details about Foursquare, which is the location data provider we will be using in this course, and its API. Essentially, you will learn how to create a Foursquare developer account, and use your credentials to search for nearby venues of a specific type, explore a particular venue, and search for trending venues around a location."
149,Foursquare API,5,https://www.coursera.org/learn/applied-data-science-capstone,"In this module, you will learn about k-means clustering, which is a form of unsupervised learning. Then you will use clustering and the Foursquare API to segment and cluster the neighborhoods in the city of New York. Furthermore, you will learn how to scrape website and parse HTML code using the Python package Beautifulsoup, and convert data into a pandas dataframe."
150,Neighborhood Segmentation and Clustering,5,https://www.coursera.org/learn/applied-data-science-capstone,"In this module, you will start working on the capstone project. You will clearly define a problem and discuss the data that you will be using to solve the problem."
151,The Battle of Neighborhoods,5,https://www.coursera.org/learn/applied-data-science-capstone,"In this module, you will carry out all the remaining work to complete your capstone project. You will submit a report of your project for peer evaluation."
152,The Battle of Neighborhoods (Cont'd),5,https://www.coursera.org/learn/applied-data-science-capstone,"IBM offers a wide range of technology and consulting services; a broad portfolio of middleware for collaboration, predictive analytics, software development and systems management; and the world's most advanced servers and supercomputers. Utilizing its business consulting, technology and R&D expertise, IBM helps clients become ""smarter"" as the planet becomes more digitally interconnected. IBM invests more than $6 billion a year in R&D, just completing its 21st year of patent leadership. IBM Research has received recognition beyond any commercial technology research organization and is home to 5 Nobel Laureates, 9 US National Medals of Technology, 5 US National Medals of Science, 6 Turing Awards, and 10 Inductees in US Inventors Hall of Fame."
153,Introduction to Customer Analytics,5,https://www.coursera.org/learn/wharton-customer-analytics?specialization=business-analytics,"In this module, you’ll learn what data can and can’t describe about customer behavior as well as the most effective methods for collecting data and deciding what it means.  You’ll understand the critical difference between data which describes a causal relationship and data which describes a correlative one as you explore the synergy between data and decisions, including the principles for systematically collecting and interpreting data to make better business decisions. You’ll also learn how data is used to explore a problem or question, and how to use that data to create products, marketing campaigns, and other strategies. By the end of this module, you’ll have a solid understanding of effective data collection and interpretation so that you can use the right data to make the right decision for your company or business."
154,Descriptive Analytics,5,https://www.coursera.org/learn/wharton-customer-analytics?specialization=business-analytics,"Once you’ve collected and interpreted data, what do you do with it? In this module, you’ll learn how to take the next step: how to use data about actions in the past to make to make predictions about actions in the future. You’ll examine the main tools used to predict behavior, and learn how to determine which tool is right for which decision purposes. Additionally, you’ll learn the language and the frameworks for making predictions of future behavior. At the end of this module, you’ll be able to determine what kinds of predictions you can make to create future strategies, understand the most powerful techniques for predictive models including regression analysis, and be prepared to take  full advantage of analytics to create effective data-driven business decisions."
155,Predictive Analytics,5,https://www.coursera.org/learn/wharton-customer-analytics?specialization=business-analytics,"How do you turn data into action? In this module, you’ll learn how prescriptive analytics provide recommendations for actions you can take to achieve your business goals. First, you’ll explore how to ask the right questions, how to define your objectives, and how to optimize for success. You’ll also examine critical examples of prescriptive models, including how quantity is impacted by price, how to maximize revenue, how to maximize profits, and how to best use online advertising. By the end of this module, you’ll be able to define a problem, define a good objective, and explore models for optimization which take competition into account, so that you can write prescriptions for data-driven actions that create success for your company or business."
156,Prescriptive Analytics,5,https://www.coursera.org/learn/wharton-customer-analytics?specialization=business-analytics,"How do top firms put data to work? In this module, you’ll learn how successful businesses use data to create cutting-edge, customer-focused marketing practices. You’ll explore real-world examples of the five-pronged attack to apply customer analytics to marketing, starting with data collection and data exploration, moving toward building predictive models and optimization, and continuing all the way to data-driven decisions. At the end of this module, you’ll know the best way to put data to work in your own company or business, based on the most innovative and effective data-driven practices of today’s top firms."
157,Application/Case Studies,5,https://www.coursera.org/learn/wharton-customer-analytics?specialization=business-analytics,"The University of Pennsylvania (commonly referred to as Penn) is a private university, located in Philadelphia, Pennsylvania, United States. A member of the Ivy League, Penn is the fourth-oldest institution of higher education in the United States, and considers itself to be the first university in the United States with both undergraduate and graduate studies. "
158,"Introduction, Descriptive and Predictive Analytics",4,https://www.coursera.org/learn/wharton-operations-analytics?specialization=business-analytics,"In this module, you'll learn how to identify the best decisions in settings with low uncertainty by building optimization models and applying them to specific business challenges. During the week, you’ll use algebraic formulations to concisely express optimization problems, look at how algebraic models should be converted into a spreadsheet format, and learn how to use spreadsheet Solvers as tools for identifying the best course of action. "
159,"Prescriptive Analytics, Low Uncertainty",4,https://www.coursera.org/learn/wharton-operations-analytics?specialization=business-analytics,"How can you evaluate and compare decisions when their impact is uncertain? In this module you will learn how to build and interpret simulation models that can help you to evaluate complex business decisions in uncertain settings. During the week, you will be introduced to some common measures of risk and reward, you’ll use simulation to estimate these quantities, and you’ll learn how to interpret and visualize your simulation results."
160,"Predictive Analytics, Risk",4,https://www.coursera.org/learn/wharton-operations-analytics?specialization=business-analytics,"This module introduces decision trees, a useful tool for evaluating decisions made under uncertainty. Using a concrete example, you'll learn how optimization, simulation, and decision trees can be used together to solve more complex business problems with high degrees of uncertainty. You'll also discover how the Newsvendor problem introduced in Week 1 can be solved with the simulation and optimization framework introduced in Weeks 2 and 3."
161,"Prescriptive Analytics, High Uncertainty ",4,https://www.coursera.org/learn/wharton-operations-analytics?specialization=business-analytics,"The University of Pennsylvania (commonly referred to as Penn) is a private university, located in Philadelphia, Pennsylvania, United States. A member of the Ivy League, Penn is the fourth-oldest institution of higher education in the United States, and considers itself to be the first university in the United States with both undergraduate and graduate studies. "
162,"Introduction to People Analytics, and Performance Evaluation",4,https://www.coursera.org/learn/wharton-people-analytics?specialization=business-analytics,"In this module, you'll learn how to use data to better analyze the key components of the staffing cycle: hiring, internal mobility and career development, and attrition. You'll explore different analytic approaches to predicting performance for hiring and for optimizing internal mobility, to understanding and reducing turnover, and to predicting attrition. You'll also learn the critical skill of understanding causality so that you can avoid using data incorrectly. By the end of this module, you'll be able to use data to improve the quality of the decisions you make in getting the right people into the right jobs and helping them stay there, to benefit not only your organization but also employee's individual careers. "
163,Staffing,4,https://www.coursera.org/learn/wharton-people-analytics?specialization=business-analytics,"In this module, you'll learn the basic principles behind using people analytics to improve collaboration between employees inside an organization so they can work together more successfully. You'll explore how data is used to describe, map, and evaluate collaboration networks, as well as how to intervene in collaboration networks to improve collaboration using examples from real-world companies. By the end of this module, you'll know how to deploy the tools and techniques of organizational network analysis to understand and improve collaboration patterns inside your organization to make your organization, and the people working within in it, more productive, effective, and successful. "
164,Collaboration,4,https://www.coursera.org/learn/wharton-people-analytics?specialization=business-analytics,"In this module, you explore talent analytics: how data may be used in talent assessment and development to maximize employee ability. You'll learn how to use data to move from performance evaluation to a more deeper analysis of employee evaluation so that you may be able to improve the both the effectiveness and the equitability of the promotion process at your firm. By the end of this module, you'll will understand the four major challenges of talent analytics: context, interdependence, self-fulfilling prophecies, and reverse causality, the challenges of working with algorithms, and some practical tips for incorporating data sensitively, fairly, and effectively into your own talent assessment and development processes to make your employees and your organization more successful. In the course conclusion, you'll also learn the current challenges and future directions of the field of people analytics, so that you may begin putting employee data to work in a ways that are smarter, practical and more powerful."
165,Talent Management and Future Directions,4,https://www.coursera.org/learn/wharton-people-analytics?specialization=business-analytics,"The University of Pennsylvania (commonly referred to as Penn) is a private university, located in Philadelphia, Pennsylvania, United States. A member of the Ivy League, Penn is the fourth-oldest institution of higher education in the United States, and considers itself to be the first university in the United States with both undergraduate and graduate studies. "
166,Ratios and Forecasting,4,https://www.coursera.org/learn/accounting-analytics?specialization=business-analytics,"This week we are going to examine ""earnings management"", which is the practice of trying to intentionally bias financial statements to look better than they really should look. Beginning with an overview of earnings management, we’ll cover means, motive, and opportunity: how managers actually make their earnings look better, their incentives for manipulating earnings, and how they get away with it. Then, we will investigate red flags for two different forms of revenue manipulation. Manipulating earnings through aggressive revenue recognition practices is the most common reason that companies get in trouble with government regulators for their accounting practices. Next, we will discuss red flags for manipulating earnings through aggressive expense recognition practices, which is the second most common reason that companies get in trouble for their accounting practices. By the end of this module, you’ll know how to spot earnings management and get a more accurate picture of earnings, so that you’ll be able to catch some bad guys in finance reporting!"
167,Earnings Management,4,https://www.coursera.org/learn/accounting-analytics?specialization=business-analytics,"This week, we’ll use big data approaches to try to detect earnings management. Specifically, we're going to use prediction models to try to predict how the financial statements would look if there were no manipulation by the manager. First, we’ll look at Discretionary Accruals Models, which try to model the non-cash portion of earnings or ""accruals,"" where managers are making estimates to calculate revenues or expenses. Next, we'll talk about Discretionary Expenditure Models, which try to model the cash portion of earnings. Then we'll look at Fraud Prediction Models, which try to directly predict what types of companies are likely to commit frauds. Finally, we’ll explore something called Benford's Law, which examines the frequency with which certain numbers appear. If certain numbers appear more often than dictated by Benford's Law, it's an indication that the financial statements were potentially manipulated. These models represent the state of the art right now, and are what academics use to try to detect and predict earnings management. By the end of this module, you'll have a very strong tool kit that will help you try to detect financial statements that may have been manipulated by managers."
168,Big Data and Prediction Models,4,https://www.coursera.org/learn/accounting-analytics?specialization=business-analytics,"Linking non-financial metrics to financial performance is one of the most important things we do as managers, and also one of the most difficult. We need to forecast future financial performance, but we have to take non-financial actions to influence it. And we must be able to accurately predict the ultimate impact on financial performance of improving non-financial dimensions. In this module, we’ll examine how to uncover which non-financial performance measures predict financial results through asking fundamental questions, such as: of the hundreds of non-financial measures, which are the key drivers of financial success? How do you rank or weight non-financial measures which don’t share a common denominator?  What performance targets are desirable? Finally, we’ll look at some comprehensive examples of how companies have used accounting analytics to show how investments in non-financial dimensions pay off in the future, and finish with some important organizational issues that commonly arise using these models. By the end of this module, you’ll know how predictive analytics can be used to determine what you should be measuring, how to weight very, very different performance measures when trying to analyze potential financial results, how to make trade-offs between short-term and long-term objectives, and how to set performance targets for optimal financial performance."
169,Linking Non-financial Metrics to Financial Performance,4,https://www.coursera.org/learn/accounting-analytics?specialization=business-analytics,"The University of Pennsylvania (commonly referred to as Penn) is a private university, located in Philadelphia, Pennsylvania, United States. A member of the Ivy League, Penn is the fourth-oldest institution of higher education in the United States, and considers itself to be the first university in the United States with both undergraduate and graduate studies. "
170,Introduction to Data Analytics,4,https://www.coursera.org/learn/decision-making?specialization=pwc-analytics,This module is an introductory look at big data and big data analytics where you will learn the about different types of data. We’ll also introduce you to PwC's perspective on big data and explain the impact of big data on businesses.  Finally we will name some of the different types of tools and technologies used to gather data.
171,Technology and types of data ,4,https://www.coursera.org/learn/decision-making?specialization=pwc-analytics,In this module we will describe some of the tools for data analytics and some of the key technologies for data analysis. We will talk about how visualization is important to the practice of data analytics. Finally we will identify a variety of tools and languages used and consider when those tools are best used.
172,Data analysis techniques and tools,4,https://www.coursera.org/learn/decision-making?specialization=pwc-analytics,"The course project will give you an opportunity to practice what you have learned.  You will participate in a simulated business situation in which you will select the best course of action.  You will then prepare a final deliverable which will be evaluated by your peers.  Additionally, you will have the opportunity to provide feedback on your peer's submissions.  "
173,Data-driven decision making project ,4,https://www.coursera.org/learn/decision-making?specialization=pwc-analytics,"With offices in 157 countries and more than 208,000 people, PwC is among the leading professional services networks in the world. Our purpose is to build trust in society and solve important problems. We help organisations and individuals create the value they’re looking for, by delivering quality in assurance, tax and advisory services. "
174,Overview of Excel,4,https://www.coursera.org/learn/excel-analysis?specialization=pwc-analytics,"In this module you will learn about VLookup, value cleansing and text functions. We will also introduce you to PwC's perspective on the value in cleansing data and using the appropriate functions.  Finally, we will provide you an opportunity to perform a problem solving exercise using VLookup, value cleansing and text function. Note: We recommend viewing videos in full-screen mode by clicking the double arrow in the lower right hand corner of your screen."
175,vLookups and Data Cleansing,4,https://www.coursera.org/learn/excel-analysis?specialization=pwc-analytics,"In this module, you will learn about logical functions and pivot tables. We will show you how to create and use pivot tables to solve business problems. We will give you an opportunity to practice creating and using a pivot table to solve a business problem. Finally, we will share some insight on PwC’s perspectives on the impact of Excel on your career and work. Note: We recommend viewing videos in full-screen mode by clicking the double arrow in the lower right hand corner of your screen."
176,Logical Functions & Pivot Tables,4,https://www.coursera.org/learn/excel-analysis?specialization=pwc-analytics,"In this module you will learn more advanced Excel formulas. We will show you how to create statistical formulas, perform an index match, and lastly, build financial formulas. We will provide you with an opportunity to problem solve using statistical formulas. Finally, we will give you an opportunity to practice what you have learned through a final project. Note: We recommend viewing videos in full-screen mode by clicking the double arrow in the lower right hand corner of your screen."
177,More Advanced Formulas,4,https://www.coursera.org/learn/excel-analysis?specialization=pwc-analytics,"With offices in 157 countries and more than 208,000 people, PwC is among the leading professional services networks in the world. Our purpose is to build trust in society and solve important problems. We help organisations and individuals create the value they’re looking for, by delivering quality in assurance, tax and advisory services. "
178,Preparing a Professional Excel ,4,https://www.coursera.org/learn/advanced-excel?specialization=pwc-analytics,"This week, we are going to explore three different analytical methods used to help model different scenarios and deal with variable uncertainty. These methods are scenario analysis, sensitivity analysis and simulation.  We’ll look at what each method is and then go deeper into why and how you use each.  Following some guided demonstration, you’ll be given a chance to practice in an Excel workbook and demonstrate what you’ve learned. "
179,Advanced Scenario Analysis ,4,https://www.coursera.org/learn/advanced-excel?specialization=pwc-analytics,"This week we are going to focus on data visualization. We will start off by discussing data visualization basics, outlining the theory and concepts behind data visualization. We will also discuss how to enable effective story telling through the correct selection, creation, and presentation of tables and charts. You’ll get a chance to learn how to create detailed graphs and charts to effectively tell a story about your data. "
180,Data Visualization,4,https://www.coursera.org/learn/advanced-excel?specialization=pwc-analytics,"In the final week of this course, you are going to learn how to create a dynamic dashboard. We are going to discuss how to establish a good understanding of your audience and how to collect key requirements in order to determine what type of dashboard to build.  We will talk about some guiding design principles and things to consider when building a dashboard. You’ll have a chance to practice everything you learn this week by creating your own functional dashboard in Excel.  "
181,Dashboarding ,4,https://www.coursera.org/learn/advanced-excel?specialization=pwc-analytics,"With offices in 157 countries and more than 208,000 people, PwC is among the leading professional services networks in the world. Our purpose is to build trust in society and solve important problems. We help organisations and individuals create the value they’re looking for, by delivering quality in assurance, tax and advisory services. "
182,Preparing a Presentation,4,https://www.coursera.org/learn/powerpoint-presentations?specialization=pwc-analytics,"This week, we will be covering the different types of communications styles.  You’ll start off by gaining an understanding of your personal professional presence and learn how to maximize it.  You’ll learn about verbal and nonverbal communications, and strategies to enhance your questioning and listening skills. We will also discuss how differences in culture can impact how you communicate."
183,Communication styles,4,https://www.coursera.org/learn/powerpoint-presentations?specialization=pwc-analytics,"This week, we're discussing how to create effective slides using PowerPoint. You’ll learn about the tools available within PowerPoint, how to structure your storyline, create storyboards, identify primary elements of slide design, display data and finalize your slide presentation. There is a peer review activity where you will apply the skills learned and create a storyboard. Finally, you will also get a chance to identify errors in a presentation to test your knowledge of standard industry practices."
184,Creating effective slides using PowerPoint,4,https://www.coursera.org/learn/powerpoint-presentations?specialization=pwc-analytics,"This week, you’re going to build and deliver a presentation to your peers, and receive feedback from them.  You will create a presentation of about 10 slides, employing the guidelines and industry best practices that have been discussed in this course. You can use the presentation storyboard that you created last week, which your peers have reviewed and given you feedback on.  Review what you’ve developed so far, and make changes or additions that you think will enhance the presentation. Once you’ve finalized your presentation, you will present it in a video using your smartphone or computer.Once you’re satisfied with the PowerPoint presentation and video, you will be submitting both for peer review.  You can use this feedback for current and future presentations that you will make during your career."
185,Delivering a presentation,4,https://www.coursera.org/learn/powerpoint-presentations?specialization=pwc-analytics,"With offices in 157 countries and more than 208,000 people, PwC is among the leading professional services networks in the world. Our purpose is to build trust in society and solve important problems. We help organisations and individuals create the value they’re looking for, by delivering quality in assurance, tax and advisory services. "
186,Course Orientation,5,https://www.coursera.org/learn/datavisualization?specialization=data-mining,"In this week's module, you will learn what data visualization is, how it's used, and how computers display information. You'll also explore different types of visualization and how humans perceive information."
187,Week 1: The Computer and the Human,5,https://www.coursera.org/learn/datavisualization?specialization=data-mining,"In this week's module, you will start to think about how to visualize data effectively. This will include assigning data to appropriate chart elements, using glyphs, parallel coordinates, and streamgraphs, as well as implementing principles of design and color to make your visualizations more engaging and effective."
188,Week 2: Visualization of Numerical Data,5,https://www.coursera.org/learn/datavisualization?specialization=data-mining,"In this week's module, you will learn how to visualize graphs that depict relationships between data items. You'll also plot data using coordinates that are not specifically provided by the data set."
189,Week 3: Visualization of Non-Numerical Data,5,https://www.coursera.org/learn/datavisualization?specialization=data-mining,"In this week's module, you will start to put together everything you've learned by designing your own visualization system for large datasets and dashboards. You'll create and interpret the visualization you created from your data set, and you'll also apply techniques from user-interface design to create an effective visualization system."
190,Week 4: The Visualization Dashboard,5,https://www.coursera.org/learn/datavisualization?specialization=data-mining,"The University of Illinois at Urbana-Champaign is a world leader in research, teaching and public engagement, distinguished by the breadth of its programs, broad academic excellence, and internationally renowned faculty and alumni. Illinois serves the world by creating knowledge, preparing students for lives of impact, and finding solutions to critical societal needs. "
191,Orientation,7,https://www.coursera.org/learn/text-retrieval?specialization=data-mining,"During this week's lessons, you will learn of natural language processing techniques, which are the foundation for all kinds of text-processing applications, the concept of a retrieval model, and the basic idea of the vector space model. "
192,Week 1,7,https://www.coursera.org/learn/text-retrieval?specialization=data-mining,"In this week's lessons, you will learn how the vector space model works in detail, the major heuristics used in designing a retrieval function for ranking documents with respect to a query, and how to implement an information retrieval system (i.e., a search engine), including how to build an inverted index and how to score documents quickly for a query. "
193,Week 2,7,https://www.coursera.org/learn/text-retrieval?specialization=data-mining,"In this week's lessons, you will learn how to evaluate an information retrieval system (a search engine), including the basic measures for evaluating a set of retrieved results and the major measures for evaluating a ranked list, including the average precision (AP) and the normalized discounted cumulative gain (nDCG), and practical issues in evaluation, including statistical significance testing and pooling."
194,Week 3,7,https://www.coursera.org/learn/text-retrieval?specialization=data-mining,"In this week's lessons, you will learn probabilistic retrieval models and statistical language models, particularly the detail of the query likelihood retrieval function with two specific smoothing methods, and how the query likelihood retrieval function is connected with the retrieval heuristics used in the vector space model. "
195,Week 4,7,https://www.coursera.org/learn/text-retrieval?specialization=data-mining,"In this week's lessons, you will learn feedback techniques in information retrieval, including the Rocchio feedback method for the vector space model, and a mixture model for feedback with language models. You will also learn how web search engines work, including web crawling, web indexing, and how links between web pages can be leveraged to score web pages. "
196,Week 5,7,https://www.coursera.org/learn/text-retrieval?specialization=data-mining,"In this week's lessons, you will learn how machine learning can be used to combine multiple scoring factors to optimize ranking of documents in web search (i.e., learning to rank), and learn techniques used in recommender systems (also called filtering systems), including content-based recommendation/filtering and collaborative filtering. You will also have a chance to review the entire course."
197,Week 6,7,https://www.coursera.org/learn/text-retrieval?specialization=data-mining,"The University of Illinois at Urbana-Champaign is a world leader in research, teaching and public engagement, distinguished by the breadth of its programs, broad academic excellence, and internationally renowned faculty and alumni. Illinois serves the world by creating knowledge, preparing students for lives of impact, and finding solutions to critical societal needs. "
198,Orientation,7,https://www.coursera.org/learn/text-mining?specialization=data-mining,"During this module, you will learn the overall course design, an overview of natural language processing techniques and text representation, which are the foundation for all kinds of text-mining applications, and word association mining with a particular focus on mining one of the two basic forms of word associations (i.e., paradigmatic relations).   "
199,Week 1,7,https://www.coursera.org/learn/text-mining?specialization=data-mining,"During this module, you will learn more about word association mining with a particular focus on mining the other basic form of word association (i.e., syntagmatic relations), and start learning topic analysis with a focus on techniques for mining one topic from text. "
200,Week 2,7,https://www.coursera.org/learn/text-mining?specialization=data-mining,"During this module, you will learn topic analysis in depth, including mixture models and how they work, Expectation-Maximization (EM) algorithm and how it can be used to estimate parameters of a mixture model, the basic topic model, Probabilistic Latent Semantic Analysis (PLSA), and how Latent Dirichlet Allocation (LDA) extends PLSA. "
201,Week 3,7,https://www.coursera.org/learn/text-mining?specialization=data-mining,"During this module, you will learn text clustering, including the basic concepts, main clustering techniques, including probabilistic approaches and similarity-based approaches, and how to evaluate text clustering. You will also start learning text categorization, which is related to text clustering, but with pre-defined categories that can be viewed as pre-defining clusters.   "
202,Week 4,7,https://www.coursera.org/learn/text-mining?specialization=data-mining,"During this module, you will continue learning about various methods for text categorization, including multiple methods classified under discriminative classifiers, and you will also learn sentiment analysis and opinion mining, including a detailed introduction to a particular technique for sentiment classification (i.e., ordinal regression). "
203,Week 5,7,https://www.coursera.org/learn/text-mining?specialization=data-mining,"During this module, you will continue learning about sentiment analysis and opinion mining with a focus on Latent Aspect Rating Analysis (LARA), and you will learn about techniques for joint mining of text and non-text data, including contextual text mining techniques for analyzing topics in text in association with various context information such as time, location, authors, and sources of data. You will also see a summary of the entire course."
204,Week 6,7,https://www.coursera.org/learn/text-mining?specialization=data-mining,"The University of Illinois at Urbana-Champaign is a world leader in research, teaching and public engagement, distinguished by the breadth of its programs, broad academic excellence, and internationally renowned faculty and alumni. Illinois serves the world by creating knowledge, preparing students for lives of impact, and finding solutions to critical societal needs. "
205,Course Orientation,5,https://www.coursera.org/learn/data-patterns?specialization=data-mining,"Module 1 consists of two lessons. Lesson 1 covers the general concepts of pattern discovery. This includes the basic concepts of frequent patterns, closed patterns, max-patterns, and association rules. Lesson 2 covers three major approaches for mining frequent patterns. We will learn the downward closure (or Apriori) property of frequent patterns and three major categories of methods for mining frequent patterns: the Apriori algorithm, the method that explores vertical data format, and the pattern-growth approach.  We will also discuss how to directly mine the set of closed patterns."
206,Module 1,5,https://www.coursera.org/learn/data-patterns?specialization=data-mining,"Module 2 covers two lessons: Lessons 3 and 4.  In Lesson 3, we discuss pattern evaluation and learn what kind of interesting measures should be used in pattern analysis. We show that the support-confidence framework is inadequate for pattern evaluation, and even the popularly used lift and chi-square measures may not be good under certain situations. We introduce the concept of null-invariance and introduce a new null-invariant measure for pattern evaluation. In Lesson 4, we examine the issues on mining a diverse spectrum of patterns. We learn the concepts of and mining methods for multiple-level associations, multi-dimensional associations, quantitative associations, negative correlations, compressed patterns, and redundancy-aware patterns."
207,Module 2,5,https://www.coursera.org/learn/data-patterns?specialization=data-mining,"Module 3 consists of two lessons: Lessons 5 and 6.   In Lesson 5, we discuss mining sequential patterns.   We will learn several popular and efficient sequential pattern mining methods, including an Apriori-based sequential pattern mining method, GSP; a vertical data format-based sequential pattern method, SPADE; and a pattern-growth-based sequential pattern mining method, PrefixSpan. We will also learn how to directly mine closed sequential patterns. In Lesson 6, we will study concepts and methods for mining spatiotemporal and trajectory patterns as one kind of pattern mining applications. We will introduce a few popular kinds of patterns and their mining methods, including mining spatial associations, mining spatial colocation patterns, mining and aggregating patterns over multiple trajectories, mining semantics-rich movement patterns, and mining periodic movement patterns."
208,Module 3,5,https://www.coursera.org/learn/data-patterns?specialization=data-mining,"Module 4 consists of two lessons: Lessons 7 and 8.   In Lesson 7, we study mining quality phrases from text data as the second kind of pattern mining application. We will mainly introduce two newer methods for phrase mining: ToPMine and SegPhrase, and show frequent pattern mining may be an important role for mining quality phrases in massive text data. In Lesson 8, we will learn several advanced topics on pattern discovery, including mining frequent patterns in data streams, pattern discovery for software bug mining, pattern discovery for image analysis, and pattern discovery and society: privacy-preserving pattern mining.  Finally, we look forward to the future of pattern mining research and application exploration."
209,Week 4,5,https://www.coursera.org/learn/data-patterns?specialization=data-mining,"The University of Illinois at Urbana-Champaign is a world leader in research, teaching and public engagement, distinguished by the breadth of its programs, broad academic excellence, and internationally renowned faculty and alumni. Illinois serves the world by creating knowledge, preparing students for lives of impact, and finding solutions to critical societal needs. "
210,Los datos y la toma de decisiones en tu vida y en las organizaciones,4,https://www.coursera.org/learn/analisis-de-datos?specialization=analisis-datos,"A través de este módulo lograrás desarrollar capacidades iniciales para el Análisis de Datos, que te serán de gran utilidad para una buena toma de decisiones en tu organización. Para lograrlo, nos enfocaremos en dos tareas que son fundamentales en esta rama de conocimiento: la exploración de patrones y comportamientos clave en los datos, así como el realizar predicciones y pronósticos a partir de los mismos.Para lograrlo, desarrollarás la capacidad de utilizar un conjunto de herramientas estadísticas, así como apoyarte en software computacional especializado para este tipo de actividades y que te permitirá generar análisis y resultados de gran utilidad para ti y tu organización, revisando diversos casos reales en donde se han aplicado este tipo de herramientas y estrategias."
211,Exploración y predicción de datos,4,https://www.coursera.org/learn/analisis-de-datos?specialization=analisis-datos,"A través de este módulo lograrás realizar un análisis integral de datos e información, para generar un diagnóstico que apoye la toma de decisiones en tu organización. Para lograrlo, desarrollarás la capacidad de generar diversos análisis y reportes, que te servirán como base para la identificación de áreas de oportunidad y cursos de acción a tomar.Para lograrlo, desarrollarás la capacidad de utilizar un conjunto de herramientas estadísticas, así como apoyarte en software computacional especializado para este tipo de actividades y que te permitirá generar análisis y resultados de gran utilidad para ti y tu organización, revisando además diversos casos reales en donde se han aplicado este tipo de herramientas y estrategias."
212,Integración y análisis de datos para el diagnóstico organizacional ,4,https://www.coursera.org/learn/analisis-de-datos?specialization=analisis-datos,"Al terminar este módulo serás capaz de identificar los distintos criterios bajo los cuales podrás tomar decisiones en tu vida y tu organización, a partir de las capacidades de análisis de datos e información que adquiriste en los módulos previos. Conocerás la estructura y beneficios de seguir distintos enfoques para la toma de decisiones, así como cuándo y bajo qué contextos es deseable seguir cada uno de ellos. Además, identificarás también la mejor estrategia a seguir bajo criterios específicos como los costos de oportunidad o escenarios de alta incertidumbre."
213,Herramientas y métodos para la toma de decisiones,4,https://www.coursera.org/learn/analisis-de-datos?specialization=analisis-datos,"Tecnológico de Monterrey es una de las instituciones educativas privadas sin fines de lucro más grande en Latinoamérica, con más de 98,000 estudiantes en preparatoria, licenciatura, y posgrado."
214,El reto de tomar mejores decisiones,4,https://www.coursera.org/learn/ordenamiento-datos?specialization=analisis-datos,En este módulo conocerás más sobre los datos y el valor de los mismos. Explorarás el uso de la  herramienta computacional de Watson Analytics para la recolección de datos que te permitirá importar datos estructurados y realizar un análisis descriptivo de los mismos.
215,Recopilación de datos,4,https://www.coursera.org/learn/ordenamiento-datos?specialization=analisis-datos,"En este módulo aprenderás el manejo de datos no estructurados utilizando la herramienta computacional Import-io para la lectura de datos de algún sitio web, así como la importación a Watson Analytics de datos de Twitter. Este módulo comprende la parte práctica del curso, por lo que al final del mismo deberás resolver un caso práctico utilizando las dos herramientas antes descritas."
216,Un mundo de datos no ordenados,4,https://www.coursera.org/learn/ordenamiento-datos?specialization=analisis-datos,"Al finalizar este módulo serás capaz de explorar los datos  utilizando las capacidades de visualización de la herramienta Watson Analytics. De la misma manera, aprenderás a encontrar patrones y relaciones en los datos que representan respuestas a problemas de negocio.  "
217,Exploración de datos,4,https://www.coursera.org/learn/ordenamiento-datos?specialization=analisis-datos,"Tecnológico de Monterrey es una de las instituciones educativas privadas sin fines de lucro más grande en Latinoamérica, con más de 98,000 estudiantes en preparatoria, licenciatura, y posgrado."
218,¿Cómo confiar en los datos?,4,https://www.coursera.org/learn/datos-tecnicas?specialization=analisis-datos,"En diversas problemáticas profesionales relacionadas con el análisis de un gran número de datos,  seguramente  te has encontrado en la disyuntiva de aceptar o rechazar una proposición y seguramente te gustaría tener más información para tomar tu decisión acertada; la forma de lograrlo  es formular el problema a través de una prueba de hipótesis.¿Cómo saber si una hipótesis estadística está correctamente planteada? ¿La verdad o falsedad de una hipótesis en particular se conoce con certeza sin tener que analizar a toda la población? 

Al finalizar este módulo serás capaz de desarrollar un procedimiento de prueba de hipótesis teniendo en cuenta el tipo de información contenida en la muestra aleatoria de la población de interés y evitar la posibilidad de llegar a una conclusión equivocada."
219,¿Son válidas las suposiciones sobre mis datos?,4,https://www.coursera.org/learn/datos-tecnicas?specialization=analisis-datos,"En este módulo conocerás la aplicación de uno de los modelos más populares para la toma de decisiones ya que te permite estimar el valor promedio de una variable dependiente tomando en cuenta una o más variables explicativas o bien hacer inferencias acerca de algún fenómeno del cual no conozcas aún su resultado. Los modelos de regresión pueden ser adaptados a un sinfín de aplicaciones ejecutivas. Hoy en día es mucho más fácil realizar el análisis de un gran volumen de datos gracias a que muchos paquetes estadísticos han desarrollado interfaces amigables con el usuario que le evitan realizar cálculos matemáticos y así el usuario centre su interés en el análisis.  Finalmente, este módulo te ayudará a identificar elementos básicos que integran un modelo de regresión pero sobre todo te permitirán el valor de los datos para una adecuada tomar de decisiones dentro de tu organización."
220,Modelos de regresión,4,https://www.coursera.org/learn/datos-tecnicas?specialization=analisis-datos,"Las ""filas"" son un aspecto típico de la vida moderna que nos encontramos continuamente en nuestras actividades cotidianas, en un banco, en un centro comercial, al abordar un avión, en un call center, etc. Este fenómeno se origina cuando tenemos la necesidad de compartir uno o más recursos, los cuales son utilizados para dar atención a un gran número de trabajadores. Las organizaciones frecuentemente deben tomar decisiones respecto a la capacidad de servicios que debe ofrecer. Sin embargo, muchas veces es imposible predecir con exactitud cuándo llegarán los clientes que demandan el servicio y/o cuánto tiempo será necesario para dar ese servicio; es por eso que esas decisiones implican dilemas que se deben de resolver con información escasa. Los modelos de filas no resuelven  directamente el problema, pero generan información que se necesita para tomar las decisiones adecuadas prediciendo algunas características sobre la línea de espera: Al finalizar este módulo serás capaz de entender cómo se estructura un sistema de filas de espera y analizar el costo que implica para las organizaciones operar con recursos ociosos cuando no se analiza adecuadamente la información del número de clientes que demandan un servicio y la duración de éste."
221,Teoría de filas  ,4,https://www.coursera.org/learn/datos-tecnicas?specialization=analisis-datos,"Tecnológico de Monterrey es una de las instituciones educativas privadas sin fines de lucro más grande en Latinoamérica, con más de 98,000 estudiantes en preparatoria, licenciatura, y posgrado."
222,Análisis de datos en el sector salud: Identificando como mejorar la atención ,4,https://www.coursera.org/learn/analisis-de-datos-aplicaciones?specialization=analisis-datos,"Dentro de los diversos sectores de la economía, el comercio al detalle (también conocido con el término anglosajón retail) es uno de los más dinámicos debido a la extensa competencia que hay en él, así como la rápida evolución del comportamiento del consumidor. En este módulo identificaremos las aplicaciones de análisis de datos que permiten encontrar formas más eficientes para planificar y operar esta industria con el fin de lograr resultados óptimos."
223,Generando valor para el consumidor: Aplicaciones de análisis de datos en ventas al detalle (Retail).,4,https://www.coursera.org/learn/analisis-de-datos-aplicaciones?specialization=analisis-datos,"Las finanzas son fundamentales para el funcionamiento de nuestro mundo y por tanto demandan una eficiente gestión de los recursos, la complejidad de las decisiones relacionadas con ésta, vuelve indispensable contar con herramientas que nos permitan contar con una alta eficacia y eficiencia al tomarlas. En este módulo exploraremos algunas de las ventajas de emplear el análisis de datos orientado a fenómenos económicos y financieros y cómo podemos sacar ventaja de la información disponible."
224,Generando mejores rendimientos: Utilizando análisis de datos para mejores decisiones financieras,4,https://www.coursera.org/learn/analisis-de-datos-aplicaciones?specialization=analisis-datos,"La gestión de la cadena de suministro es una función vital en las organizaciones. Su operación eficaz es indispensable para cumplir expectativas de servicio de los clientes y consumidores, y conducirla de manera eficiente permite que los beneficios puedan maximizarse. En este módulo conoceremos algunas de las aplicaciones del análisis de datos en los procesos fundamentales de la cadena de suministro, tales como planeación de la demanda, gestión de proveedores y distribución de productos."
225,Mejores decisiones en la cadena de suministro mediante análisis de datos,4,https://www.coursera.org/learn/analisis-de-datos-aplicaciones?specialization=analisis-datos,"Tecnológico de Monterrey es una de las instituciones educativas privadas sin fines de lucro más grande en Latinoamérica, con más de 98,000 estudiantes en preparatoria, licenciatura, y posgrado."
226,About This Specialization and Course ,5,https://www.coursera.org/learn/analytics-business-metrics?specialization=excel-mysql,"Welcome! This week we will explore business metrics - the critical numbers that help companies figure out how to survive and thrive. Inside every pile of data is a vital metric trying to get out! By the end of this week, you will be able to: distinguish business metrics from mere business data; identify critical business metrics such as cash flow, profitability, and online retail marketing metrics;  distinguish revenue, profitability and risk metrics; and distinguish traditional from dynamic metrics. Included in this week’s course materials is a Cash Flow and P&L statement for Egger’s Roast Coffee, as a supplemental document, so be sure to review it carefully and refer to the glossary for key information. "
227,Introducing Business Metrics,5,https://www.coursera.org/learn/analytics-business-metrics?specialization=excel-mysql,"Welcome!  This week, we will meet some great people - all former students of mine - now working at super-interesting and exciting jobs as business analysts, business data analysts, or data scientists. We’ll explore what they do, how their role relates to big data, and the skills they needed to get hired! Our hope is this information will give you a better understanding of the type of data-related job you might apply for once you've completed this specialization, and a sense of the type of company you would find most appealing to work for. By the end of this week, you will be able to:  differentiate among different job roles within a company that work with data; identify how each role works with data; and describe the skills required to perform each job role. You will differentiate how different types of companies relate to big data culture, and rank any company according to a 20-item checklist. You will also learn to differentiate how different types of companies relate to big data culture. Included in this week’s materials is a 20-item checklist to rank companies. This week also includes in-video polls so you can see how others are ranking their businesses."
228,Working in the Business Data Analytics Marketplace,5,https://www.coursera.org/learn/analytics-business-metrics?specialization=excel-mysql,"Welcome! This week we’re going to go deeper into the critically-important metrics for web marketing - metrics every type of business needs to understand in order to survive. We’ll dive into the 'vertical' market of financial services - where digital companies are threatening to take away the market from traditional 'brick-and- mortar' companies.By the end of this week, you will be able to: Identify critical business metrics for all companies engaged in web-based marketing; and identify critical business metrics for financial services companies. You’ll find additional website links that expand some of the course materials covered in this week’s video lectures. "
229,Going Deeper into Business Metrics ,5,https://www.coursera.org/learn/analytics-business-metrics?specialization=excel-mysql,"This week contains the final course assignment, a peer assessment in which you will identify business metrics of interest in a case example, describe those metrics, and propose a business process change that could be supported by the metric chosen."
230,Applying Business Metrics to a Business Case Study,5,https://www.coursera.org/learn/analytics-business-metrics?specialization=excel-mysql,"Duke University has about 13,000 undergraduate and graduate students and a world-class faculty helping to expand the frontiers of knowledge. The university has a strong commitment to applying knowledge in service to society, both near its North Carolina campus and around the world."
231,About This Course,7,https://www.coursera.org/learn/analytics-excel?specialization=excel-mysql,"In this module, will explore the essential Excel skills to address typical business situations you may encounter in the future. The Excel vocabulary and functions taught throughout this module make it possible for you to understand the additional explanatory Excel spreadsheets that accompany later videos in this course. "
232,Excel Essentials for Beginners,7,https://www.coursera.org/learn/analytics-excel?specialization=excel-mysql,"Separating collections into two categories, such as “buy this stock, don’t but that stock” or “target this customer with a special offer, but not that one” is the ultimate goal of most business data-analysis projects. There is a specialized vocabulary of measures for comparing and optimizing the performance of the algorithms used to classify collections into two groups. You will learn how and why to apply these different metrics, including how to calculate the all-important AUC: the area under the Receiver Operating Characteristic (ROC) Curve. "
233,Binary Classification,7,https://www.coursera.org/learn/analytics-excel?specialization=excel-mysql,"In this module, you will learn how to calculate and apply the vitally useful uncertainty metric known as “entropy.” In contrast to the more familiar “probability” that represents the uncertainty that a single outcome will occur, “entropy” quantifies the aggregate uncertainty of all possible outcomes.The entropy measure provides the framework for accountability in data-analytic work. Entropy gives you the power to quantify the uncertainty of future outcomes relevant to your business twice: using the best-available estimates before you begin a project, and then again after you have built a predictive model.
The difference between the two measures is the Information Gain contributed by your work."
234,Information Measures,7,https://www.coursera.org/learn/analytics-excel?specialization=excel-mysql,"The Linear Correlation measure is a much richer metric for evaluating associations than is commonly realized. You can use it to quantify how much a linear model reduces uncertainty.  When used to forecast future outcomes, it can be converted into a “point estimate” plus a “confidence interval,” or converted into an information gain measure. You will develop a fluent knowledge of these concepts and the many valuable uses to which linear regression is put in business data analysis. This module also teaches how to use the Central Limit Theorem (CLT) to solve practical problems. The two topics are closely related because regression and the CLT both make use of a special family of probability distributions called “Gaussians.” You will learn everything you need to know to work with Gaussians in these and other contexts. "
235,Linear Regression,7,https://www.coursera.org/learn/analytics-excel?specialization=excel-mysql,"This module gives you additional valuable concepts and skills related to building high-quality models. As you know, a “model” is a description of a process applied to available data (inputs) that produces an estimate of a future and as yet unknown outcome as output. 
Very often, models for outputs take the form of a probability distribution. This module covers how to estimate probability distributions from data (a “probability histogram”), and how to describe and generate the most useful probability distributions used by data scientists. It also covers in detail how to develop a binary classification model with parameters optimized to maximize the AUC, and how to apply linear regression models when your input consists of multiple types of data for each event. 
The module concludes with an explanation of “over-fitting” which is the main reason that apparently good predictive models often fail in real life business settings. We conclude with some tips for how you can avoid over-fitting in you own predictive model for the final project – and in real life."
236,Additional Skills for Model Building,7,https://www.coursera.org/learn/analytics-excel?specialization=excel-mysql,"The final course project is a comprehensive assessment covering all of the course material, and consists of four quizzes and a peer review assignment.  For quiz one and quiz two, there are learning points that explain components of the quiz.  These learning points will unlock only after you complete the quiz with a passing grade. Before you start, please read through the final project instructions.  From past student experience, the final project which includes all the quizzes and peer assessment, takes anywhere from 10-12 hours."
237,Final Course Project,7,https://www.coursera.org/learn/analytics-excel?specialization=excel-mysql,"Duke University has about 13,000 undergraduate and graduate students and a world-class faculty helping to expand the frontiers of knowledge. The university has a strong commitment to applying knowledge in service to society, both near its North Carolina campus and around the world."
238,About this Specialization and Course,6,https://www.coursera.org/learn/analytics-tableau?specialization=excel-mysql,"Welcome! This week, you will learn how data analysts ask the right questions to ensure project success. By the end of this week, you will be able to: <p><ul><li>Craft the right questions to ensure your analysis projects succeed</li><li> Leverage questions to design logical and structured analysis plans</ul></li> <p> Remember to refer back to the Additional Resources reading: Identifying and Eliciting Information from Stakeholders). In addition, you will complete a  graded quiz. <p> As always, if you have any questions, post them to the <b>Discussions.</b> <p>To get started, please begin with the video “Tips for Becoming a Data Analyst.” <p>I hope you enjoy this week's materials!</p>"
239,"Asking The ""Right Questions""",6,https://www.coursera.org/learn/analytics-tableau?specialization=excel-mysql,"Welcome to week 2! This week you'll install Tableau Desktop to learn how visualizing data helps you figure out what your data mean efficiently, and in the process of doing so, helps you narrow in on what factors you should take into consideration in your statistical models or predictive algorithms.  Over the next two weeks, we’re going to learn how to use Tableau to implement this type of visualization and to help you find, and communicate, answers to business questions, as well as work with the Tableau functions that all data analysts should be familiar with.  You will learn to install Tableau Desktop and learn to use the program by working with two data sets. In addition, through a series of practice exercises, you will use a data set to do example analyses and to answer specific sample questions about salaries for certain data-related jobs across the United State. Then for graded exercises, you will use a different data set to work out analyses and questions that will require you to directly apply the Tableau skills you have acquired through practice. <p>By the end of this week, you will be able to: <ul><li>Create the most important graphs used in business analysis and transform data in Tableau </li></ul><p>Once you have watched the ""Why Tableau"" video, review the ""Written Instructions to install Tableau Desktop"" and install the software. Remember to refer back to the Salary Data Set and to the Dognition Data Set resources posted on the course site this week. You will also complete a graded quiz at the end of the week. <p>As always, if you have any questions, post them to the <b>Discussions</b>.<p>To get started, please begin with the video “Use Data Visualization to Drive Your Analysis"" and then review the ""Written Instructions to install Tableau Desktop.<p>I hope you enjoy this week's materials! "
240,Data Visualization with Tableau,6,https://www.coursera.org/learn/analytics-tableau?specialization=excel-mysql,"Welcome to week 3! This week you'll continue learning how to use Tableau to answer data analysis questions. You will learn how to use Tableau to both find, and eventually communicate answers to business questions. You'll learn about the process of elicitation, and learn how to ensure your data story is not undermined by overgeneralization or bias and how to format your data charts to begin creating a compelling data story.  By the end of this week, you will be able to: <ul><li>Write calculations and equations in Tableau</li> <li>Publish online business dashboards with Tableau.</li></ul> <p>Remember to refer  to the additional resources for this week: “Examples of Tableau Dashboards and Stories” and ""Using Tableau Dashboards When You Don't Have To."" <p>You will also complete a graded quiz. <p>As always, if you have any questions, post them to the Discussions. <p>To get started, please begin with the video “Customizing and Sharing New Data in Tableau.” <p>I hope you enjoy this week's materials!"
241,Dynamic Data Manipulation and Presentation in Tableau,6,https://www.coursera.org/learn/analytics-tableau?specialization=excel-mysql,"Welcome to week 4! This week you will become a master at getting people to agree with your data-driven business recommendations as you learn to deliver a compelling business presentation.  You’ll learn about the insight from the intersection of visualization science and decision science, and what this means for you as a  data analyst, who seeks to design a compelling and effective business presentations. If you intend to affect people’s decisions, you need to influence where they look. This week we will review  a set of tools and concepts you can use to optimize your visualizations and your presentation style. You will soon  be a master at getting people to agree with your data-driven business recommendations! <p>By the end of this week, you will be able to:<p><ul><li>Tell stories with data</li> <li>Design effective slide presentations to showcase your data story, and</li> <li> Deliver compelling business presentations</ul></li><p> Remember to refer back to the Study Guide: Designing and Delivering Effective Presentations. You will also complete a graded quiz. <p>As always, if you have any questions, post them to the <b>Discussions</b>.<p> To get started, please begin with the video “Using Visualization to Influence Business Decisions.”<p> I hope you enjoy this week's materials!"
242,"Your Communication Toolbox: Visualizations, Logic, and Stories",6,https://www.coursera.org/learn/analytics-tableau?specialization=excel-mysql,"Welcome to week 5! This week you will complete your final project. This assignment requires you to submit a recording of yourself giving a 4-5 minute presentation in which you present a data-driven business process change proposal to Dognition company management about how to increase the numbers of tests users complete. Students will give a short, peer-reviewed business presentation that uses a specified chart in Tableau. The final project will assess your mastery of the following: <p> <ul><li>Demonstrated understanding the Tableau functions discussed in this course</li><li>Adapting visualizations to make them maximally communicative</li><li>Storyboarding skills</li> <li>Translating your story into a presentation ready for the boardroom</li><li>Effective presentation delivery</li><li>Evaluating business presentations</ul></li><p> Remember to refer to the Background Information for Peer Review Assignment  on the course web site before you begin. This final course project is a comprehensive assessment covering all of the course material and will take approximately 6-8 hours to complete.<p>As always, if you have any questions, post them to the Discussions. Thank you for your contributions to this  final project!<p> "
243,Final Project,6,https://www.coursera.org/learn/analytics-tableau?specialization=excel-mysql,"Duke University has about 13,000 undergraduate and graduate students and a world-class faculty helping to expand the frontiers of knowledge. The university has a strong commitment to applying knowledge in service to society, both near its North Carolina campus and around the world."
244,About this Specialization and Course ,6,https://www.coursera.org/learn/analytics-mysql?specialization=excel-mysql,"Welcome to week 1! This week  you will learn how relational databases are organized, and practice making and interpreting Entity Relationship (ER) diagrams and relational schemas that describe the structure of data stored in a database. <p>By the end of the week, you will be able to:<ul><li>Describe the fundamental principles of relational database design <li>Interpret Entity Relationship (ER) diagrams and Entity Relationship (ER) schemas, and</li><li>Create your own ER diagrams and relational schemas using a software tool called ERDPlus that you will use to aid your query-writing later in the course.</li></ul><p>This week’s exercises are donated from a well-known Database Systems textbook, and will help you deepen and strengthen your understanding of how relational databases are organized.  This deeper understanding will help you navigate complicated business databases, and allow you to write more efficient queries.  At the conclusion of the week, you will test your understanding of database design principles by completing the Week 1 graded quiz.</p> <p>To get started, please begin with the video “Problems with Having a Lot of Data Used by a Lot of People.” <p>As always, if you have any questions, post them to the Discussions. <p>I hope you enjoy this week's materials!"
245,Understanding Relational Databases,6,https://www.coursera.org/learn/analytics-mysql?specialization=excel-mysql,"Welcome to week 2! This week, you will start interacting with business databases. You will write SQL queries that query data from two real companies. One data set, donated from a local start-up in Durham, North Carolina called Dognition, is a MySQL database containing tables of over 1 million rows. The other data set, donated from a national US department store chain called Dillard’s, is a Teradata database containing tables with over a hundred million rows. By the end of the week, you will be able to:1.  Use two different database user interfaces2.  Write queries to verify and describe all the contents of the Dognition MySQL database and the Dillard’s Teradata database3.  Retrieve data that meet specific criteria in a socially-responsible using SELECT, FROM, WHERE, LIMIT, and TOP clauses, and4.  Format the data you retrieve using aliases, DISTINCT clauses, and ORDER BY clauses.Make sure to watch the instructional videos about how to use the database interfaces we have established for this course, and complete both the MySQL and the Teradata exercises. At the end of the week, you will test your understanding of the SQL syntax introduced this week by completing the Week 2 graded quiz.To get started, please begin with the video “Introduction to Week 2.”  As always, if you have any questions, post them to the Discussions. Enjoy this week's materials!"
246, Queries to Extract Data from Single Tables ,6,https://www.coursera.org/learn/analytics-mysql?specialization=excel-mysql,"<p>Welcome to week 3! This week, we are going to learn the SQL syntax that allows you to segment your data into separate categories and segment.  We are also going to learn how to combine data stored in separate tables.</p><p>By the end of the week, you will be able to:</p><ul><li>Summarize values across entire columns, and break those summaries up according to specific variables or values in others columns using GROUP BY and HAVING clauses</li><li>Combine information from multiple tables using inner and outer joins</li><li>Use strategies to manage joins between tables with duplicate rows, many-to-many relationships, and atypical configurations</li><li>Practice one of the slightly more challenging use cases of aggregation functions, and</li><li>Work with the Dognition database to learn more about how MySQL handles mismatched aggregation levels.</li></ul><p>Make sure to watch the videos about joins, and complete both the MySQL and the Teradata exercises. At the end of the week, you will test your understanding of the SQL syntax introduced this week by completing the Week 3 graded quiz.</p><p>We strongly encourage you to use the course Discussions to help each other with questions. </p> <p>To get started, please begin with the video 'Welcome to Week 3.’</p><p>I hope you enjoy this week’s materials!</p>"
247,Queries to Summarize Groups of Data from Multiple Tables ,6,https://www.coursera.org/learn/analytics-mysql?specialization=excel-mysql,"<p>Welcome to week 4, the final week of Managing Big Data with MySQL!  This week you will practice integrating the SQL syntax you’ve learn so far into queries that address analysis questions typical of those you will complete as a business data analyst.</p>  <p>By the end of the week, you will be able to:</p><ul><li>Design and execute subqueries</li><li>Introduce logical conditions into your queries using IF and CASE statements</li><li>Implement analyses that accommodate missing data or data mistakes, and</li><li>Write complex queries that incorporate many tables and clauses.</li></ul><p>By the end of this week you will feel confident claiming that you know how to write SQL queries to create business value. Due to the extensive nature of the queries we will practice this week, we have put the graded quiz that tests your understanding of the SQL strategies you will practice in its own week rather than including it in this week’s materials. </p> <p>Make sure to complete both the MySQL exercises and the Teradata exercises, and we strongly encourage you to use the course Discussions to help each other with questions.  </p><p>To get started, please begin with the video 'Welcome to Week 4.’</p><p>I hope you enjoy this week’s materials!</p>"
248, Queries to Address More Detailed Business Questions,6,https://www.coursera.org/learn/analytics-mysql?specialization=excel-mysql,"This week contains the final ungraded Teradata exercises, and the final graded quiz for the course. The exercises are intended to hone and build your understanding of the last important concepts in the course, and lead directly to the quiz so be sure to do both!"
249,Strengthen and Test Your Understanding ,6,https://www.coursera.org/learn/analytics-mysql?specialization=excel-mysql,"Duke University has about 13,000 undergraduate and graduate students and a world-class faculty helping to expand the frontiers of knowledge. The university has a strong commitment to applying knowledge in service to society, both near its North Carolina campus and around the world."
250,Getting Started + Functions & Evaluation,6,https://www.coursera.org/learn/progfun1?specialization=scala,"This week, we'll learn about functions as first-class values, and higher order functions. We'll also learn about Scala's syntax and how it's formally defined. Finally, we'll learn about methods, classes, and data abstraction through the design of a data structure for rational numbers."
251,Higher Order Functions,6,https://www.coursera.org/learn/progfun1?specialization=scala,"This week, we'll cover traits, and we'll learn how to organize classes into hierarchies. We'll cover the hierarchy of standard Scala types, and see how to organize classes and traits into packages. Finally, we'll touch upon the different sorts of polymorphism in Scala."
252,Data and Abstraction,6,https://www.coursera.org/learn/progfun1?specialization=scala,"This week we'll learn about the relationship between functions and objects in Scala; functions *are* objects! We'll zoom in on Scala's type system, covering subtyping and generics, and moving on to more advanced aspects of Scala's type system like variance. Finally, we'll cover Scala's most widely used data structure, Lists, and one of Scala's most powerful tools, pattern matching."
253,Types and Pattern Matching,6,https://www.coursera.org/learn/progfun1?specialization=scala,"This week we dive into Lists, the most commonly-used data structure in Scala."
254,Lists,6,https://www.coursera.org/learn/progfun1?specialization=scala,"After a deep-dive into Lists, this week we'll explore other data structures; vectors, maps, ranges, arrays, and more. We'll dive into Scala's powerful and flexible for-comprehensions for querying data."
255,Collections,6,https://www.coursera.org/learn/progfun1?specialization=scala,
256,For Expressions and Monads,5,https://www.coursera.org/learn/progfun2?specialization=scala,"This week we'll revisit performance issues caused by combinatorial search, and we'll discover an important concept in functional programming that can these issues: laziness. We'll also learn a little bit about proofs on trees; in particular, we'll see how to extend structural induction to trees."
257,Lazy Evaluation,5,https://www.coursera.org/learn/progfun2?specialization=scala,"This week, we’ll learn how to make the compiler write programs for us! We’ll see how the compiler can summon program fragments based on their type and how this mechanism can be used to implement a new form of polymorphism (type classes)."
258,Type-Directed Programming,5,https://www.coursera.org/learn/progfun2?specialization=scala,"This week, we'll learn about state and side-effects. Through a rich example, we'll learn programming patterns for managing state in larger programs. We'll also learn about for-loops and while-loops in Scala."
259,Functions and State,5,https://www.coursera.org/learn/progfun2?specialization=scala,"This week we'll learn a number of important programming patterns via examples, starting with the observer pattern, and then going on to functional reactive programming."
260,Timely Effects,5,https://www.coursera.org/learn/progfun2?specialization=scala,
261,Parallel Programming,4,https://www.coursera.org/learn/parprog1?specialization=scala,"We continue with examples of parallel algorithms by presenting a parallel merge sort. We then explain how operations such as map, reduce, and scan can be computed in parallel. We present associativity as the key condition enabling parallel implementation of reduce and scan."
262,Basic Task Parallel Algorithms,4,https://www.coursera.org/learn/parprog1?specialization=scala,"We show how data parallel operations enable the development of elegant data-parallel code in Scala. We give an overview of the parallel collections hierarchy, including the traits of splitters and combiners that complement iterators and builders from the sequential case."
263,Data-Parallelism,4,https://www.coursera.org/learn/parprog1?specialization=scala,"We give a glimpse of the internals of data structures for parallel computing, which helps us understand what is happening under the hood of parallel collections."
264,Data Structures for Parallel Computing,4,https://www.coursera.org/learn/parprog1?specialization=scala,
265,Getting Started + Spark Basics,4,https://www.coursera.org/learn/scala-spark-big-data?specialization=scala,"This week, we'll look at a special kind of RDD called pair RDDs. With this specialized kind of RDD in hand, we'll cover essential operations on large data sets, such as reductions and joins."
266,Reduction Operations & Distributed Key-Value Pairs,4,https://www.coursera.org/learn/scala-spark-big-data?specialization=scala,"This week we'll look at some of the performance implications of using operations like joins. Is it possible to get the same result without having to pay for the overhead of moving data over the network? We'll answer this question by delving into how we can partition our data to achieve better data locality, in turn optimizing some of our Spark jobs."
267,Partitioning and Shuffling,4,https://www.coursera.org/learn/scala-spark-big-data?specialization=scala,"With our newfound understanding of the cost of data movement in a Spark job, and some experience optimizing jobs for data locality last week, this week we'll focus on how we can more easily achieve similar optimizations. Can structured data help us? We'll look at Spark SQL and its powerful optimizer which uses structure to apply impressive optimizations. We'll move on to cover DataFrames and Datasets, which give us a way to mix RDDs with the powerful automatic optimizations behind Spark SQL."
268,"Structured data: SQL, Dataframes, and Datasets",4,https://www.coursera.org/learn/scala-spark-big-data?specialization=scala,
269,"Week 1: Orientation, Introduction to Clouds, MapReduce ",5,https://www.coursera.org/learn/cloud-computing?specialization=cloud-computing,"Lesson 1: This module teaches how the multicast problem is solved by using epidemic/gossip protocols. It also teaches analysis of such protocols. Lesson 2: This module covers the design of failure detectors, a key component in any distributed system. Membership protocols, which use failure detectors as components, are also covered. Lesson 3: This module covers Grid computing, an important precursor to cloud computing."
270,"Week 2: Gossip, Membership, and Grids",5,https://www.coursera.org/learn/cloud-computing?specialization=cloud-computing,"P2P systems: This module teaches the detailed design of two classes of peer to peer systems: (a) popular ones including Napster, Gnutella, FastTrack, and BitTorrent; and (b) efficient ones including distributed hash tables (Chord, Pastry, and Kelips). Besides focusing on design, the module also analyzes these systems in detail."
271,Week 3: P2P Systems,5,https://www.coursera.org/learn/cloud-computing?specialization=cloud-computing,"Lesson 1: This module motivates and teaches the design of key-value/NoSQL storage/database systems. We cover the design of two major industry systems: Apache Cassandra and HBase. We also cover the famous CAP theorem.  Lesson 2: Distributed systems are asynchronous, which makes clocks at different machines hard to synchronize. This module first covers various clock synchronization algorithms, and then covers ways of tagging events with causal timestamps that avoid synchronizing clocks. These classical algorithms were invented decades ago, yet are used widely in today’s cloud systems."
272,"Week 4: Key-Value Stores, Time, and Ordering",5,https://www.coursera.org/learn/cloud-computing?specialization=cloud-computing,"Lesson 1: This module covers how to calculate a distributed snapshot, leveraging causality again to circumvent the synchronization problem. Lesson 2: This lecture teaches how to order multicasts in any distributed system. Algorithms for assigning timestamp tags to multicasts using various flavors of ordering – FIFO, Causal, and Total – are covered. The module also covers virtual synchrony, a paradigm that combines reliable multicasts with membership views.  Lesson 3: Consensus is one of the most important problems in a distributed system, enabling multiple machines to agree. This module uses Paxos, one of the most popular consensus solutions used in the industry today. Paxos is not perfect because consensus cannot be solved completely – an optional lecture presents the famous FLP proof of impossibility of consensus. "
273,Week 5: Classical Distributed Algorithms,5,https://www.coursera.org/learn/cloud-computing?specialization=cloud-computing,"The University of Illinois at Urbana-Champaign is a world leader in research, teaching and public engagement, distinguished by the breadth of its programs, broad academic excellence, and internationally renowned faculty and alumni. Illinois serves the world by creating knowledge, preparing students for lives of impact, and finding solutions to critical societal needs. "
274,Week 1: Course Orientation and Classical Distributed Algorithms Continued,5,https://www.coursera.org/learn/cloud-computing-2?specialization=cloud-computing,"Lesson 1: Transactions are an important component of many cloud systems today. This module presents building blocks to ensure transactions work as intended, from Remote Procedure Calls (RPCs), to serial equivalence for transactions, to optimistic and pessimistic approaches to concurrency control, to deadlock avoidance/prevention.  Lesson 2: This module covers how replication – maintaining copies of the same data at different locations – is used to provide many nines of availability in distributed systems, as well as different techniques for replication and for ensuring transactions commit correctly in spite of replication. "
275,Week 2: Concurrency and Replication Control,5,https://www.coursera.org/learn/cloud-computing-2?specialization=cloud-computing,"Lesson 1: We study the emerging area of stream processing, touching on key design aspects of Apache Storm.  Lesson 2: We study how enormous graphs can be processed in clouds. Lesson 3: We study various types of networks/graphs that are both natural and artificial, and their surprising commonalities.  Lesson 4: This module presents classical scheduling algorithms that have been used in operating systems since the inception of computers. We then cover two popular scheduling algorithms for Hadoop."
276,Week 3: Emerging Paradigms,5,https://www.coursera.org/learn/cloud-computing-2?specialization=cloud-computing,"Lesson 1: When files and directories are stored/accessed over the network, it is called a distributed file system. This module covers the working of distributed file systems like NFS and AFS. Lesson 2: This module covers Distributed Shared Memory systems, their techniques, and pros/cons.  Lesson 3: This module looks at the area of sensor networks, starting from what’s inside a sensor mote and how networks of them work."
277,Week 4: Classical Systems,5,https://www.coursera.org/learn/cloud-computing-2?specialization=cloud-computing,"Lesson 1: This module is a primer on basic security concepts, not just applied to distributed systems, but also more generally. We study various policies and mechanisms, including encryption, authentication, and authorization.  Lesson 2: This module presents case studies of real datacenter outages, and attempts to draw lessons on how to prevent them and how to better prepare for them. "
278,Week 5: Real-Life Behaviors,5,https://www.coursera.org/learn/cloud-computing-2?specialization=cloud-computing,"The University of Illinois at Urbana-Champaign is a world leader in research, teaching and public engagement, distinguished by the breadth of its programs, broad academic excellence, and internationally renowned faculty and alumni. Illinois serves the world by creating knowledge, preparing students for lives of impact, and finding solutions to critical societal needs. "
279,Course Orientation ,6,https://www.coursera.org/learn/cloud-applications-part1?specialization=cloud-computing,"Welcome to the first module of the course! In this module, we will introduce the concept of cloud computing and the economical foundations that make cloud computing make sense. We then introduce some fundamental concepts including software defined architectures and cloud services. We end the module by introducing you to the low level cloud computing service offered, infrastructure as a service. "
280,Module 1: Introduction to Cloud Computing,6,https://www.coursera.org/learn/cloud-applications-part1?specialization=cloud-computing,"Welcome to the second module! Here, we cover virtualization and containers with deeper focus, including lectures on Docker, JVM and Kubernates. We finish up week two by comparing the infrastructure as a service offering by the big three: Amazon, Google and Microsoft. "
281,"Module 2: Foundations: Containers, Virtual Machine, JVM",6,https://www.coursera.org/learn/cloud-applications-part1?specialization=cloud-computing,"Welcome to the third module, where we introduce Metal as a Service (provision real hardware in the cloud), Platform as a Service (provide a platform to run user code on) and Web Middleware as the glue technology that empowers cloud computing. "
282,"Module 3: MAAS, PAAS, Web Services",6,https://www.coursera.org/learn/cloud-applications-part1?specialization=cloud-computing,"Welcome to the last and final module of the cloud computing course! So far we have covered various methods of running certain computations on the cloud. Now it's time to focus on data storage in the clouds. In this module, we introduce big data and cloud file systems such as HDFS and Ceph, cloud object stores such has Open Stack Swift or Amazon S3, virtualized block storage devices such as Amazon EBS and archival storage options like the Amazon Glacier. Finally, we conclude the module with introducing the DropBox cloud API that enables developers to quickly integrate cloud storage options in their applications. "
283,"Module 4: Storage: Ceph, SWIFT, HDFS, NAAS, SAN, Zookeeper",6,https://www.coursera.org/learn/cloud-applications-part1?specialization=cloud-computing,You will find out where to go next after completing this course and be able to share any thoughts you have on this course experience.
284,Course Conclusion,6,https://www.coursera.org/learn/cloud-applications-part1?specialization=cloud-computing,"The University of Illinois at Urbana-Champaign is a world leader in research, teaching and public engagement, distinguished by the breadth of its programs, broad academic excellence, and internationally renowned faculty and alumni. Illinois serves the world by creating knowledge, preparing students for lives of impact, and finding solutions to critical societal needs. "
285,Course Orientation,5,https://www.coursera.org/learn/cloud-applications-part2?specialization=cloud-computing,"In Module 1, we introduce you to the world of Big Data applications. We start by introducing you to Apache Spark, a common framework used for many different tasks throughout the course. We then introduce some Big Data distro packages, the HDFS file system, and finally the idea of batch-based Big Data processing using the MapReduce programming paradigm. "
286,"Module 1: Spark, Hortonworks, HDFS, CAP",5,https://www.coursera.org/learn/cloud-applications-part2?specialization=cloud-computing,"In this module, you will learn about large scale data storage technologies and frameworks. We start by exploring the challenges of storing large data in distributed systems. We then discuss in-memory key/value storage systems, NoSQL distributed databases, and distributed publish/subscribe queues. "
287,Module 2: Large Scale Data Storage,5,https://www.coursera.org/learn/cloud-applications-part2?specialization=cloud-computing,"This module introduces you to real-time streaming systems, also known as Fast Data. We talk about Apache Storm in length, Apache Spark Streaming, and Lambda and Kappa architectures. Finally, we contrast all these technologies as a streaming ecosystem. "
288,Module 3: Streaming Systems,5,https://www.coursera.org/learn/cloud-applications-part2?specialization=cloud-computing,"In this module, we discuss the applications of Big Data. In particular, we focus on two topics: graph processing, where massive graphs (such as the web graph) are processed for information, and machine learning, where massive amounts of data are used to train models such as clustering algorithms and frequent pattern mining. We also introduce you to deep learning, where large data sets are used to train neural networks with effective results. "
289,Module 4: Graph Processing and Machine Learning,5,https://www.coursera.org/learn/cloud-applications-part2?specialization=cloud-computing,"The University of Illinois at Urbana-Champaign is a world leader in research, teaching and public engagement, distinguished by the breadth of its programs, broad academic excellence, and internationally renowned faculty and alumni. Illinois serves the world by creating knowledge, preparing students for lives of impact, and finding solutions to critical societal needs. "
290,Introduction to the Data and Machine Learning on Google Cloud Platform Specialization .,6,https://www.coursera.org/learn/gcp-big-data-ml-fundamentals?specialization=gcp-data-engineering,In this module you will have an existing Apache SparkML recommendation model that is running on-premise. You will learn about recommendation models and how you can run them in the cloud with Cloud Dataproc and Cloud SQL.
291,Recommending Products using Cloud SQL and Spark,6,https://www.coursera.org/learn/gcp-big-data-ml-fundamentals?specialization=gcp-data-engineering,"In this module, you will learn the foundations of BigQuery and big data analysis at scale. You will then learn how to build your own custom machine learning model to predict visitor purchases using just SQL with BigQuery ML. "
292,Predict Visitor Purchases with BigQuery ML,6,https://www.coursera.org/learn/gcp-big-data-ml-fundamentals?specialization=gcp-data-engineering,"In this module you will engineer and build an auto-scaling streaming data pipeline to ingest, process, and visualize data on a dashboard. Before you build your pipeline you'll learn the foundations of message-oriented architecture and pitfalls to avoid when designing and implementing modern data pipelines."
293,Create Streaming Data Pipelines with Cloud Pub/sub and Cloud Dataflow,6,https://www.coursera.org/learn/gcp-big-data-ml-fundamentals?specialization=gcp-data-engineering,Don't want to create a custom ML model from scratch? Learn how to leverage and extend pre-built ML models like the Vision API and Cloud AutoML for image classification.
294,Classify Images with Pre-Built Models using Vision API and Cloud AutoML,6,https://www.coursera.org/learn/gcp-big-data-ml-fundamentals?specialization=gcp-data-engineering,"In this final module, we will review the key challenges, solutions, and topics covered as part of this fundamentals course. We will also review additional resources and the steps you can take to get certified as a Google Cloud Data Engineer. "
295,Summary,6,https://www.coursera.org/learn/gcp-big-data-ml-fundamentals?specialization=gcp-data-engineering,"We help millions of organizations empower their employees, serve their customers, and build what’s next for their businesses with innovative technology created in—and for—the cloud. Our products are engineered for security, reliability, and scalability, running the full stack from infrastructure to applications to devices and hardware. Our teams are dedicated to helping customers apply our technologies to create success."
296,Introduction,5,https://www.coursera.org/learn/data-lakes-data-warehouses-gcp?specialization=gcp-data-engineering,This module describes the role of a data engineer and motivates the claim why data engineering should be done in the Cloud
297,Introduction to Data Engineering,5,https://www.coursera.org/learn/data-lakes-data-warehouses-gcp?specialization=gcp-data-engineering,"In this module, we describe what  data lake is and how to use Google Cloud Storage as you data lake on GCP"
298,Building a Data Lake,5,https://www.coursera.org/learn/data-lakes-data-warehouses-gcp?specialization=gcp-data-engineering,"In this module, we talk about BigQuery as a data warehousing option on GCP"
299,Building a data warehouse,5,https://www.coursera.org/learn/data-lakes-data-warehouses-gcp?specialization=gcp-data-engineering,This module reviews all the topics covered in the course
300,Summary,5,https://www.coursera.org/learn/data-lakes-data-warehouses-gcp?specialization=gcp-data-engineering,"We help millions of organizations empower their employees, serve their customers, and build what’s next for their businesses with innovative technology created in—and for—the cloud. Our products are engineered for security, reliability, and scalability, running the full stack from infrastructure to applications to devices and hardware. Our teams are dedicated to helping customers apply our technologies to create success."
301,Introduction,6,https://www.coursera.org/learn/batch-data-pipelines-gcp?specialization=gcp-data-engineering,"This module reviews different methods of data loading: EL, ELT and ETL and when to use what"
302,Introduction to Batch Data Pipelines,6,https://www.coursera.org/learn/batch-data-pipelines-gcp?specialization=gcp-data-engineering,"This module shows how to run Hadoop on Cloud Dataproc, how to leverage GCS, and how to optimize your Dataproc jobs."
303,Executing Spark on Cloud Dataproc,6,https://www.coursera.org/learn/batch-data-pipelines-gcp?specialization=gcp-data-engineering,This module shows how to manage data pipelines with Cloud Data Fusion and Cloud Composer.  
304,Manage Data Pipelines with Cloud Data Fusion and Cloud Composer	,6,https://www.coursera.org/learn/batch-data-pipelines-gcp?specialization=gcp-data-engineering,This module covers using Cloud Dataflow to build your data processing pipelines
305,Serverless Data Processing with Cloud Dataflow	,6,https://www.coursera.org/learn/batch-data-pipelines-gcp?specialization=gcp-data-engineering,This module reviews the topics covered in this course
306,Summary,6,https://www.coursera.org/learn/batch-data-pipelines-gcp?specialization=gcp-data-engineering,"We help millions of organizations empower their employees, serve their customers, and build what’s next for their businesses with innovative technology created in—and for—the cloud. Our products are engineered for security, reliability, and scalability, running the full stack from infrastructure to applications to devices and hardware. Our teams are dedicated to helping customers apply our technologies to create success."
307,Introduction,7,https://www.coursera.org/learn/streaming-analytics-systems-gcp?specialization=gcp-data-engineering,This modules talks about challenges with processing streaming data
308,Introduction to Processing Streaming Data,7,https://www.coursera.org/learn/streaming-analytics-systems-gcp?specialization=gcp-data-engineering,This module talks about using Cloud Pub/Sub to ingest incoming streaming data
309,Serverless Messaging with Cloud Pub/Sub,7,https://www.coursera.org/learn/streaming-analytics-systems-gcp?specialization=gcp-data-engineering,This module revisits Cloud Dataflow and focuses on its streaming data processing capabilities 
310,Cloud Dataflow Streaming Features,7,https://www.coursera.org/learn/streaming-analytics-systems-gcp?specialization=gcp-data-engineering,This modules covers BigQuery and Bigtable for streaming data
311,High-Throughput BigQuery and Bigtable Streaming Features,7,https://www.coursera.org/learn/streaming-analytics-systems-gcp?specialization=gcp-data-engineering,This module dives into more advanced features of BigQuery
312,Advanced BigQuery Functionality and Performance,7,https://www.coursera.org/learn/streaming-analytics-systems-gcp?specialization=gcp-data-engineering,This module recaps the topics covered in course
313,Summary,7,https://www.coursera.org/learn/streaming-analytics-systems-gcp?specialization=gcp-data-engineering,"We help millions of organizations empower their employees, serve their customers, and build what’s next for their businesses with innovative technology created in—and for—the cloud. Our products are engineered for security, reliability, and scalability, running the full stack from infrastructure to applications to devices and hardware. Our teams are dedicated to helping customers apply our technologies to create success."
314,Big Data Rankings & Products,6,https://www.coursera.org/learn/big-data-emerging-technologies,"The second module “Big Data & Hadoop” focuses on the characteristics and operations of Hadoop, which is the original big data system that was used by Google. The lectures explain the functionality of MapReduce, HDFS (Hadoop Distributed FileSystem), and the processing of data blocks. These functions are executed on a cluster of nodes that are assigned the role of NameNode or DataNodes, where the data processing is conducted by the JobTracker and TaskTrackers, which are explained in the lectures. In addition, the characteristics of metadata types and the differences in the data analysis processes of Hadoop and SQL (Structured Query Language) are explained. Then the Hadoop Release Series is introduced which include the descriptions of Hadoop YARN (Yet Another Resource Negotiator), HDFS Federation, and HDFS HA (High Availability) big data technology."
315,Big Data & Hadoop,6,https://www.coursera.org/learn/big-data-emerging-technologies,"The third module “Spark” focuses on the operations and characteristics of Spark, which is currently the most popular big data technology in the world. The lecture first covers the differences in data analysis characteristics of Spark and Hadoop, then goes into the features of Spark big data processing based on the RDD (Resilient Distributed Datasets), Spark Core, Spark SQL, Spark Streaming, MLlib (Machine Learning Library), and GraphX core units. Details of the features of Spark DAG (Directed Acyclic Graph) stages and pipeline processes that are formed based on Spark transformations and actions are explained. Especially, the definition and advantages of lazy transformations and DAG operations are described along with the characteristics of Spark variables and serialization. In addition, the process of Spark cluster operations based on Mesos, Standalone, and YARN are introduced."
316,Spark,6,https://www.coursera.org/learn/big-data-emerging-technologies,"The fourth module “Spark ML & Streaming” focuses on how Spark ML (Machine Learning) works and how Spark streaming operations are conducted. The Spark ML algorithms include featurization, pipelines, persistence, and utilities which operate on the RDDs (Resilient Distributed Datasets) to extract information form the massive datasets. The lectures explain the characteristics of the DataFrame-based API, which is the primary ML API in the spark.ml package. Spark ML basic statistics algorithms based on correlation and hypothesis testing (P-value) are first introduced followed by the Spark ML classification and regression algorithms based on linear models, naive Bayes, and decision tree techniques. Then the characteristics of Spark streaming, streaming input and output, as well as streaming receiver types (which include basic, custom, and advanced) are explained, followed by how the Spark Streaming process and DStream (Discretized Stream) enable big data streaming operations for real-time and near-real-time applications."
317,Spark ML & Streaming,6,https://www.coursera.org/learn/big-data-emerging-technologies,"The fifth module “Storm” focuses on the characteristics and operations of Storm big data systems. The lecture first covers the differences in data analysis characteristics of Storm, Spark, and Hadoop technology. Then the features of Storm big data processing based on the nimbus, spouts, and bolts are described followed by the Storm streams, supervisor, and ZooKeeper details. Further details on Storm reliable and unreliable spouts and bolts are provided followed by the advantages of Storm DAG (Directed Acyclic Graph) and data stream queue management. In addition, the advantages of using Storm based fast real-time applications, which include real-time analytics, online ML (Machine Learning), continuous computation, DRPC (Distributed Remote Procedure Call), and ETL (Extract, Transform, Load) are introduced."
318,Storm,6,https://www.coursera.org/learn/big-data-emerging-technologies,"The sixth and last module “IBM SPSS Statistics Project” focuses on providing experience on one of the most famous and widely used big data statistical analysis systems in the world. First, the lecture starts with how to setup and use IBM SPSS Statistics, and continues on to describe how IBM SPSS Statistics can be used to gain corporate data analysis experience. Then the data processing statistical results of two projects based on using the IBM SPSS Statistics big data system is conducted. The projects are conducted so the student can discover new ways to use, analyze, and draw charts of the relationship between datasets, and also compare the statistical results using IBM SPSS Statistics."
319,IBM SPSS Statistics Project,6,https://www.coursera.org/learn/big-data-emerging-technologies,"Yonsei University was established in 1885 and is the oldest private university in Korea.Yonsei’s main campus is situated minutes away from the economic, political, and cultural centers of Seoul’s metropolitan downtown. Yonsei has 3,500 eminent faculty members who are conducting cutting-edge research across all academic disciplines. There are 18 graduate schools, 22 colleges and 133 subsidiary institutions hosting a selective pool of students from around the world.

Yonsei is proud of its history and reputation as a leading institution of higher education and research in Asia."
320,Mobile Business Rankings & Analysis,6,https://www.coursera.org/learn/smart-device-mobile-emerging-technologies,"The second module “Smart Devices” focuses on the core technology and components of the world’s most popular smartphones (i.e., the Samsung Galaxy Note8 and and Apple iPhone X) and smart watches (i.e., Samsung Gear S3 and the Apple Watch Series 3). The state-of-the-art smartphones’ camera, battery, CPUs, GPUs, chipsets (e.g., Samsung Exynos Octa 8895, ARM big.LITTLE, Qualcomm MSM8998 Snapdragon 835, Apple A11 Bionic, Kryo 280, Adreno 540, Monsoon, and Mistral) characteristics are introduced, followed by a description of the functionality of thread based multi-core scheduling and processing, and relations with the smartphone OS (Operating System) Android and iOS. Then the IP (International Protection Marking) code that is used in protection level marking against solids and liquids of smart devices is described. To better understand the current technology level of CPUs, GPUs, and chip sets, the fundamentals of Moore’s law along with state-of-the-art 10 nm semiconductor technology and benefits of smaller transistors are explained. In addition, a description of the smart device sensors (e.g., accelerometer, gyro (gyroscope sensor), heart rate sensor, optical IR (infrared) light sensor, barometer, and pressure altimeters) along with the GPS (Global Positioning System) and A-GPS (Assisted GPS, based on MSA (Mobile Station Assisted) and MSB (Mobile Station Based)) operations are described. The lectures then cover the smart device display technology, which include shatterproof glass, gorilla glass, oleophobic coating, AMOLED (Active-Matrix Organic Light-Emitting Diode), OLED (Organic Light-Emitting Diode), Super AMOLED, Super AMOLED Plus, HD Super AMOLED, Full HD Super AMOLED, WQHD Super AMOLED, and other display technologies. The module then describes the characteristics of wireless charging technologies, including WPC (Wireless Power Consortium), Qi, PMA (Power Matters Alliance), A4WP (Alliance for Wireless Power), and the AirFuel Alliance. Through the lectures of this module, the level of the state-of-the-art smart devices, internal components, and performance limits are introduced."
321,Smart Devices,6,https://www.coursera.org/learn/smart-device-mobile-emerging-technologies,"The third module “Mobile Communications” focuses on the evolution and core technologies of mobile communications and the corresponding mobile phones. The lectures introduce the differences in the generations of the mobile communications evolution, starting with the 1G (first generation) AMPS (Advanced Mobile Phone System) analog wireless mobile technology. Then the beginning of the digital revolution in mobile communications is introduced in 2G (second generation) technology based on GSM (Global System for Mobile Communications), IS-95, and cdmaOne (which is based on CDMA (Code Division Multiple Access) technology). As GSM technology dominated the 2G mobile communications world, the key GSM features including GSM voice calls, data transfer, SMS (Short Message Service), and SIM (Subscriber Identity Module) card technology are introduced. Then the evolution to 3G (third generation) mobile communications technology is introduced based on UMTS (Universal Mobile Telecommunication System), WCDMA (Wideband CDMA), CDMA2000, CDMA2000 1xEV-DO, HSDPA (High Speed Downlink Packet Access), EV-DO Rev. A, HSPA+ (Evolved High Speed Packet Access), and EV-DO Rev. B (Evolution-Data Optimized Revision B) standards. Next, the current state-of-the-art in mobile communications, which is the 4G (fourth generation) technology based on LTE (Long-Term Evolution) and LTE-A (LTE-Advanced) is introduced."
322,Mobile Communications,6,https://www.coursera.org/learn/smart-device-mobile-emerging-technologies,"The fourth module “4G & 5G Mobile Technologies” focuses on the architecture, core technologies, and features of mobile communications 4G (fourth generation) and 5G (fifth generation) systems. In module 4, a special focus on 4G and 5G systems is made because this is where all the current investments, research, development, and new services are being made. First, the current state-of-the-art 4G LTE (Long-Term Evolution) and LTE-A (LTE-Advanced) technology performance requirements are introduced focusing on the data rates, spectral efficiency, spectrum flexibility, performance at cell edges, and number of simultaneously active subscribers. Next, the LTE architecture based on the EPS (Evolved Packet System), which includes the EPC (Evolved Packet Core) and E-UTRAN (Evolved Universal Terrestrial RAN), and the UE (User Equipment) is described. EPC elements (i.e., P-GW (Packet Data Network Gateway), S-GW (Serving Gateway), and MME (Mobility Management Entity)) and the features of LTE core technologies (e.g., seamless HO (Handover), packet forwarding, MBMS (Multimedia Broadcast Multicast Service), ICIC (Inter-Cell Interference Coordination), FFR (Fractional Frequency Reuse), DSA (Dynamic Subcarrier Assignment), CoMP (Coordinated Multi Point), CA (Carrier Aggregation), multi-RAT (Radio Access Technology), NOMA (Non-Orthogonal Multiple Access), advanced D2D (Device to Device), MIMO (Multiple Input Multiple Output), and OFDM (Orthogonal Frequency Division Multiplexing)) are introduced. Then the features of LTE HetNet (Heterogeneous Network), Small Cells, and SON (Self-Organizing Network) that include self-configuration and self-healing technology are explained. Next, the 5G standardization of ITU-R (ITU Radiocommunication Sector) IMT-2020 and 3GPP (3rd Generation Partnership Project) 5G NR are introduced and the differences in IMT 2020 5G target performance specifications compared to IMT Advanced based 4G LTE-A and IMT 2000 based 3G technology are discussed, followed by a description of the 3GPP 5G NR usage scenarios eMBB (enhanced Mobile BroadBand), URLLC (Ultra-Reliable and Low Latency Communication), and mMTC (massive Machine Type Communication). The 5G network architecture is introduced based on the NR (New Radio) access network and NGC (Next Generation Core), as well as the types of 5G deployment scenarios based on various NSA (Non-standalone) options. Then the flat, flexible, distributed, and sliced 5G network characteristics along with the enabling SDN (Software-Defined Network) and NFV (Network Function Virtualization) programmable technology is described. In addition, the advantages of 5G network slicing technology used to divide the 5G physical network into multiple virtual E2E (End-to-End) networks, which are logically isolated service dedicated network technology are introduced."
323,4G & 5G Mobile Technology,6,https://www.coursera.org/learn/smart-device-mobile-emerging-technologies,"The fifth module “Smartphone OSs” focuses on the characteristics and operations of the iOS and Android smartphone OSs (Operating Systems). First, the characteristics of the iOS evolution and features of the iOS 1, 1.1, 1.1.3, 2, 2.1, 2.2, 3, 3.2, 4, 4.2.5, 4.3, 5, 6, 7, 8, 9, 10, and 11 operating systems are introduced. Then the characteristics of the iOS and SDK (Software Development Kit) architecture, which consists of the Cocoa touch layer, Media services layer, Core services layer, Core OS layer, and the Kernel and Device Drivers are described. Secondly, the Android evolution versions with API (Application Programming Interface) levels are introduced, which include the Android 1.0 Alpha (API level 1), 1.1 Beta (API level 2), 1.5 Cupcake (API level 3), 1.6 Donut (API level 4) , 2.0 Eclair (API level 5), 2.2~2.2.3 Froyo (API level 8), 2.3~2.3.2 Gingerbread (API level 9), 3.0 Honeycomb (API level 11), 4.0~4.0.2 Ice Cream Sandwich, 4.1 Jelly Bean (API level 16), 4.4 KitKat (API level 19), 5.0~5.0.2 Lollipop (API level 21), 5.1 Lollipop (API level 22), 6.0 Marshmallow (API level 23), 7.0~7.1 Nougat (API level 24 / 25), and 8.0 Oreo (API level 26). Then the characteristics of the Android OS, middleware, and key applications are introduced. The description on the Android architecture covers all parts, which include the application, JAVA API framework, native C/C++ libraries, Android runtime, HAL (Hardware Abstraction Layer), and the Linux kernel. Among the Android sublayers, the features of the HAL is further described, which includes details on the standard interfaces for the higher-level Java API, framework to use the device’s hardware & processors, multiple library modules, and the customized support for hardware components along with the Bluetooth and camera module. In addition, the features of the Android’s Linux kernel that include the Linux kernel drivers, Android shared memory, power management, Wi-Fi, Bluetooth, and mobile communications components are introduced."
324,Smartphone OSs,6,https://www.coursera.org/learn/smart-device-mobile-emerging-technologies,"The sixth and last module “Smartphone & Mobile Network Project” focuses on methods and apps to analyze the components of smartphones and check the mobile network. In project 1, the Smartphone project, the status and components of both Android and iPhone smartphones are tested. Because the projects require for both Android and iPhone smartphones to be tested, the learner may need to borrow a smartphone (the type which you do not have) for a while to do the experiments, and after the project is done, erase the installed app(s) (and maybe recharge it) before returning the borrowed smartphone. In the Smartphone project, the smartphone types and the specs of the CPU, SoC, number of cores, memory types & sizes of each smartphone need to be reported and will be Peer Review evaluated. In project 2, the Mobile Network project, the details of the connected mobile network are to be observed. During the Mobile Network project, the learner will measure the PCI, RSSI, RSRP, RSRQ, RSSNR, ASU, and CQI values, and also find a location of where the largest number of Neighbor Base Stations, and how many were there, and report all details for Peer Review evaluation."
325,Smartphone & Mobile Network Project,6,https://www.coursera.org/learn/smart-device-mobile-emerging-technologies,"Yonsei University was established in 1885 and is the oldest private university in Korea.Yonsei’s main campus is situated minutes away from the economic, political, and cultural centers of Seoul’s metropolitan downtown. Yonsei has 3,500 eminent faculty members who are conducting cutting-edge research across all academic disciplines. There are 18 graduate schools, 22 colleges and 133 subsidiary institutions hosting a selective pool of students from around the world.

Yonsei is proud of its history and reputation as a leading institution of higher education and research in Asia."
326,IoT Business & Products,6,https://www.coursera.org/learn/iot-wireless-cloud-computing,"The second module “IoT Architecture & Technologies” focuses on the functionality and characteristics of the IoT architecture layers as well as the characteristics of IoT technologies, which include WSN (Wireless Sensor Networks), IoT cloud computing, IoT R&D (Research & Development), and IoT hardware technologies. Further details are provided in the descriptions of the characteristics of IoT sensors types, actuator types, and RFID types as well as the functionality and characteristics of IoT device platforms, which include the Arduino, Raspberry Pi, and BeagleBoard products. Next, a comparison of the representative IoT developer platform products is presented, which include the Raspberry Pi, Raspberry Pi 3 Model B, BeagleBoard, Beaglebone Black, and the Arduino systems Uno R3 (for entry and general purpose), Yun (for IoT), and Lilypad (for wearable). "
327,IoT Architecture & Technologies,6,https://www.coursera.org/learn/iot-wireless-cloud-computing,"The third module “IoT Networks” focuses on the functionality and characteristics of IoT wireless networks, the IoT network architecture, and wearable IoT networks. To describe the frequency requirements, the characteristics and requirements of the ISM (Industrial, Scientific and Medical) band are introduced. Next, the functionality and characteristics of IoT wireless communication technologies based on WLAN (Wireless Local Area Network), WPAN (Wireless Personal Area Network), and LPWAN (Low-Power Wide Area Network) are described. Then further details on WPAN (which include Bluetooth, ZigBee, 6LoWPAN, and IEEE 802.15.4 technology) and LPWAN (which include LoRa, UNB, Sigfox, and NB-IoT) are provided. In addition, the advantages of IoT and 5G mobile communication networks and the characteristics of mMTC (massive MTC) is covered. "
328,IoT Networks,6,https://www.coursera.org/learn/iot-wireless-cloud-computing,"The fourth module “Wi-Fi & Bluetooth” focuses on the details of Wi-Fi and Bluetooth technology. First, Wi-Fi technology and the WLAN (Wireless Local Area Network) market is introduced, followed by a description of the functionality of Wi-Fi transmission modes (which include the Infrastructure mode and the Ad-Hoc mode) and wireless APs (Access Points) as well as BSS (Basic Service Set) and ESS (Extended Service Set) network formations. The internal process of Wi-Fi operations and role of DCF (Distributed Coordination Function) and CSMA/CA (Carrier-Sense Multiple Access with Collision Avoidance) are described followed by the characteristics of Wi-Fi standards (which include the IEEE 802.11a, 11b, 11e, 11g, 11n, 11p, 11ac, 11ad, 11ah specifications), Wi-Fi PHY (Physical Layer) modulation schemes, as well as the IFS (Inter-Frame Space) types and how IFSs are used in priority access control. In addition, the advantages of Wi-Fi Dual Band and Wi-Fi Direct are introduced. Second, Bluetooth standards and feature evolution are introduced, which include the specifications from 1.1 to 5 including EDR (Enhanced Data Rate), HS (High Speed), BLE (Bluetooth Low Energy), and Beacon technology. The description incudes the characteristics of Bluetooth piconets and types of operations (which include Classic Bluetooth and BLE (Bluetooth Low Energy)) as well as the channel specifications, advertising, and connection events. "
329,Wi-Fi & Bluetooth,6,https://www.coursera.org/learn/iot-wireless-cloud-computing,"The fifth module “Cloud Technology” focuses on the Cloud market analysis, Cloud service types, MCC (Mobile Cloud Computing), and Edge Computing technology. Frist, the characteristics of the world’s top cloud companies and their services including AWS (Amazon Web Service), Microsoft, IBM, Google, and Apple's iCloud are introduced. Then the characteristics of cloud models, which include public cloud, private cloud, community cloud, and hybrid cloud are described along with the differences in cloud service models, which include SaaS (Software as a Service), PaaS (Platform as a Service), and IaaS (Infrastructure as a Service). Based on the service models, the benefits and characteristics of Cloud services are introduced. More details on the operation process are introduced, which include the IaaS and VM (Virtual Machine) administration, PaaS Runtime Environment for application support, and Open SaaS applications access processes. Then the relation between IoT and state-of-the-art mobile cloud technology is introduced. First the differences in MCC (Mobile Cloud Computing) and Edge Computing are described, which includes details on Fog computing, MEC (Mobile Edge Computing), and Cloudlet technology. In addition, the functionality and characteristics of the Cloudlet architecture and its 3 layers are covered. "
330,Cloud Technology,6,https://www.coursera.org/learn/iot-wireless-cloud-computing,"The sixth module “IoT Bluetooth & Wi-Fi & AWS EC2 Project” focuses on three IoT projects to provide experience in Bluetooth, Wi-Fi, and AWS (Amazon Web Service) EC2 (Elastic Compute Cloud) system details. The first project provides experience on the operation process of Bluetooth in Android and iPhone smartphones, teaching how to scan a Bluetooth packet and identify different Bluetooth versions being used on a smartphone. The second project provides experience on the operation process of Wi-Fi in Android and iPhone smartphones, teaching how to use a Wi-Fi network analyzer, conduct a LAN scan, send ping to a gateway, conduct a Wi-Fi signal scan, and use a Wi-Fi channel graph. The third project provides experience on how to setup an EC2 (Elastic Compute Cloud) Virtual Computer in AWS (Amazon Web Service) and how to use various options and compute a process on EC2 and use S3. "
331,IoT Bluetooth & Wi-Fi and EC2 Cloud Projects,6,https://www.coursera.org/learn/iot-wireless-cloud-computing,"Yonsei University was established in 1885 and is the oldest private university in Korea.Yonsei’s main campus is situated minutes away from the economic, political, and cultural centers of Seoul’s metropolitan downtown. Yonsei has 3,500 eminent faculty members who are conducting cutting-edge research across all academic disciplines. There are 18 graduate schools, 22 colleges and 133 subsidiary institutions hosting a selective pool of students from around the world.

Yonsei is proud of its history and reputation as a leading institution of higher education and research in Asia."
332,"AR Applications, Products & Business",7,https://www.coursera.org/learn/ar-technologies-video-streaming,"The second module “AR Technology” focuses on AR (Augmented Reality) technologies, operation workflow, and Cloud support technologies. First, the features of AR technological components, and the role of AR feature detection/description technology and the IPD (Interest Point Detection) process is introduced. Second the advantages of AR cloud cooperative computation and AR cloud offloading is covered. In addition, the types of AR feature extraction descriptor types, feature detector requirements, and influencing factors are covered. "
333,AR Technology,7,https://www.coursera.org/learn/ar-technologies-video-streaming,"The third module “SIFT SURF FAST BRIEF ORB BRISK” focuses on all of the core feature extraction technologies used in AR (Augmented Reality), which include SIFT, SURF, FAST, BRIEF, ORB, and BRISK. As feature extraction is the most important (and computation burdening and time consuming) procedure of the AR process, the variety of technologies applied in state-of-the-art AR devices are studied in detail in this module. The lectures cover the characteristics of the AR IPD (Interest Point Detection), feature detection, and description schemes, which include SIFT (Scale Invariant Feature Transform), SURF (Speed-Up Robust Feature), FAST (Features from Accelerated Segment Test), BRIEF (Binary Robust Independent Elementary Features), ORB (Oriented FAST and Rotated BRIEF), and BRISK (Binary Robust Invariant Scalable Keypoints)."
334,SIFT SURF FAST BRIEF ORB BRISK,7,https://www.coursera.org/learn/ar-technologies-video-streaming,"The fourth module “Skype, YouTube & H.264/MPEG-4 AVC” focuses on the two most famous video service types that exist in the World. Skype is the most widely used video conferencing and VoIP (Voice over IP) application service in the World, which is now included in various Microsoft products, making video and voice communications possible from practically anywhere an Internet connection is available. YouTube is the World’s most widely used video service application service. The lectures cover the history of Skype and YouTube and also the evolution of their video and audio codec technologies. In addition, the lecture covers the details of the state-of-the-art H.264/MPEG-4 AVC video media technology that is currently used by Skype and YouTube.  "
335,"Skype, YouTube & H.264/MPEG-4 AVC",7,https://www.coursera.org/learn/ar-technologies-video-streaming,"The fifth module “Video Streaming & MPEG-DASH” focuses on advanced video streaming techniques and details on MPEG-DASH (Moving Picture Experts Group - Dynamic Adaptive Streaming over HTTP) technology. First, the differences in Push vs. Pull based media streaming is covered along with the operation process of Pull based adaptive media streaming. Second, the types of video frames along with the structure of the fragmented MP4 file and GOP (Group of Pictures) are studied. Third, HTTP (Hypertext Transfer Protocol) versions 1.0~2 and the DASH scheme is explained followed by examples of the YouTube MPEG-DASH progressive downloading process. Fourth, the standardization of ISO/IEC 23009-1 based MPEG-DASH specifications and the operation process of MPEG-DASH MDP (Multimedia Presentation Description) hierarchical data and MPD decoding & playing methods are covered."
336,Video Streaming & MPEG-DASH,7,https://www.coursera.org/learn/ar-technologies-video-streaming,"The sixth module “CDN Video Streaming Technology” focuses on the necessity and operations of advanced video service CDN (Content Delivery Network) technologies. First, the CDN structure and the operation process of CDN hierarchical content delivery is covered. Second, the CDN market value, market size, service providers, and the role of the Telcos, CDN providers, operators, and market regions are studied. Third, details on CDN cooperative caching and content routing, Query based scheme, Digest based scheme, Directory based scheme, Hashing based scheme, and the Semi-hashing based scheme are covered. Fourth, content aging and updating operations along with CDN popularity prediction and contents update techniques (with operational examples of the LRU (Least Recently Used) and LFU (Least Frequently Used) strategies) are covered in the lectures. In addition, the differences in CDN vs. Mobile CDN technology are discussed. "
337,CDN Video Streaming Technology,7,https://www.coursera.org/learn/ar-technologies-video-streaming,"The seventh module “AR Smartphone Project” focuses on two AR smartphone projects using the IKEA Catalog and Google Translate applications. First the operation features of the IKEA Catalog and Google Translate AR applications are studies in the project. Second the limitations of the operation process of these AR applications are tested to recognize how the brightness levels, shined light angles, shape and size of the area and object, distance, font and texture types, and language translations types can influence the accuracy of the AR operations."
338,AR Smartphone Project,7,https://www.coursera.org/learn/ar-technologies-video-streaming,"Yonsei University was established in 1885 and is the oldest private university in Korea.Yonsei’s main campus is situated minutes away from the economic, political, and cultural centers of Seoul’s metropolitan downtown. Yonsei has 3,500 eminent faculty members who are conducting cutting-edge research across all academic disciplines. There are 18 graduate schools, 22 colleges and 133 subsidiary institutions hosting a selective pool of students from around the world.

Yonsei is proud of its history and reputation as a leading institution of higher education and research in Asia."
339,Introduction to specialization,6,https://www.coursera.org/learn/google-machine-learning?specialization=machine-learning-tensorflow-gcp,"You will learn what we mean when we say that Google’s company strategy is to be AI-first, and what that means in practice."
340,What it means to be AI first,6,https://www.coursera.org/learn/google-machine-learning?specialization=machine-learning-tensorflow-gcp,This module is about the organizational know-how Google has acquired over the years.
341,How Google does ML,6,https://www.coursera.org/learn/google-machine-learning?specialization=machine-learning-tensorflow-gcp,This module will discuss why machine learning systems aren’t fair by default and some of the things you have to keep in mind as you infuse ML into your products.
342,Inclusive ML,6,https://www.coursera.org/learn/google-machine-learning?specialization=machine-learning-tensorflow-gcp,"This module covers Cloud Datalab, which is the development environment you will use in this specialization."
343,Python notebooks in the cloud,6,https://www.coursera.org/learn/google-machine-learning?specialization=machine-learning-tensorflow-gcp,Review the core ML topics that this specialization will cover.
344,Summary,6,https://www.coursera.org/learn/google-machine-learning?specialization=machine-learning-tensorflow-gcp,"We help millions of organizations empower their employees, serve their customers, and build what’s next for their businesses with innovative technology created in—and for—the cloud. Our products are engineered for security, reliability, and scalability, running the full stack from infrastructure to applications to devices and hardware. Our teams are dedicated to helping customers apply our technologies to create success."
345,Introduction,5,https://www.coursera.org/learn/launching-machine-learning?specialization=machine-learning-tensorflow-gcp,"In this module, we will introduce some of the main types of machine learning and review the history of ML leading up to the state of the art so that you can accelerate your growth as an ML practitioner."
346,Practical ML,5,https://www.coursera.org/learn/launching-machine-learning?specialization=machine-learning-tensorflow-gcp,In this module we will walk you through how to optimize your ML models.
347,Optimization,5,https://www.coursera.org/learn/launching-machine-learning?specialization=machine-learning-tensorflow-gcp,Now it’s time to answer a rather weird question: when is the most accurate ML model not the right one to pick?  As we hinted at in the last module on Optimization -- simply because a model has a loss metric of 0 for your training dataset does not mean it will perform well on new data in the real world. 
348,Generalization and Sampling,5,https://www.coursera.org/learn/launching-machine-learning?specialization=machine-learning-tensorflow-gcp,
349,Summary,5,https://www.coursera.org/learn/launching-machine-learning?specialization=machine-learning-tensorflow-gcp,"We help millions of organizations empower their employees, serve their customers, and build what’s next for their businesses with innovative technology created in—and for—the cloud. Our products are engineered for security, reliability, and scalability, running the full stack from infrastructure to applications to devices and hardware. Our teams are dedicated to helping customers apply our technologies to create success."
350,Introduction,5,https://www.coursera.org/learn/intro-tensorflow?specialization=machine-learning-tensorflow-gcp,"We will introduce you to the core components of TensorFlow and you will get hands-on practice building machine learning programs. You will compare and write lazy evaluation and imperative programs, work with graphs, sessions, variables, as finally debug TensorFlow programs."
351,Core TensorFlow,5,https://www.coursera.org/learn/intro-tensorflow?specialization=machine-learning-tensorflow-gcp,In this module we will walk you through the Estimator API.
352,Estimator API,5,https://www.coursera.org/learn/intro-tensorflow?specialization=machine-learning-tensorflow-gcp,I’m here to talk about how you would go about taking your TensorFlow model and training it on GCP’s managed infrastructure for machine learning model training and deployed.
353,Scaling TensorFlow models,5,https://www.coursera.org/learn/intro-tensorflow?specialization=machine-learning-tensorflow-gcp,"Here we summarize the TensorFlow topics we covered so far in this course. We'll revisit core TensorFlow code, the Estimator API, and end with scaling your machine learning models with Cloud Machine Learning Engine."
354,Summary,5,https://www.coursera.org/learn/intro-tensorflow?specialization=machine-learning-tensorflow-gcp,"We help millions of organizations empower their employees, serve their customers, and build what’s next for their businesses with innovative technology created in—and for—the cloud. Our products are engineered for security, reliability, and scalability, running the full stack from infrastructure to applications to devices and hardware. Our teams are dedicated to helping customers apply our technologies to create success."
355,Introduction,6,https://www.coursera.org/learn/feature-engineering?specialization=machine-learning-tensorflow-gcp,"Feature engineering is often the longest and most difficult phase of building your ML project. In the feature engineering process, you start with your raw data and use your own domain knowledge to create features that will make your machine learning algorithms work. In this module we explore what makes a good feature and how to represent them in your ML model."
356,Raw Data to Features,6,https://www.coursera.org/learn/feature-engineering?specialization=machine-learning-tensorflow-gcp,This section of the module covers pre-processing and feature creation which are data processing techniques that can help you prepare a feature set for a machine learning system.
357,Preprocessing and Feature Creation,6,https://www.coursera.org/learn/feature-engineering?specialization=machine-learning-tensorflow-gcp,"In traditional machine learning, feature crosses don’t play much of a role, but in modern day ML methods, feature crosses are an invaluable part of your toolkit.In this module, you will learn how to recognize the kinds of problems where feature crosses are a powerful way to help machines learn."
358,Feature Crosses,6,https://www.coursera.org/learn/feature-engineering?specialization=machine-learning-tensorflow-gcp,"TensorFlow Transform (tf.Transform) is a library for preprocessing data with TensorFlow. tf.Transform is useful for preprocessing that requires a full pass the data, such as:

- normalizing an input value by mean and stdev
- integerizing a vocabulary by looking at all input examples for values
- bucketizing inputs based on the observed data distribution

In this module we will explore use cases for tf.Transform."
359,TF Transform,6,https://www.coursera.org/learn/feature-engineering?specialization=machine-learning-tensorflow-gcp,"Here we recap the major points you learned in each module on Feature Engineering: Selecting Good Features, Preprocessing at Scale, Using Feature Crosses, and Practicing with TensorFlow."
360,Summary,6,https://www.coursera.org/learn/feature-engineering?specialization=machine-learning-tensorflow-gcp,"We help millions of organizations empower their employees, serve their customers, and build what’s next for their businesses with innovative technology created in—and for—the cloud. Our products are engineered for security, reliability, and scalability, running the full stack from infrastructure to applications to devices and hardware. Our teams are dedicated to helping customers apply our technologies to create success."
361,Welcome to From ​Data ​to ​Insights ​with ​Google ​Cloud Platform: ​Exploring ​and ​Preparing ​your ​Data,6,https://www.coursera.org/learn/gcp-exploring-preparing-data-bigquery,Understand the core principles behind Google Cloud Platform and how to leverage them for big data analysis
362,Module 1: Introduction ​to ​Data ​on Google ​Cloud ​Platform,6,https://www.coursera.org/learn/gcp-exploring-preparing-data-bigquery,"Learn what are the key big data tools on Google Cloud Platform that you will be using to analyze, prepare, and visualize data"
363,Module 2: ​Big ​Data ​Tools ​Overview,6,https://www.coursera.org/learn/gcp-exploring-preparing-data-bigquery,Learn how to query your data with the basics of SQL (Structured Query Language) and practice writing queries in BigQuery
364,Module 3: ​Exploring ​your ​Data ​with SQL,6,https://www.coursera.org/learn/gcp-exploring-preparing-data-bigquery,Understand how pricing works in BigQuery and how you can best optimize your queries
365,Module 4: ​Google ​BigQuery ​Pricing,6,https://www.coursera.org/learn/gcp-exploring-preparing-data-bigquery,Understand the importance of creating high quality datasets and learn the tools that will help you transform your data
366,Module 5: ​Cleaning ​and ​Transforming your ​Data,6,https://www.coursera.org/learn/gcp-exploring-preparing-data-bigquery,"We help millions of organizations empower their employees, serve their customers, and build what’s next for their businesses with innovative technology created in—and for—the cloud. Our products are engineered for security, reliability, and scalability, running the full stack from infrastructure to applications to devices and hardware. Our teams are dedicated to helping customers apply our technologies to create success."
367,Introduction,6,https://www.coursera.org/learn/gcp-creating-bigquery-datasets-visualizing-insights,Create new permanent and temporary tables from your query results
368,Storing and Exporting Data,6,https://www.coursera.org/learn/gcp-creating-bigquery-datasets-visualizing-insights,Load and create new datasets inside BigQuery
369,Ingesting New Datasets into Google BigQuery,6,https://www.coursera.org/learn/gcp-creating-bigquery-datasets-visualizing-insights,Understand the differences between SQL JOINs and UNIONs and when to use each
370,Joining and Merging Datasets,6,https://www.coursera.org/learn/gcp-creating-bigquery-datasets-visualizing-insights,Compare data visualizations and learn how to use Google Data Studio
371,Data Visualization,6,https://www.coursera.org/learn/gcp-creating-bigquery-datasets-visualizing-insights,
372,End of Course Recap ,6,https://www.coursera.org/learn/gcp-creating-bigquery-datasets-visualizing-insights,"We help millions of organizations empower their employees, serve their customers, and build what’s next for their businesses with innovative technology created in—and for—the cloud. Our products are engineered for security, reliability, and scalability, running the full stack from infrastructure to applications to devices and hardware. Our teams are dedicated to helping customers apply our technologies to create success."
373,Introduction,8,https://www.coursera.org/learn/gcp-advanced-insights-bigquery,"Deepen your knowledge of SQL on BigQuery by learning about more advanced functions like statistical approximations, analytical window queries, user-defined functions, and WITH clauses."
374,Advanced Functions and Clauses,8,https://www.coursera.org/learn/gcp-advanced-insights-bigquery,Walkthrough the evolution of how traditional databases handle dataset scale and compare how BigQuery was developed to address scaling limitations. Deep dive into nested and repeated fields which are a key part of denormalized BigQuery data structures.
375,Schema Design and Nested Data Structures,8,https://www.coursera.org/learn/gcp-advanced-insights-bigquery,"Dive deeper into advanced visualization topics like dashboard calculated fields, filters, multi-page reports, and dashboard cache."
376,More Visualization with Google Data Studio,8,https://www.coursera.org/learn/gcp-advanced-insights-bigquery,Learn the fundamental pieces of work that impact BigQuery performance and how to optimize your queries for speed.
377,Optimizing for Performance,8,https://www.coursera.org/learn/gcp-advanced-insights-bigquery,Introducing Cloud Datalab -- a key tool in the Data Scientist toolkit -- which enables analysts to collaborate through the use of scalable cloud notebooks.
378,Advanced Insights with Cloud Datalab,8,https://www.coursera.org/learn/gcp-advanced-insights-bigquery,Securing and sharing your BigQuery datasets is critical for any organization. Learn what Google Cloud Platform and BigQuery tools are available to you to permission control and share your data. 
379,Data Access,8,https://www.coursera.org/learn/gcp-advanced-insights-bigquery,Congratulations! You have made it to the end. Let's recap what we have covered so far.
380,Summary,8,https://www.coursera.org/learn/gcp-advanced-insights-bigquery,"We help millions of organizations empower their employees, serve their customers, and build what’s next for their businesses with innovative technology created in—and for—the cloud. Our products are engineered for security, reliability, and scalability, running the full stack from infrastructure to applications to devices and hardware. Our teams are dedicated to helping customers apply our technologies to create success."
381,Introduction,6,https://www.coursera.org/learn/data-insights-gcp-apply-ml,"In this module, we define what Machine Learning is and how it can benefit your business. You'll see a few demos of ML in action and learn key ML terms like instances, features, and labels."
382,Introduction to Machine Learning,6,https://www.coursera.org/learn/data-insights-gcp-apply-ml,In this module we will dive into pre-built and pre-trained ML models that we can access (like image recognition and sentiment analysis) within Cloud Datalab. 
383,Pre-trained ML APIs,6,https://www.coursera.org/learn/data-insights-gcp-apply-ml,
384,Creating ​ML Datasets in BigQuery,6,https://www.coursera.org/learn/data-insights-gcp-apply-ml,"In this module, you will learn how to create machine learning models directly inside of BigQuery. You will learn the new syntax and work through the phases of building, evaluating, and testing an ML model."
385,Creating ML Models in BigQuery,6,https://www.coursera.org/learn/data-insights-gcp-apply-ml,You've made it to the end! Let's review the lessons learned in the course and what resources are available for continued learning.
386,End of Course Recap,6,https://www.coursera.org/learn/data-insights-gcp-apply-ml,"We help millions of organizations empower their employees, serve their customers, and build what’s next for their businesses with innovative technology created in—and for—the cloud. Our products are engineered for security, reliability, and scalability, running the full stack from infrastructure to applications to devices and hardware. Our teams are dedicated to helping customers apply our technologies to create success."
387,Week 1:  Introduction to Data Products,5,https://www.coursera.org/learn/basic-data-processing-visualization-python,"This week, we will learn how to load in datasets from CSV and JSON files. We will also practice manipulating data from these datasets with basic Python commands."
388,Week 2: Reading Data in Python,5,https://www.coursera.org/learn/basic-data-processing-visualization-python,"This week, our goal is to understand how to clean up a dataset before analyzing it. We will go over how to work with different types of  data, such as strings and dates."
389,Week 3: Data Processing in Python,5,https://www.coursera.org/learn/basic-data-processing-visualization-python,"In this last week, we will get a sense of common libraries in Python and how they can be useful. We will cover data visualization with numpy and MatPlotLib, and also introduce you to the basics of webscraping with urllib and BeautifulSoup."
390,Week 4: Python Libraries and Toolkits,5,https://www.coursera.org/learn/basic-data-processing-visualization-python,"Create your own Jupyter notebook with a dataset of your own choosing and practice data manipulation. Show off the skills you've learned and the libraries you know about in this project. We hope you enjoyed the course, and best of luck in your future learning!"
391,Final Project,5,https://www.coursera.org/learn/basic-data-processing-visualization-python,"UC San Diego is an academic powerhouse and economic engine, recognized as one of the top 10 public universities by U.S. News and World Report. Innovation is central to who we are and what we do. Here, students learn that knowledge isn't just acquired in the classroom—life is their laboratory."
392,Week 1: Supervised Learning & Regression,5,https://www.coursera.org/learn/design-thinking-predictive-analytics-data-products,"This week, we will learn what features are in a dataset and how we can work with them through cleaning, manipulation, and analysis in Jupyter notebooks."
393,Week 2: Features ,5,https://www.coursera.org/learn/design-thinking-predictive-analytics-data-products,"This week, we will learn about classification and several ways you can implement it, such as K-nearest neighbors, logistic regression, and support vector machines."
394,Week 3: Classification,5,https://www.coursera.org/learn/design-thinking-predictive-analytics-data-products,"This week, we will learn the importance of properly training and testing a model. We will also implement gradient descent in both Python and TensorFlow."
395,Week 4: Gradient Descent,5,https://www.coursera.org/learn/design-thinking-predictive-analytics-data-products,"In the final week of this course, you will continue building on the project from the first course of Python Data Products for Predictive Analytics with simple predictive machine learning algorithms. Find a dataset, clean it, and perform basic analyses on the data."
396,Final Project,5,https://www.coursera.org/learn/design-thinking-predictive-analytics-data-products,"UC San Diego is an academic powerhouse and economic engine, recognized as one of the top 10 public universities by U.S. News and World Report. Innovation is central to who we are and what we do. Here, students learn that knowledge isn't just acquired in the classroom—life is their laboratory."
397,Week 1: Diagnostics for Data,4,https://www.coursera.org/learn/meaningful-predictive-modeling,"This week, we will learn how to create a simple bag of words for analysis. We will also cover regularization and why it matters when building a model. Lastly, we will evaluate a model with regularization, focusing on classifiers."
398,"Week 2: Codebases, Regularization, and Evaluating a Model",4,https://www.coursera.org/learn/meaningful-predictive-modeling,"This week, we will learn about validation and how to implement it in tandem with training and testing. We will also cover how to implement a regularization pipeline in Python and introduce a few guidelines for best practices."
399,Week 3: Validation and Pipelines,4,https://www.coursera.org/learn/meaningful-predictive-modeling,"In the final week of this course, you will continue building on the project from the first and second courses of Python Data Products for Predictive Analytics with simple predictive machine learning algorithms. Find a dataset, clean it, and perform basic analyses on the data. Evaluate your model, validate your analyses, and make sure you aren't overfitting the data."
400,Final Project,4,https://www.coursera.org/learn/meaningful-predictive-modeling,"UC San Diego is an academic powerhouse and economic engine, recognized as one of the top 10 public universities by U.S. News and World Report. Innovation is central to who we are and what we do. Here, students learn that knowledge isn't just acquired in the classroom—life is their laboratory."
401,Introduction,5,https://www.coursera.org/learn/deploying-machine-learning-models,"This week, we will learn how to implement a similarity-based recommender, returning predictions similar to an user's given item. We will cover how to optimize these models based on gradient descent and Jaccard similarity."
402,Implementing Recommender Systems,5,https://www.coursera.org/learn/deploying-machine-learning-models,"This week, we will learn about Python web server frameworks and the overall structure of interactive Python data applications. We will also cover some tips for best practices on deploying and monitoring your applications."
403,Deploying Recommender Systems,5,https://www.coursera.org/learn/deploying-machine-learning-models,"For this final project, you will build a recommender system of your own. Find a dataset, clean it, and create a predictive system from the dataset. This will help prepare you for the upcoming capstone, where you will harness your skills from all courses of this specialization into one single project!"
404,Project 4: Recommender System,5,https://www.coursera.org/learn/deploying-machine-learning-models,"Time to put all your hard work to the test! This capstone project consists of four components, each drawing from a separate course in this specialization. It's time to show off everything you've learned from this specialization."
405,Capstone,5,https://www.coursera.org/learn/deploying-machine-learning-models,"UC San Diego is an academic powerhouse and economic engine, recognized as one of the top 10 public universities by U.S. News and World Report. Innovation is central to who we are and what we do. Here, students learn that knowledge isn't just acquired in the classroom—life is their laboratory."
406,Introducing Google Cloud Platform,9,https://www.coursera.org/learn/gcp-fundamentals,"GCP customers use projects to organize the resources they use. They use Google Cloud Identity and Access Management, also called “IAM,” to control who can do what with those resources. They use any of several technologies to connect with GCP. This module covers each of these topics, and it introduces a service called Cloud Launcher that is an easy way to get started with GCP."
407,Getting Started with Google Cloud Platform,9,https://www.coursera.org/learn/gcp-fundamentals,"Compute Engine lets you run virtual machines on Google’s global infrastructure. This module covers how Compute Engine works, with a focus on Google virtual networking. "
408,Virtual Machines in the Cloud,9,https://www.coursera.org/learn/gcp-fundamentals,"Every application needs to store data. Different applications and workloads require different storage and database solutions. This module describes and differentiates among GCP's core storage options: Cloud Storage, Cloud SQL, Cloud Spanner, Cloud Datastore, and Google Bigtable."
409,Storage in the Cloud,9,https://www.coursera.org/learn/gcp-fundamentals,"Containers are simple and interoperable, and they enable seamless, fine-grained scaling. Kubernetes is an orchestration layer for containers. Kubernetes Engine is Kubernetes as a service, a scalable managed offering that runs on Google’s infrastructure. You direct the creation of a cluster, and Kubernetes Engine schedules your containers into the cluster and manages them automatically, based on requirements you define. This module explains how Kubernetes Engine works and how it helps deploy applications in containers."
410,Containers in the Cloud,9,https://www.coursera.org/learn/gcp-fundamentals,"App Engine is a Platform-as-a-Service (""PaaS"") offering. The App Engine platform manages the hardware and networking infrastructure required to run your code. App Engine provides built-in services that many web applications need. This module describes how App Engine works."
411,Applications in the Cloud,9,https://www.coursera.org/learn/gcp-fundamentals,"Popular tools for development, deployment, and monitoring just work in GCP. Customers also have options for tools in each of these three areas that are tightly integrated with GCP. This module covers those tools."
412,"Developing, Deploying and Monitoring in the Cloud",9,https://www.coursera.org/learn/gcp-fundamentals,GCP's big-data and machine learning offerings are intended to help customers get the most out of data. These tools are intended to be simple and practical to embed in your applications. This module describes the available big-data and machine learning services and explains the usefulness of each.
413,Big Data and Machine Learning in the Cloud,9,https://www.coursera.org/learn/gcp-fundamentals,"This module reviews the GCP services covered in this course and reminds learners of the differences among them. The module compares GCP compute services, GCP storage services, and important Google VPC networking capabilities."
414,Summary and Review,9,https://www.coursera.org/learn/gcp-fundamentals,"We help millions of organizations empower their employees, serve their customers, and build what’s next for their businesses with innovative technology created in—and for—the cloud. Our products are engineered for security, reliability, and scalability, running the full stack from infrastructure to applications to devices and hardware. Our teams are dedicated to helping customers apply our technologies to create success."
415,Course introduction,4,https://www.coursera.org/learn/foundations-google-kubernetes-engine-gke,"This module helps you start off with the right framework of concepts. After a review of fundamentals cloud computing, you will learn about how GCP’s resources around the world are organized into regions and zones. You'll also learn how you can organize the resources you use in GCP, so that you can manage them. Finally, you'll meet the tools that let you connect to GCP and allocate, change, and release resources."
416,Introduction to Google Cloud Platform,4,https://www.coursera.org/learn/foundations-google-kubernetes-engine-gke,In this module you will learn about software containers and their benefits are for application deployment. You'll configure and build containers. You'll also learn about the functions container that management solutions like Kubernetes provide. You'll encounter the advantages of Google Kubernetes Engine compared to building your own container-management infrastructure.  
417,Containers and Kubernetes in GCP,4,https://www.coursera.org/learn/foundations-google-kubernetes-engine-gke,In this module you’ll learn the components of a Kubernetes cluster and how they work together. You'll deploy a Kubernetes cluster using Google Kubernetes Engine and deploy Pods to a GKE cluster. You'll also view and manage several very useful kinds of Kubernetes objects.
418,Kubernetes Architecture,4,https://www.coursera.org/learn/foundations-google-kubernetes-engine-gke,"We help millions of organizations empower their employees, serve their customers, and build what’s next for their businesses with innovative technology created in—and for—the cloud. Our products are engineered for security, reliability, and scalability, running the full stack from infrastructure to applications to devices and hardware. Our teams are dedicated to helping customers apply our technologies to create success."
419,Course introduction,5,https://www.coursera.org/learn/deploying-workloads-google-kubernetes-engine-gke,"In this module you will learn about the kubectl command, which is the command line utility used to interact with and manage the resources inside Kubernetes clusters. You'll learn how to connect it to Google Kubernetes Engine clusters, and use it to create, inspect, interact and delete Pods and other objects within Kubernetes clusters. You'll also use kubectl to view a Pod’s console output, and sign in interactively to a Pod."
420,Kubernetes Operations,5,https://www.coursera.org/learn/deploying-workloads-google-kubernetes-engine-gke,"GKE works with containerized applications: in other words, applications packaged into hardware-independent, isolated user-space instances. In GKE and Kubernetes, these packaged applications are collectively called workloads. In this module you will learn about Deployments and Jobs, two of the main types of workload. You will also learn about the mechanisms that are used to scale the GKE clusters where you run your applications. You'll learn to control on which Nodes Pods may and may not run. You'll also explore ways to get software into your cluster. "
421,"Deployments, Jobs, and Scaling",5,https://www.coursera.org/learn/deploying-workloads-google-kubernetes-engine-gke,"In this module, you’ll learn how to create Services to expose applications running within Pods, which allows them to communicate with the outside world. You'll also learn how to create Ingress resources for HTTP or HTTPS load balancing. You'll also learn about GKE's container-native load balancing, which allows you to directly configure Pods as network endpoints with Google Cloud Load Balancing. "
422,Google Kubernetes Engine Networking,5,https://www.coursera.org/learn/deploying-workloads-google-kubernetes-engine-gke,"In this module you’ll learn about the different types of Kubernetes storage abstractions. You’ll learn about StatefulSets and how to use them to manage ordered deployments of Pods and storage. You’ll also learn how ConfigMaps can save you time during application deployment by decoupling configuration artifacts from container definitions. Finally, you’ll learn how to keep sensitive information safer from accidental exposure using Kubernetes Secrets."
423,Persistent Data and Storage,5,https://www.coursera.org/learn/deploying-workloads-google-kubernetes-engine-gke,"We help millions of organizations empower their employees, serve their customers, and build what’s next for their businesses with innovative technology created in—and for—the cloud. Our products are engineered for security, reliability, and scalability, running the full stack from infrastructure to applications to devices and hardware. Our teams are dedicated to helping customers apply our technologies to create success."
424,Course Introduction,4,https://www.coursera.org/learn/deploying-secure-kubernetes-containers-in-production,"In this module, you will learn about Kubernetes authentication and authorization, in order to control who is able to perform what actions to resources in your GKE clusters. Using what you learn in this module will help you ensure that appropriate access policies are in place to make your cluster and applications more secure."
425,Access Control and Security in Kubernetes and GKE,4,https://www.coursera.org/learn/deploying-secure-kubernetes-containers-in-production,"In this module you will learn how logging is implemented in Kubernetes, and how GKE extends that basic functionality using Stackdriver, which is a suite of multi-cloud resource reconnaissance tools provided by Google. You'll learn to locate and inspect Kubernetes logs produced by resources inside your GKE clusters. You’ll learn how to use Stackdriver to monitor and manage the availability and performance of your GCP resources, and also the applications that are built with those resources. You'll also learn to use Stackdriver and Google Bigquery for longer term retention and forensic analysis of logs. You'll learn how to create probes for wellness checks on the applications you’re running."
426,GKE Logging and Monitoring,4,https://www.coursera.org/learn/deploying-secure-kubernetes-containers-in-production,"In this module, you’ll learn about the pros and cons of managed storage services versus self-managed containerized storage for your applications. You'll identify use cases for Cloud Storage for applications running in a Kubernetes cluster, and you'll survey the range of GCP managed database services. You'll learn how to use the Cloud SQL Proxy to simplify the task of connecting from within Kubernetes applications to Cloud SQL, one of those services."
427,Using GCP Managed Storage Services with GKE,4,https://www.coursera.org/learn/deploying-secure-kubernetes-containers-in-production,"We help millions of organizations empower their employees, serve their customers, and build what’s next for their businesses with innovative technology created in—and for—the cloud. Our products are engineered for security, reliability, and scalability, running the full stack from infrastructure to applications to devices and hardware. Our teams are dedicated to helping customers apply our technologies to create success."
428,Introducing Google Cloud Platform,9,https://www.coursera.org/learn/gcp-fundamentals,"GCP customers use projects to organize the resources they use. They use Google Cloud Identity and Access Management, also called “IAM,” to control who can do what with those resources. They use any of several technologies to connect with GCP. This module covers each of these topics, and it introduces a service called Cloud Launcher that is an easy way to get started with GCP."
429,Getting Started with Google Cloud Platform,9,https://www.coursera.org/learn/gcp-fundamentals,"Compute Engine lets you run virtual machines on Google’s global infrastructure. This module covers how Compute Engine works, with a focus on Google virtual networking. "
430,Virtual Machines in the Cloud,9,https://www.coursera.org/learn/gcp-fundamentals,"Every application needs to store data. Different applications and workloads require different storage and database solutions. This module describes and differentiates among GCP's core storage options: Cloud Storage, Cloud SQL, Cloud Spanner, Cloud Datastore, and Google Bigtable."
431,Storage in the Cloud,9,https://www.coursera.org/learn/gcp-fundamentals,"Containers are simple and interoperable, and they enable seamless, fine-grained scaling. Kubernetes is an orchestration layer for containers. Kubernetes Engine is Kubernetes as a service, a scalable managed offering that runs on Google’s infrastructure. You direct the creation of a cluster, and Kubernetes Engine schedules your containers into the cluster and manages them automatically, based on requirements you define. This module explains how Kubernetes Engine works and how it helps deploy applications in containers."
432,Containers in the Cloud,9,https://www.coursera.org/learn/gcp-fundamentals,"App Engine is a Platform-as-a-Service (""PaaS"") offering. The App Engine platform manages the hardware and networking infrastructure required to run your code. App Engine provides built-in services that many web applications need. This module describes how App Engine works."
433,Applications in the Cloud,9,https://www.coursera.org/learn/gcp-fundamentals,"Popular tools for development, deployment, and monitoring just work in GCP. Customers also have options for tools in each of these three areas that are tightly integrated with GCP. This module covers those tools."
434,"Developing, Deploying and Monitoring in the Cloud",9,https://www.coursera.org/learn/gcp-fundamentals,GCP's big-data and machine learning offerings are intended to help customers get the most out of data. These tools are intended to be simple and practical to embed in your applications. This module describes the available big-data and machine learning services and explains the usefulness of each.
435,Big Data and Machine Learning in the Cloud,9,https://www.coursera.org/learn/gcp-fundamentals,"This module reviews the GCP services covered in this course and reminds learners of the differences among them. The module compares GCP compute services, GCP storage services, and important Google VPC networking capabilities."
436,Summary and Review,9,https://www.coursera.org/learn/gcp-fundamentals,"We help millions of organizations empower their employees, serve their customers, and build what’s next for their businesses with innovative technology created in—and for—the cloud. Our products are engineered for security, reliability, and scalability, running the full stack from infrastructure to applications to devices and hardware. Our teams are dedicated to helping customers apply our technologies to create success."
437,Welcome to Managing Security in Google Cloud Platform,6,https://www.coursera.org/learn/managing-security-in-google-cloud-platform,"Securing systems is a hot topic and should be a priority for everyone today - and, as you will see, it is definitely a priority here at Google. In this module we will introduce you to GCP’s approach to security. We will also discuss the shared security responsibility model, which is a collaborative effort between Google and its users.  Next, we will outline several threats that are mitigated for you when your systems are run on Google’s infrastructure in GCP.  And, finally, we will end with a section on access transparency."
438,Foundations of GCP Security,6,https://www.coursera.org/learn/managing-security-in-google-cloud-platform,"In this module we will discuss Cloud Identity, a service which makes it easy to manage cloud users, devices, and apps from one console.  We will also discuss a few related features to help reduce the operational overhead of managing GCP users, such as the Google Cloud Directory Sync and Single Sign-On. We will end with some authentication best practices."
439,Cloud Identity,6,https://www.coursera.org/learn/managing-security-in-google-cloud-platform,"Cloud Identity and Access Management (or Cloud IAM as it is known) lets administrators authorize who can take action on specific resources, giving you full control and visibility to manage your cloud resources centrally. More specifically, we will cover; the Resource Manager which enables you to centrally manage projects, folders, and organizations, IAM roles and policies, including custom roles, and Cloud IAM best practices, including separation of duties and the principle of least privilege."
440,Identity and Access Management (IAM),6,https://www.coursera.org/learn/managing-security-in-google-cloud-platform,"Managed networking on GCP utilizes a Virtual Private Cloud (or VPC). In this module we will discuss VPC related security concepts including: VPC firewalls, load balancing SSL policies, network Interconnect & peering options, VPC network best practices and VPC flow logs. You will also have the opportunity to practice what you’ve learned, by completing the labs exercises “Configuring VPC Firewalls” and “Using and Viewing VPC Flow Logs in Stackdriver.”  "
441,VPCs for Isolation and Security,6,https://www.coursera.org/learn/managing-security-in-google-cloud-platform,"Collecting, processing, aggregating, and displaying real-time quantitative data is helpful in supplying raw input into business analytics and in facilitating analysis of security breaches. GCP provides many services and features to help with this - and that is what this module is all about.In this module we will investigate Stackdriver monitoring and logging, cloud audit logging, and then discuss how to leverage Forseti Security to systematically monitor your GCP resources."
442,StackDriver and Scanning,6,https://www.coursera.org/learn/managing-security-in-google-cloud-platform,"We help millions of organizations empower their employees, serve their customers, and build what’s next for their businesses with innovative technology created in—and for—the cloud. Our products are engineered for security, reliability, and scalability, running the full stack from infrastructure to applications to devices and hardware. Our teams are dedicated to helping customers apply our technologies to create success."
443,Welcome to Mitigating Security Vulnerabilities on Google Cloud Platform,6,https://www.coursera.org/learn/mitigating-security-vulnerabilites-gcp,"In this module we will start with a discussion of service accounts, IAM roles and API scopes as they apply to compute engine. We will also discuss managing VM logins, and how to use organization policies to set constraints that apply to all resources in your organization's hierarchy. Next, we will review compute engine best practices to give you some tips for securing compute engine.Lastly, we will cover encrypting persistent disks with Customer Supplied Encryption keys."
444,Securing Compute Engine,6,https://www.coursera.org/learn/mitigating-security-vulnerabilites-gcp,"In this module we discuss controlling IAM permissions and access control lists on Cloud Storage buckets, auditing cloud data, including finding and remediating data that has been set to publicly accessible, how to use signed Cloud Storage URLs  and signed policy documents, and encrypting data at rest.  In addition, BigQuery IAM roles and authorized views will be covered to demonstrate managing access to datasets and tables. The module will conclude with an overview of storage best practices."
445,Securing Cloud Data,6,https://www.coursera.org/learn/mitigating-security-vulnerabilites-gcp,Distributed Denial of Service Attacks are a major concern today and can have a huge impact on businesses if the business is not adequately prepared. In this module we will begin with a quick discussion on how DDoS attacks work and then review some DDoS mitigation techniques that are provided by the Google Cloud Platform.  We will finish up with a review of complementary partner products and a lab where you will get a chance to see some DDoS mitigations in action.
446,Protecting against Distributed Denial of Service Attacks (DDoS),6,https://www.coursera.org/learn/mitigating-security-vulnerabilites-gcp,"In this module we will discuss application security techniques and best practices. We will see how the Google Cloud Security scanner can be used to identify vulnerabilities in your applications, and dive into the subject of Identity and Oauth phishing. Lastly, you will learn how the Google Cloud Identity-Aware Proxy or IAP can be used to control access to your cloud applications."
447,Application Security,6,https://www.coursera.org/learn/mitigating-security-vulnerabilites-gcp,"In this module we will discuss threats to your content.  First, we review the threat of ransomware, and some of the mitigations you can utilize in GCP to help protect your systems from it.  Then we will move to a discussion of threats related to data misuse and privacy violations and discuss a few mitigation strategies that can be utilized to protect applications and systems. "
448,Content-Related Vulnerabilities,6,https://www.coursera.org/learn/mitigating-security-vulnerabilites-gcp,"We help millions of organizations empower their employees, serve their customers, and build what’s next for their businesses with innovative technology created in—and for—the cloud. Our products are engineered for security, reliability, and scalability, running the full stack from infrastructure to applications to devices and hardware. Our teams are dedicated to helping customers apply our technologies to create success."
449,Introducing Google Cloud Platform,9,https://www.coursera.org/learn/gcp-fundamentals,"GCP customers use projects to organize the resources they use. They use Google Cloud Identity and Access Management, also called “IAM,” to control who can do what with those resources. They use any of several technologies to connect with GCP. This module covers each of these topics, and it introduces a service called Cloud Launcher that is an easy way to get started with GCP."
450,Getting Started with Google Cloud Platform,9,https://www.coursera.org/learn/gcp-fundamentals,"Compute Engine lets you run virtual machines on Google’s global infrastructure. This module covers how Compute Engine works, with a focus on Google virtual networking. "
451,Virtual Machines in the Cloud,9,https://www.coursera.org/learn/gcp-fundamentals,"Every application needs to store data. Different applications and workloads require different storage and database solutions. This module describes and differentiates among GCP's core storage options: Cloud Storage, Cloud SQL, Cloud Spanner, Cloud Datastore, and Google Bigtable."
452,Storage in the Cloud,9,https://www.coursera.org/learn/gcp-fundamentals,"Containers are simple and interoperable, and they enable seamless, fine-grained scaling. Kubernetes is an orchestration layer for containers. Kubernetes Engine is Kubernetes as a service, a scalable managed offering that runs on Google’s infrastructure. You direct the creation of a cluster, and Kubernetes Engine schedules your containers into the cluster and manages them automatically, based on requirements you define. This module explains how Kubernetes Engine works and how it helps deploy applications in containers."
453,Containers in the Cloud,9,https://www.coursera.org/learn/gcp-fundamentals,"App Engine is a Platform-as-a-Service (""PaaS"") offering. The App Engine platform manages the hardware and networking infrastructure required to run your code. App Engine provides built-in services that many web applications need. This module describes how App Engine works."
454,Applications in the Cloud,9,https://www.coursera.org/learn/gcp-fundamentals,"Popular tools for development, deployment, and monitoring just work in GCP. Customers also have options for tools in each of these three areas that are tightly integrated with GCP. This module covers those tools."
455,"Developing, Deploying and Monitoring in the Cloud",9,https://www.coursera.org/learn/gcp-fundamentals,GCP's big-data and machine learning offerings are intended to help customers get the most out of data. These tools are intended to be simple and practical to embed in your applications. This module describes the available big-data and machine learning services and explains the usefulness of each.
456,Big Data and Machine Learning in the Cloud,9,https://www.coursera.org/learn/gcp-fundamentals,"This module reviews the GCP services covered in this course and reminds learners of the differences among them. The module compares GCP compute services, GCP storage services, and important Google VPC networking capabilities."
457,Summary and Review,9,https://www.coursera.org/learn/gcp-fundamentals,"We help millions of organizations empower their employees, serve their customers, and build what’s next for their businesses with innovative technology created in—and for—the cloud. Our products are engineered for security, reliability, and scalability, running the full stack from infrastructure to applications to devices and hardware. Our teams are dedicated to helping customers apply our technologies to create success."
458,Welcome to Networking in GCP: Defining and Implementing Networks,5,https://www.coursera.org/learn/networking-gcp-defining-implementing-networks,"In this module, we're going to cover the fundamentals of Virtual Private Cloud (VPC) networking in Google Cloud Platform (GCP). This includes the different types of VPC objects, Internal DNS, Cloud DNS, IP aliases and VMs with multiple network interfaces."
459,Module 1: Google Cloud VPC Networking Fundamentals	,5,https://www.coursera.org/learn/networking-gcp-defining-implementing-networks,"In this module, we're going to cover ways to control access to VPC Networks. This includes Cloud Identity and Access Management (Cloud IAM) and firewall rules."
460,Module 2: Controlling Access to VPC Networks,5,https://www.coursera.org/learn/networking-gcp-defining-implementing-networks,"In this module, we are going to cover two configurations for sharing VPC networks across GCP projects. First, we will go over Shared VPC which allows you to share a network across several projects in your GCP organization. Then, we will go over VPC Network Peering which allows you to configure private communication across projects in the same or different organizations. "
461,Module 3: Sharing Networks across Projects,5,https://www.coursera.org/learn/networking-gcp-defining-implementing-networks,"In this module, we are going to cover the five different types of load balancers that are available in GCP. We will also go over managed instance groups, Cloud Armor and Cloud CDN."
462,Module 4: Load Balancing,5,https://www.coursera.org/learn/networking-gcp-defining-implementing-networks,"We help millions of organizations empower their employees, serve their customers, and build what’s next for their businesses with innovative technology created in—and for—the cloud. Our products are engineered for security, reliability, and scalability, running the full stack from infrastructure to applications to devices and hardware. Our teams are dedicated to helping customers apply our technologies to create success."
463,Welcome to Networking in GCP: Hybrid Connectivity and Network Management ,5,https://www.coursera.org/learn/networking-gcp-hybrid-connectivity-network-management,"In this module, we are going to cover the GCP interconnect and peering services available to connect your infrastructure to GCP. These services are Dedicated Interconnect, Partner Interconnect, IPsec VPN, Direct Peering and Carrier Peering. "
464,Module 1: Hybrid Connectivity,5,https://www.coursera.org/learn/networking-gcp-hybrid-connectivity-network-management,"In this module, we are going to cover how GCP networking features are charged for, how to leverage Network Service Tiers to optimize your spend and how to administer billing within GCP."
465,Module 2: Networking Pricing and Billing,5,https://www.coursera.org/learn/networking-gcp-hybrid-connectivity-network-management,"In this module, we are going to explain some common network designs, automate the deployment of networks using Deployment Manager and launch networking solutions using Cloud Marketplace."
466,Module 3: Network Design and Deployment,5,https://www.coursera.org/learn/networking-gcp-hybrid-connectivity-network-management,"In this module, we are going to cover network monitoring and logging features that can help you troubleshoot your GCP network infrastructure."
467,Module 4: Network Monitoring and Troubleshooting,5,https://www.coursera.org/learn/networking-gcp-hybrid-connectivity-network-management,"We help millions of organizations empower their employees, serve their customers, and build what’s next for their businesses with innovative technology created in—and for—the cloud. Our products are engineered for security, reliability, and scalability, running the full stack from infrastructure to applications to devices and hardware. Our teams are dedicated to helping customers apply our technologies to create success."
468,Course Introduction,11,https://www.coursera.org/learn/database-management?specialization=data-warehousing,"We’ll launch into an exploration of databases and database technology and their impact on organizations in Module 2. We’ll investigate database characteristics, database technology features, including non-procedural access, two key processing environments, and an evolution of the database software industry. This short informational module will ensure that we all have the same background and context, which is critical for success in the later modules that emphasize details and hands-on skills."
469,Introduction to Databases and DBMSs,11,https://www.coursera.org/learn/database-management?specialization=data-warehousing,"Now that you have the informational context for database features and environments, you’ll start building! In this module, you’ll learn relational data model terminology, integrity rules, and the CREATE TABLE statement. You’ll apply what you’ve learned in practice and graded problems using a database management system (DBMS), either Oracle or MySQL, creating tables using the SQL CREATE TABLE statement and populating your tables using given SQL INSERT statements."
470,Relational Data Model and the CREATE TABLE Statement,11,https://www.coursera.org/learn/database-management?specialization=data-warehousing,"This module is all about acquiring query formulation skills. Now that you know the relational data model and have basic skills with the CREATE TABLE statement, we can cover basic syntax of the SQL SELECT statement and the join operator for combining tables. SELECT statement examples are presented for single table conditions, join operations, and grouping operations. You’ll practice writing simple SELECT statements using the tables that you created in the assignment for module 3."
471,Basic Query Formulation with SQL,11,https://www.coursera.org/learn/database-management?specialization=data-warehousing,"Now that you can identify and use the SELECT statement and the join operator, you’ll extend your problem solving skills in this module so you can gain confidence on more complex queries. You will work on retrieval problems with multiple tables and grouping. In addition, you’ll learn to use the UNION operator in the SQL SELECT statement and write SQL modification statements."
472,Extended Query Formulation with SQL,11,https://www.coursera.org/learn/database-management?specialization=data-warehousing,"Module 6 represents another shift in your learning. In previous modules, you’ve created and populated tables and developed query formulation skills using the SQL SELECT statement. Now you’ll start to develop skills that allow you to create a database design to support business requirements. You’ll learn basic notation used in entity relationship diagrams (ERDs), a graphical notation for data modeling. You will create simple ERDs using basic diagram symbols and relationship variations to start developing your data modeling skills. "
473,Notation for Entity Relationship Diagrams,11,https://www.coursera.org/learn/database-management?specialization=data-warehousing,Module 7 builds on your knowledge of database development using basic ERD symbols and relationship variations. We’ll be practicing precise usage of ERD notation and basic problem solving skills. You will learn about diagram rules and work problems to help you gain confidence using and creating ERDs.
474,ERD Rules and Problem Solving,11,https://www.coursera.org/learn/database-management?specialization=data-warehousing,"In Module 8, you’ll use your ERD notation skills and your ability to avoid diagram errors to develop ERDs that satisfy specific business data requirements. You will learn and practice powerful problem-solving skills as you analyze narrative statements and transformations to generate alternative ERDs."
475,Developing Business Data Models,11,https://www.coursera.org/learn/database-management?specialization=data-warehousing,"Now that you have practiced data modeling techniques, you’ll get to wrestle with narrative problem analyses and transformations for generating alternative database designs in Module 9. At the end of this module, you’ll learn guidelines for documentation and detection of design errors that will serve you well as you design databases for business situations."
476,Data Modeling Problems and Completion of an ERD,11,https://www.coursera.org/learn/database-management?specialization=data-warehousing,"Modules 6 to 9 covered conceptual data modeling, emphasizing precise usage of ERD notation, analysis of narrative problems, and generation of alternative designs. Modules 10 and 11 cover logical database design, the next step in the database development process. In Module 10, we’ll cover schema conversion, the first step in the logical database design phase. You will learn to convert an ERD into a table design that can be implemented on a relational DBMS."
477,Schema Conversion,11,https://www.coursera.org/learn/database-management?specialization=data-warehousing,"Module 11 covers normalization, the second part of the logical database design process. Normalization provides tools to remove unwanted redundancy in a table design. You’ll discover the motivation for normalization, constraints to reason about unwanted redundancy, and rules that detect excessive redundancy in a table design. You’ll practice integrating and applying normalization techniques in the final lesson of this course."
478,Normalization Concepts and Practice,11,https://www.coursera.org/learn/database-management?specialization=data-warehousing,"The University of Colorado is a recognized leader in higher education on the national and global stage.  We collaborate to meet the diverse needs of our students and communities.  We promote innovation, encourage discovery and support the extension of knowledge in ways unique to the state of Colorado and beyond."
479,Data Warehouse Concepts and Architectures,6,https://www.coursera.org/learn/dwdesign?specialization=data-warehousing,"Now that you have the informational context for data warehouse development, you’ll start using data warehouse tools! In module 2, you will learn about the multidimensional representation of a data warehouse used by business analysts. You’ll apply what you’ve learned in practice and graded problems using WebPivotTable or Pivot4J, open source tools for manipulating pivot tables. At the end of this module, you will have solid background to communicate and assist business analysts who use a multidimensional representation of a data warehouse. After completing this module, you should proceed to module 3 to complete an assignment and quiz with either WebPivotTable or Pivot4J. Because Pivot4J can be difficult to install, I recommend completing the assignment and quiz using WebPivotTable."
480,Multidimensional Data Representation and Manipulation,6,https://www.coursera.org/learn/dwdesign?specialization=data-warehousing,"Choice 1 and 2: If completing the WebPivotTable assignment (choice 1), you should also complete the WebPivotTable quiz (choice 2). | Choice 3 and 4: If completing the Pivot4J assignment (choice 3), you should also complete the Pivot4J quiz (choice 4). Due to potential difficulty with installing Pivot4J, I recommend that you complete the WebPivotTable assignment and quiz."
481,Multidimensional Data Representation and Manipulation: Lesson Choices,6,https://www.coursera.org/learn/dwdesign?specialization=data-warehousing,"This module emphasizes data warehouse design skills. Now that you understand the multidimensional representation used by business analysts, you are ready to learn about data warehouse design using a relational database. In practice, the multidimensional representation used by business analysts must be derived from a data warehouse design using a relational DBMS.You will learn about design patterns, summarizability problems, and design methodologies. You will apply these concepts to mini case studies about data warehouse design. At the end of the module, you will have created data warehouse designs based on data sources and business needs of hypothetical organizations."
482,Data Warehouse Design Practices and Methodologies,6,https://www.coursera.org/learn/dwdesign?specialization=data-warehousing,"Module 4 extends your background about data warehouse development. After learning about schema design concepts and practices, you are ready to learn about data integration processing to populate and refresh a data warehouse. The informational background in module 4 covers concepts about data sources, data integration processes, and techniques for pattern matching and inexact matching of text. Module 4 provides a context for the software skills that you will learn in module 5. "
483,"Data Integration Concepts, Processes,and Techniques ",6,https://www.coursera.org/learn/dwdesign?specialization=data-warehousing,"Module 5 extends your background about data integration from module 4. Module 5 covers architectures, features, and details about data integration tools to complement the conceptual background in module 4. You will learn about the features of two open source data integration tools, Talend Open Studio and Pentaho Data Integration. You will use Pentaho Data Integration in guided tutorial in preparation for a graded assignment involving Pentaho Data Integration."
484,"Architectures, Features, and Details of Data Integration Tools",6,https://www.coursera.org/learn/dwdesign?specialization=data-warehousing,"The University of Colorado is a recognized leader in higher education on the national and global stage.  We collaborate to meet the diverse needs of our students and communities.  We promote innovation, encourage discovery and support the extension of knowledge in ways unique to the state of Colorado and beyond."
485,DBMS Extensions and Example Data Warehouses,5,https://www.coursera.org/learn/dwrelational?specialization=data-warehousing,"Now that you have the informational context for relational database support of data warehouses, you’ll start using relational databases to write business intelligence queries! In module 2, you will learn an important extension of the SQL SELECT statement for subtotal operators. You’ll apply what you’ve learned in practice and graded problems using Oracle SQL for problems involving the CUBE, ROLLUP, and GROUPING SETS operators. Because the subtotal operators are part of the SQL standard, your learning will readily apply to other enterprise DBMSs. At the end of this module, you will have solid background to write queries using the SQL subtotal operators as a data warehouse analyst."
486,SQL Subtotal Operators,5,https://www.coursera.org/learn/dwrelational?specialization=data-warehousing,"After your experience using the SQL subtotal operators, you are ready to learn another important SQL extension for business intelligence applications. In module 3, you will learn about an extended processing model for SQL analytic functions that support common analysis in business intelligence applications. You’ll apply what you’ve learned in practice and graded problems using Oracle SQL for problems involving qualitative ranking of business units, window comparisons showing relationships of business units over time, and quantitative contributions showing performance thresholds and contributions of individual business units to a whole business. Because analytic functions are part of the SQL standard, your learning will apply to other enterprise DBMSs. At the end of this module, you will have solid background to write queries using the SQL analytic functions as a data warehouse analyst."
487,SQL Analytic Functions,5,https://www.coursera.org/learn/dwrelational?specialization=data-warehousing,"After acquiring query formulation skills for development of business intelligence applications, you are ready to learn about DBMS extensions for efficient query execution. Business intelligence queries can use lots of resources so materialized view processing and design has become an important extension of DBMSs. In module 4, you will learn about an SQL statement for creating materialized views, processing requirements for materialized views, and rules for rewriting queries using materialized views. To gain insight about the complexity of query rewriting, you will practice rewriting queries using materialized views. To provide closure about relational database support for data warehouses, you will learn about about Oracle tools for data integration, the Oracle Data Integrator, along with two SQL statements useful for specific data integration tasks. After this module, you will have a solid background to use materialized views to improve query performance and deploy the Extraction, Loading, and Transformation approach for data integration as a data warehouse administrator or analyst."
488,Materialized View Processing and Design,5,https://www.coursera.org/learn/dwrelational?specialization=data-warehousing,"Module 5 finishes the course with a return to conceptual material about physical design technologies and data governance practices. You will learn about storage architectures, scalable parallel processing, big data issues, and data governance. After this module, you will have background about conceptual issues important for data warehouse administrators."
489,Physical Design and Governance,5,https://www.coursera.org/learn/dwrelational?specialization=data-warehousing,"The University of Colorado is a recognized leader in higher education on the national and global stage.  We collaborate to meet the diverse needs of our students and communities.  We promote innovation, encourage discovery and support the extension of knowledge in ways unique to the state of Colorado and beyond."
490,Decision Making and Decision Support Systems,5,https://www.coursera.org/learn/business-intelligence-tools?specialization=data-warehousing,"Now that you understand the conceptual foundation of decision making and DSS, in module 2 we start by defining business intelligence (BI), BI architecture, and its components, and relate them to DSS.  In lesson 2, you will learn the main components of  BI platforms, their capabilities, and understand the competitive landscape of BI platforms. In lesson 3, you will learn the building blocks of business reports, the types of business reports, and the components and structure of business reporting systems. Finally, in lesson 4, you will learn different types of OLAP and their applications and comprehend the differences between OLAP and OLTP. You will need to use MicroStrategy Desktop to create effective and compelling data visualizations to analyze data and acquire insights into business practices in a peer-evaluated exercise. "
491,Business Intelligence Concepts and Platform Capabilities,5,https://www.coursera.org/learn/business-intelligence-tools?specialization=data-warehousing,"This module continues on the top job responsibilities of BI analysts by focusing on creating data visualizations and dashboards. You will first learn the importance of data visualization and different types of data that can be visually represented. You will then learn about the types of basic and composite charts. This will help you to determine which visualization is most effective to display data for a given data set and to identify best practices for designing data visualizations. In lesson 3, you will learn the common characteristics of a dashboard, the types of dashboards, and the list attributes of metrics usually included in dashboards. Finally, in lesson 4, you will learn the guidelines for designing dashboard and the common pitfalls of dashboard design. You will need to use MicroStrategy  Desktop Visual Insight to design a dashboard for a Financial Services company in a peer-evaluated exercise."
492,Data Visualization and Dashboard Design,5,https://www.coursera.org/learn/business-intelligence-tools?specialization=data-warehousing,"This module focuses on how BI is used for Business Performance Management (BPM). You will learn the main components of BPM as well as the four phases of BPM cycle and how organizations typically deploy BPM. In lesson 2, you will learn the purpose of Performance Measurement System and how organizations need to define the key performance indicators (KPIs) for their performance management system. In lesson 3, you will learn the four balanced scorecards perspectives and the differences between dashboards and scorecards. You will also be able to compare and contrast the benefits of using balanced scorecard versus using Six Sigma in a performance measurement system. Finally, in lesson 4, you will learn the role of visual and business analytics (BA) in BI and how various forms of BA are supported in practice. At the end of the module, you will apply these concepts to create a dashboard, blend it with external datasets, and explore various visualization capabilities to find insights faster in a peer-evaluated exercise."
493, Business Performance Management Systems,5,https://www.coursera.org/learn/business-intelligence-tools?specialization=data-warehousing,"Module 5 covers BI maturity and strategy. You will learn different levels of BI maturity, the factors that impact BI maturity within an organization, and the main challenges and the potential solutions for a pervasive BI maturity within an organization. The last lesson will focus on the critical success factors for implementing a BI strategy, BI framework, and BI implementation targets. Finally, in your summative project, you will use MicroStrategy visual analytics capabilities to analyze KPIs for a fast food company to find the causes for problems ."
494,"BI Maturity, Strategy, and Summative Project",5,https://www.coursera.org/learn/business-intelligence-tools?specialization=data-warehousing,"The University of Colorado is a recognized leader in higher education on the national and global stage.  We collaborate to meet the diverse needs of our students and communities.  We promote innovation, encourage discovery and support the extension of knowledge in ways unique to the state of Colorado and beyond."
495,The Big Picture,2,https://www.coursera.org/learn/digital-manufacturing-design?specialization=digital-manufacturing-design-technology,"The University at Buffalo (UB) is a premier, research-intensive public university and the largest, most comprehensive institution of the State University of New York (SUNY) system. UB offers more than 100 undergraduate degrees and nearly 300 graduate and professional programs."
496,Components of the Paradigm,2,https://www.coursera.org/learn/digital-manufacturing-design?specialization=digital-manufacturing-design-technology,"The State University of New York, with 64 unique institutions, is the largest comprehensive system of higher education in the United States. Educating nearly 468,000 students in more than 7,500 degree and certificate programs both on campus and online, SUNY has nearly 3 million alumni around the globe."
497,Digital Thread Defined,3,https://www.coursera.org/learn/digital-thread-components?specialization=digital-manufacturing-design-technology,"The purpose of this module is to explain factors impacting the ability of organizations to share data (internally and externally).  Upon completion of the module, learners will be able to evaluate data sharing strategies and point out potential strengths and weaknesses of different approaches. Details of individual lessons in this module are provided below"
498,Data Storage in the Digital Thread,3,https://www.coursera.org/learn/digital-thread-components?specialization=digital-manufacturing-design-technology,"The University at Buffalo (UB) is a premier, research-intensive public university and the largest, most comprehensive institution of the State University of New York (SUNY) system. UB offers more than 100 undergraduate degrees and nearly 300 graduate and professional programs."
499,Data Sharing and The Digital Thread,3,https://www.coursera.org/learn/digital-thread-components?specialization=digital-manufacturing-design-technology,"The State University of New York, with 64 unique institutions, is the largest comprehensive system of higher education in the United States. Educating nearly 468,000 students in more than 7,500 degree and certificate programs both on campus and online, SUNY has nearly 3 million alumni around the globe."
500,Strategic issues in implementing the digital thread,5,https://www.coursera.org/learn/digital-thread-implementation?specialization=digital-manufacturing-design-technology,The purpose of this module is to discuss individual digital analysis tools used in the design process. Details of individual lessons in this module are provided below.
501,Cyberinfrastructure Components of the Digital Thread,5,https://www.coursera.org/learn/digital-thread-implementation?specialization=digital-manufacturing-design-technology,The purpose of this module is to introduce the growing number of digital tools available to support manufacturing operations. Details of individual lessons in this module are provided below.
502,Technologies used in the Design Process,5,https://www.coursera.org/learn/digital-thread-implementation?specialization=digital-manufacturing-design-technology,The purpose of this module is to introduce how a digital thread implementation impacts the design and manufacturing enterprise. Details of individual lessons in this module are provided below.
503,Digital Thread on the Shop Floor,5,https://www.coursera.org/learn/digital-thread-implementation?specialization=digital-manufacturing-design-technology,"The University at Buffalo (UB) is a premier, research-intensive public university and the largest, most comprehensive institution of the State University of New York (SUNY) system. UB offers more than 100 undergraduate degrees and nearly 300 graduate and professional programs."
504,Digital Thread and the Manufacturing Enterprise,5,https://www.coursera.org/learn/digital-thread-implementation?specialization=digital-manufacturing-design-technology,"The State University of New York, with 64 unique institutions, is the largest comprehensive system of higher education in the United States. Educating nearly 468,000 students in more than 7,500 degree and certificate programs both on campus and online, SUNY has nearly 3 million alumni around the globe."
505,Introduction to Advanced Manufacturing Process Analysis,3,https://www.coursera.org/learn/advanced-manufacturing-process-analysis?specialization=digital-manufacturing-design-technology,"The purpose of this module is to introduce various techniques used in advanced analysis, like Determination of Significant Variables/Factors, Data Visualization, and Anomaly Detection. Also, this module will introduce various computational platforms (HPC, Cloud computing techniques) that exist for carrying out advanced analysis."
506,Data Collection,3,https://www.coursera.org/learn/advanced-manufacturing-process-analysis?specialization=digital-manufacturing-design-technology,"The University at Buffalo (UB) is a premier, research-intensive public university and the largest, most comprehensive institution of the State University of New York (SUNY) system. UB offers more than 100 undergraduate degrees and nearly 300 graduate and professional programs."
507,Data Analysis: Computational Techniques and Platforms,3,https://www.coursera.org/learn/advanced-manufacturing-process-analysis?specialization=digital-manufacturing-design-technology,"The State University of New York, with 64 unique institutions, is the largest comprehensive system of higher education in the United States. Educating nearly 468,000 students in more than 7,500 degree and certificate programs both on campus and online, SUNY has nearly 3 million alumni around the globe."
508,Computational Social Science (CSS),4,https://www.coursera.org/learn/computational-social-science-methods?specialization=computational-social-science-ucdavis,"In this module, you will be presented with an example of how computational social science is applied in the real world through a case study. You will be able to discuss examples of digital footprint and describe how computational social science is applied. You will practice an activity and be able to configure a machine to create a database that can later be used for analysis."
509,Example of Computational Social Science: Data Science,4,https://www.coursera.org/learn/computational-social-science-methods?specialization=computational-social-science-ucdavis,"In this module, you will be able to discover how artificial intelligence can convert news stories into a real-time observatory of global unrest and potential terror attacks, and how brain scans can be used to reveal aspects of your moral values. You will be able to practice interacting with artificial intelligence that can interpret your art skills."
510,Examples of CSS: Machine Learning & AI,4,https://www.coursera.org/learn/computational-social-science-methods?specialization=computational-social-science-ucdavis,"In this module, you will be able to discover how social networks and human dynamics create systems that are larger than you and me: social systems. You will be able to discuss how social networks and human dynamics follow recognizable patterns. You will be able to identify how social network analysis and computer simulations are currently quite successful in untangling some of the mysteries of social emergence. "
511,Examples of CSS: Social Networks and Computer Simulations,4,https://www.coursera.org/learn/computational-social-science-methods?specialization=computational-social-science-ucdavis,"UC Davis, one of the nation’s top-ranked research universities, is a global leader in agriculture, veterinary medicine, sustainability, environmental and biological sciences, and technology. With four colleges and six professional schools, UC Davis and its students and alumni are known for their academic excellence, meaningful public service and profound international impact."
512,Getting Started and Big Data Opportunities,4,https://www.coursera.org/learn/big-data-ai-ethics?specialization=computational-social-science-ucdavis,"In this module, you will be able to explain the limitations of big data. You will work with an AI interface, IBM Watson, and discover how AI can identify personality through Natural Language Processing. You will analyze the personality of a person."
513,Big Data Limitations,4,https://www.coursera.org/learn/big-data-ai-ethics?specialization=computational-social-science-ucdavis,"In this module, you will discover the history of artificial intelligence (AI) and its fields of study. You'll be able to examine how AI is used through case studies. You will be able to discuss the application of AI and you will use AI to create a unique artifact through a hands-on exercise."
514,Artificial Intelligence,4,https://www.coursera.org/learn/big-data-ai-ethics?specialization=computational-social-science-ucdavis,"In this module, you will be able to define the term research ethics. You will be able to examine the role ethics plays in conducting research. You will be able to discuss how ethics is applied when using AI and big data."
515,Research Ethics ,4,https://www.coursera.org/learn/big-data-ai-ethics?specialization=computational-social-science-ucdavis,"UC Davis, one of the nation’s top-ranked research universities, is a global leader in agriculture, veterinary medicine, sustainability, environmental and biological sciences, and technology. With four colleges and six professional schools, UC Davis and its students and alumni are known for their academic excellence, meaningful public service and profound international impact."
516,Getting Started and Formalizing Networks,5,https://www.coursera.org/learn/social-network-analysis?specialization=computational-social-science-ucdavis,"In this module, you will be able to discuss the structure of networks and be able to explain how a person can be the center of one. You will be able to discover the different types of language that networks use and be able to identify the three types of network measurements."
517,Social Network Analysis,5,https://www.coursera.org/learn/social-network-analysis?specialization=computational-social-science-ucdavis,"In this module, you will begin with a social network analysis lab activity. You will be able to do data wrangling of databases and visualize a network. You will be able to analyze a social network and also be able to examine other social network analysis through case studies."
518,Analyzing a Network with Software,5,https://www.coursera.org/learn/social-network-analysis?specialization=computational-social-science-ucdavis,"In this module, you will be able to identify the different types of social networks. You will be able to discuss what mechanisms generates these different types of networks and you will be able to explain how networks move from being static to dynamic."
519,Network Evolution,5,https://www.coursera.org/learn/social-network-analysis?specialization=computational-social-science-ucdavis,"In this module, you will be able to examine theoretical predictions of networks. You will be able to calculate basic math problems and be able to discuss how to make networks more efficient and stable."
520,Growing Networks and Making Predictions,5,https://www.coursera.org/learn/social-network-analysis?specialization=computational-social-science-ucdavis,"UC Davis, one of the nation’s top-ranked research universities, is a global leader in agriculture, veterinary medicine, sustainability, environmental and biological sciences, and technology. With four colleges and six professional schools, UC Davis and its students and alumni are known for their academic excellence, meaningful public service and profound international impact."
521,Getting Started and Computer Simulations,4,https://www.coursera.org/learn/computer-simulations?specialization=computational-social-science-ucdavis,"In this module, you will be able to identify how to mix different models to create new and more complex models. You will be able to explore how to create sophisticated versions of artificial societies. You'll also be able to examine an artificial society called Sugarscape."
522,Artificial Societies: Sugarscape,4,https://www.coursera.org/learn/computer-simulations?specialization=computational-social-science-ucdavis,"In this module, you will be able to discover how one uses computer simulations to solve practical problems. You will be able to discuss agent-based models (ABM) and identify how ABM can be used in social science."
523,Computer Simulations and Characteristics of ABM,4,https://www.coursera.org/learn/computer-simulations?specialization=computational-social-science-ucdavis,"In this module, you will be able to describe what agent-based models are. You will be able to identify their capabilities and limitations. You will be able to define and use vocabulary and terminology around model thinking. You'll also be able to code using NetLogo and be able to grow your own artificial society."
524,Model Thinking and Coding Artificial Societies,4,https://www.coursera.org/learn/computer-simulations?specialization=computational-social-science-ucdavis,"UC Davis, one of the nation’s top-ranked research universities, is a global leader in agriculture, veterinary medicine, sustainability, environmental and biological sciences, and technology. With four colleges and six professional schools, UC Davis and its students and alumni are known for their academic excellence, meaningful public service and profound international impact."
525,Research Designs and Data Sources,4,https://www.coursera.org/learn/data-collection-framework?specialization=data-collection,"In this module we will emphasize the importance of having a well-specified research question and analysis plan. We will provide an overview over the various data collection strategies, a variety of available modes for data collection and some thinking on how to choose the right mode. "
526,Measurements and Analysis Plan,4,https://www.coursera.org/learn/data-collection-framework?specialization=data-collection,"In this module you will be introduced to a general framework that allows you to not only understand each step required for a successful data collection and analysis, but also helps you to identify errors associated with different data sources. You will learn some metrics to quantify each potential error, and thus you will have tools at hand to describe the quality of a data source."
527,Quality Framework,4,https://www.coursera.org/learn/data-collection-framework?specialization=data-collection,In this module we introduce a few surveys across a variety of topics. For each we highlight data collection features. The surveys span a variety of topics. We challenge you to think about alternative data sources that can be used to gather the same information or insights.
528,Application of TSE Framework to Existing Surveys,4,https://www.coursera.org/learn/data-collection-framework?specialization=data-collection,"The University of Maryland is the state's flagship university and one of the nation's preeminent public research universities. A global leader in research, entrepreneurship and innovation, the university is home to more than 37,000 students, 9,000 faculty and staff, and 250 academic programs. Its faculty includes three Nobel laureates, three Pulitzer Prize winners, 47 members of the national academies and scores of Fulbright scholars. The institution has a $1.8 billion operating budget, secures $500 million annually in external research funding and recently completed a $1 billion fundraising campaign."
529,"Module 1: Introduction, Classic Modes of Survey Data Collection ",4,https://www.coursera.org/learn/data-collection-methods?specialization=data-collection,"This second lesson focuses on modes in which survey respondents self-administer questions and provide their responses directly to researchers.  By the end of Lesson 2, you will understand the pros and cons of self-administered modes from the TSE perspective."
530,"Module  2: Self-administration, Online Data Collection",4,https://www.coursera.org/learn/data-collection-methods?specialization=data-collection,"In this lesson, we explore the various roles interviewers take on beside asking questions and collecting answers, as well as some of the different approaches to interviewing that have been proposed and how they affect the accuracy of responses.  By the end of Lesson 3, you will appreciate the benefits and costs of collecting data in interviews and will be able to contrast them with the costs and benefits of self-administration. "
531,Module 3: Interviewers and Interviewing,4,https://www.coursera.org/learn/data-collection-methods?specialization=data-collection,"In this lesson, we focus on some new data collection modes such as mobile web surveys and SMS text interviews, as well as alternative data sources such as sensor data, administrative data, and social media.  By the end of this lesson, you will have a sense of the issues to which survey methodologists and survey researchers are devoting much of their attention these days. You will be able to weigh the pros and cons of these new methods and data sources. "
532,"Module 4: Emerging modes, new data sources",4,https://www.coursera.org/learn/data-collection-methods?specialization=data-collection,"The mission of the University of Michigan is to serve the people of Michigan and the world through preeminence in creating, communicating, preserving and applying knowledge, art, and academic values, and in developing leaders and citizens who will challenge the present and enrich the future."
533,Introduction and Unit 1: Overview of Standardized Interviewing,6,https://www.coursera.org/learn/questionnaire-design?specialization=data-collection,Comprehension; Retrieval; Judgment; Response
534,Unit 2: Response Process,6,https://www.coursera.org/learn/questionnaire-design?specialization=data-collection,"Facts and quasi facts; Memory and recall; Asking sensitive questions; Mode, privacy and confidentiality"
535,Unit 3: Asking Factual Questions,6,https://www.coursera.org/learn/questionnaire-design?specialization=data-collection,Context effects in attitude questions; Use of different scales; Offering don’t know options; Response order effects
536,Unit 4: Measuring Attitudes,6,https://www.coursera.org/learn/questionnaire-design?specialization=data-collection,Expert reviews and focus groups; Cognitive interviews; Behavior coding; Quantitative techniques
537,Unit 5: Testing Questionnaires,6,https://www.coursera.org/learn/questionnaire-design?specialization=data-collection,The questionnaire from start to finish; Things to put at the end; Mode Choice: Implementations for layout; Self-administered questionnaires
538,Unit 6: Putting It All Together,6,https://www.coursera.org/learn/questionnaire-design?specialization=data-collection,"The mission of the University of Michigan is to serve the people of Michigan and the world through preeminence in creating, communicating, preserving and applying knowledge, art, and academic values, and in developing leaders and citizens who will challenge the present and enrich the future."
539,Module 1: Sampling as a research tool,6,https://www.coursera.org/learn/sampling-methods?specialization=data-collection,
540,Mere randomization,6,https://www.coursera.org/learn/sampling-methods?specialization=data-collection,
541,Saving money using cluster sampling,6,https://www.coursera.org/learn/sampling-methods?specialization=data-collection,
542,Using auxiliary data to be more efficient,6,https://www.coursera.org/learn/sampling-methods?specialization=data-collection,
543,Simplified sampling,6,https://www.coursera.org/learn/sampling-methods?specialization=data-collection,
544,Pulling it all together,6,https://www.coursera.org/learn/sampling-methods?specialization=data-collection,"The mission of the University of Michigan is to serve the people of Michigan and the world through preeminence in creating, communicating, preserving and applying knowledge, art, and academic values, and in developing leaders and citizens who will challenge the present and enrich the future."
545,Meet Dr. Schweidel & Course Overview,5,https://www.coursera.org/learn/meaningful-marketing-insights?specialization=marketing-analytics,"Modules 2 and 3 focus on identifying appropriate descriptive statistics (measures of central tendency and dispersion) for different types of data, as well as recoding data using reference commands to prepare it for analysis. Additionally, you will manipulate and summarize data using pivot tables in Excel, produce visualizations that are appropriate based on the type of data being analyzed, and interpret statistics and visualizations to draw conclusions to address relevant marketing questions."
546,"Exploring your Data with Visualization and Descriptive Statistics, Part 1",5,https://www.coursera.org/learn/meaningful-marketing-insights?specialization=marketing-analytics,"Modules 2 and 3 focus on identifying appropriate descriptive statistics (measures of central tendency and dispersion) for different types of data, as well as recoding data using reference commands to prepare it for analysis. Additionally, you will manipulate and summarize data using pivot tables in Excel, produce visualizations that are appropriate based on the type of data being analyzed, and interpret statistics and visualizations to draw conclusions to address relevant marketing questions."
547,"Exploring your Data with Visualization and Descriptive Statistics, Part 2",5,https://www.coursera.org/learn/meaningful-marketing-insights?specialization=marketing-analytics,"In this module, you will be asked to determine the appropriate type of regression for different types of marketing data and will perform regression analysis to assess the impact of marketing actions on outcomes of interest, such as sales, traffic, and brand choices. You will also be asked to interpret regression output to understand overall model performance and importance of different predictors, as well as make predictions using the appropriate regression model."
548,Regression Analysis for Marketing Data,5,https://www.coursera.org/learn/meaningful-marketing-insights?specialization=marketing-analytics,"This final module will connect the results of regression analysis to marketing decisions. You will learn to build tools that allow users to evaluate outcomes based on different marketing decisions, as well as characterize the extent of uncertainty in outcomes based on the selected marketing decisions."
549,From Analysis to Action,5,https://www.coursera.org/learn/meaningful-marketing-insights?specialization=marketing-analytics,"Emory University, located in Atlanta, Georgia, is one of the world's leading research universities. Its mission is to create, preserve, teach and apply knowledge in the service of humanity."
550,Randomness and Probability,4,https://www.coursera.org/learn/uncertainty-marketing-decisions?specialization=marketing-analytics,"Building on the basics of randomness and probability discussed in Module 1, we examine the use of Monte Carlo simulations for incorporating randomness into business problems. Using Microsoft Excel, we will build a tool that conducts a Monte Carlo simulation. We will use this tool to evaluate the best course of action for a particular business problem."
551,Conducting Monte Carlo Simulations in Excel,4,https://www.coursera.org/learn/uncertainty-marketing-decisions?specialization=marketing-analytics,"In Module 3, we look at the use of probability distributions as a means of characterizing uncertainty. We initially look at how uncertainty is incorporated into a general decision making framework. We then turn our attention to different probability distributions that can be used to model uncertainty, depending on the nature of the data. We examine the application of these probability distributions to assess the likelihood of events using features within Microsoft Excel."
552,Using Probability Distributions to Model Uncertainty,4,https://www.coursera.org/learn/uncertainty-marketing-decisions?specialization=marketing-analytics,"Building the the discussion of probability distributions in Module 3, we apply this knowledge to a specific application: the design of extended service warranty plans. We provide an overview of the business problem and discuss how to incorporate uncertainty in customers' use of the warranty plan using the Poisson distribution. Using Microsoft Excel, we design a spreadsheet tool that enables a user to adjust features of the service plans. By comparing firm profit under different scenarios, we investigate how different features of the service plan result in risk being shared by the consumer and the firm."
553,Application: Designing Extended Service Warranty Plans,4,https://www.coursera.org/learn/uncertainty-marketing-decisions?specialization=marketing-analytics,"Emory University, located in Atlanta, Georgia, is one of the world's leading research universities. Its mission is to create, preserve, teach and apply knowledge in the service of humanity."
554,Basics of Forecasting Models,4,https://www.coursera.org/learn/forecasting-models-marketing-decisions?specialization=marketing-analytics,"""Meaningful Marketing Insights,"" This content will be familiar for learners who completed the first course; please think of this portion of the class as a review."
555,Customer Analytics: Predicting Individual Customer Behavior,4,https://www.coursera.org/learn/forecasting-models-marketing-decisions?specialization=marketing-analytics,"This module will discuss managing customer equity, acquisition, retention, & market value, and customer valuation.  You will learn how to decompose customer value into its underlying components."
556,Managing Customer Equity: Linking Customer Analytics to Customer Value ,4,https://www.coursera.org/learn/forecasting-models-marketing-decisions?specialization=marketing-analytics,"A common task in developing forecasting models is to use them to make decisions regarding the marketing mix activity. With a marketing mix model, organizations can assess the efficacy of different marketing actions. Included is a sample of data for a popular frozen food category. In addition to weekly sales and pricing, for the focal brand we have information on whether the product was featured in the store’s advertising (e.g., newspaper circular) and if the product was on display in the store. We also have pricing information from competitors. In this module, we will build a series of regression models to evaluate the impact of the brand’s actions and competitors’ actions."
557,Marketing Mix Modeling,4,https://www.coursera.org/learn/forecasting-models-marketing-decisions?specialization=marketing-analytics,"Emory University, located in Atlanta, Georgia, is one of the world's leading research universities. Its mission is to create, preserve, teach and apply knowledge in the service of humanity."
558,Introduction to Factor Analysis,4,https://www.coursera.org/learn/survey-analysis-marketing-insights?specialization=marketing-analytics,This module will provide lectures and exercises that will inform students on how to determine the number of factors to consider in your analysis and to evaluate the fit of the data.
559,Implementing Factor Analysis,4,https://www.coursera.org/learn/survey-analysis-marketing-insights?specialization=marketing-analytics,This module will introduce components of customer segmentation to students.  Students will use this knowledge to be able to analyze data and make more informed business decisions.
560,Customer Segmentation,4,https://www.coursera.org/learn/survey-analysis-marketing-insights?specialization=marketing-analytics,This module will explain and describe perceptual maps.  Students will be able to create perceptual maps and also analyze data from perceptual maps.
561,Perceptual Maps,4,https://www.coursera.org/learn/survey-analysis-marketing-insights?specialization=marketing-analytics,"Emory University, located in Atlanta, Georgia, is one of the world's leading research universities. Its mission is to create, preserve, teach and apply knowledge in the service of humanity."
562,Data Science Context and Concepts,5,https://www.coursera.org/learn/data-manipulation,"Relational Databases are the workhouse of large-scale data management.  Although originally motivated by problems in enterprise operations, they have proven remarkably capable for analytics as well.  But most importantly, the principles underlying relational databases are universal in managing, manipulating, and analyzing data at scale.  Even as the landscape of large-scale data systems has expanded dramatically in the last decade, relational models and languages have remained a unifying concept.  For working with large-scale data, there is no more important programming model to learn."
563,Relational Databases and the Relational Algebra,5,https://www.coursera.org/learn/data-manipulation,"The MapReduce programming model (as distinct from its implementations) was proposed as a simplifying abstraction for parallel manipulation of massive datasets, and remains an important concept to know when using and evaluating modern big data platforms.  "
564,MapReduce and Parallel Dataflow Programming,5,https://www.coursera.org/learn/data-manipulation,"NoSQL systems are purely about scale rather than analytics, and are arguably less relevant for the practicing data scientist.  However, they occupy an important place in many practical big data platform architectures, and data scientists need to understand their limitations and strengths to use them effectively."
565,NoSQL: Systems and Concepts,5,https://www.coursera.org/learn/data-manipulation,"Graph-structured data are increasingly common in data science contexts due to their ubiquity in modeling the communication between entities: people (social networks), computers (Internet communication), cities and countries (transportation networks), or corporations (financial transactions).  Learn the common algorithms for extracting information from graph data and how to scale them up. "
566,Graph Analytics,5,https://www.coursera.org/learn/data-manipulation,"Founded in 1861, the University of Washington is one of the oldest state-supported institutions of higher education on the West Coast and is one of the preeminent research universities in the world."
567,Practical Statistical Inference,4,https://www.coursera.org/learn/predictive-analytics,"Follow a tour through the important methods, algorithms, and techniques in machine learning.  You will learn how these methods build upon each other and can be combined into practical algorithms that perform well on a variety of tasks.  Learn how to evaluate machine learning methods and the pitfalls to avoid."
568,Supervised Learning,4,https://www.coursera.org/learn/predictive-analytics,"You will learn how to optimize a cost function using gradient descent, including popular variants that use randomization and parallelization to improve performance.  You will gain an intuition for popular methods used in practice and see how similar they are fundamentally. "
569,Optimization,4,https://www.coursera.org/learn/predictive-analytics,A brief tour of selected unsupervised learning methods and an opportunity to apply techniques in practice on a real world problem.
570,Unsupervised Learning,4,https://www.coursera.org/learn/predictive-analytics,"Founded in 1861, the University of Washington is one of the oldest state-supported institutions of higher education on the West Coast and is one of the preeminent research universities in the world."
571,Visualization,3,https://www.coursera.org/learn/data-results,"Big Data has become closely linked to issues of privacy and ethics: As the limits on what we *can* do with data continue to evaporate, the question of what we *should* do with data becomes paramount.  Motivated in the context of case studies, you will learn the core principles of codes of conduct for data science and statistical analysis.  You will learn the limits of current theory on protecting privacy while still permitting useful statistical analysis. "
572,Privacy and Ethics,3,https://www.coursera.org/learn/data-results,"Science is facing a credibility crisis due to unreliable reproducibility, and as research becomes increasingly computational, the problem seems to be paradoxically getting worse.  But reproducibility is not just for academics: Data scientists who cannot share, explain, and defend their methods for others to build on are dangerous.  In this module, you will explore the importance of reproducible research and how cloud computing is offering new mechanisms for sharing code, data, environments, and even costs that are critical for practical reproducibility."
573,Reproducibility and Cloud Computing,3,https://www.coursera.org/learn/data-results,"Founded in 1861, the University of Washington is one of the oldest state-supported institutions of higher education on the West Coast and is one of the preeminent research universities in the world."
574,Project A: Blight Fight,6,https://www.coursera.org/learn/datasci-capstone,You are given sets of incidents with location information; you need to use some assumptions to group these incidents by location to identify specific buildings.
575,Week 2: Derive a list of buildings,6,https://www.coursera.org/learn/datasci-capstone,Construct a training set by associating each of your buildings with a ground truth label derived from the permit data.
576,Week 3: Construct a training dataset,6,https://www.coursera.org/learn/datasci-capstone,Use a trivial feature set to train and evaluate a simple model
577,Week 4: Train and evaluate a simple model,6,https://www.coursera.org/learn/datasci-capstone,Derive additional features and retrain to improve the efficacy of your model.
578,Week 5: Feature Engineering,6,https://www.coursera.org/learn/datasci-capstone,Enter your final report for grading.
579,Week 6: Final Report,6,https://www.coursera.org/learn/datasci-capstone,"Founded in 1861, the University of Washington is one of the oldest state-supported institutions of higher education on the West Coast and is one of the preeminent research universities in the world."
580,Data and Machine Learning on GCP 専門講座の概要,6,https://www.coursera.org/learn/gcp-big-data-ml-fundamentals-jp?specialization=gcp-data-machine-learning-jp,このモジュールでは、オンプレミスで実行されている Apache Spark ML の既存のレコメンデーション モデルを使用して、レコメンデーション モデルの概要と、Cloud Dataproc および Cloud SQL を使用してクラウドでこのモデルを実行する方法について学びます。
581,Cloud SQL と Spark を使用した商品のレコメンデーション,6,https://www.coursera.org/learn/gcp-big-data-ml-fundamentals-jp?specialization=gcp-data-machine-learning-jp,このモジュールでは、BigQuery と大規模なビッグデータ分析の基礎について学びます。さらに、BigQuery ML で SQL のみを使用して、訪問者の購入を予測するカスタムの機械学習モデルを構築する方法を学びます。
582,BigQuery ML で訪問者の購入を予測する,6,https://www.coursera.org/learn/gcp-big-data-ml-fundamentals-jp?specialization=gcp-data-machine-learning-jp,このモジュールでは、自動スケーリングに対応したストリーミング データ パイプラインを設計、構築して、データの取り込み、処理、ダッシュボードでの可視化を行います。パイプラインを構築する前に、メッセージ指向アーキテクチャの基礎と、最新のデータ パイプラインを設計、実装する際の注意点について学びます。
583,Cloud Pub/Sub と Cloud Dataflow を使用してストリーミング データ パイプラインを作成する,6,https://www.coursera.org/learn/gcp-big-data-ml-fundamentals-jp?specialization=gcp-data-machine-learning-jp,カスタム ML モデルをゼロから作成したくない場合もあります。ここでは、Vision API や Cloud AutoML のような構築済みの ML モデルを活用、拡張して画像を分類する方法を学びます。
584,Vision API と Cloud AutoML を使用して、構築済みのモデルで画像を分類する,6,https://www.coursera.org/learn/gcp-big-data-ml-fundamentals-jp?specialization=gcp-data-machine-learning-jp,最後のモジュールでは、この基礎コースで説明した主な課題、ソリューション、トピックについて確認します。また、その他のリソースと、Google Cloud Data Engineer の認定資格を取得するためのステップについても確認します。
585,まとめ,6,https://www.coursera.org/learn/gcp-big-data-ml-fundamentals-jp?specialization=gcp-data-machine-learning-jp,"We help millions of organizations empower their employees, serve their customers, and build what’s next for their businesses with innovative technology created in—and for—the cloud. Our products are engineered for security, reliability, and scalability, running the full stack from infrastructure to applications to devices and hardware. Our teams are dedicated to helping customers apply our technologies to create success."
586,Serverless Machine Learning on Google Cloud Platform へようこそ,5,https://www.coursera.org/learn/serverless-machine-learning-gcp-jp?specialization=gcp-data-machine-learning-jp,
587,モジュール 1: 機械学習の使用開始,5,https://www.coursera.org/learn/serverless-machine-learning-gcp-jp?specialization=gcp-data-machine-learning-jp,
588,モジュール 2: Tensorflow による ML モデルの構築,5,https://www.coursera.org/learn/serverless-machine-learning-gcp-jp?specialization=gcp-data-machine-learning-jp,
589,モジュール 3: Cloud ML Engine による ML モデルのスケーリング,5,https://www.coursera.org/learn/serverless-machine-learning-gcp-jp?specialization=gcp-data-machine-learning-jp,
590,モジュール 4: 特徴エンジニアリング,5,https://www.coursera.org/learn/serverless-machine-learning-gcp-jp?specialization=gcp-data-machine-learning-jp,"We help millions of organizations empower their employees, serve their customers, and build what’s next for their businesses with innovative technology created in—and for—the cloud. Our products are engineered for security, reliability, and scalability, running the full stack from infrastructure to applications to devices and hardware. Our teams are dedicated to helping customers apply our technologies to create success."
591,モジュール 1: Cloud Dataproc の概要,4,https://www.coursera.org/learn/leveraging-unstructured-data-dataproc-gcp-jp?specialization=gcp-data-machine-learning-jp,
592,モジュール 2: Dataproc ジョブの実行,4,https://www.coursera.org/learn/leveraging-unstructured-data-dataproc-gcp-jp?specialization=gcp-data-machine-learning-jp,
593,モジュール 3: GCP の活用,4,https://www.coursera.org/learn/leveraging-unstructured-data-dataproc-gcp-jp?specialization=gcp-data-machine-learning-jp,
594,モジュール 4: 非構造化データの分析,4,https://www.coursera.org/learn/leveraging-unstructured-data-dataproc-gcp-jp?specialization=gcp-data-machine-learning-jp,"We help millions of organizations empower their employees, serve their customers, and build what’s next for their businesses with innovative technology created in—and for—the cloud. Our products are engineered for security, reliability, and scalability, running the full stack from infrastructure to applications to devices and hardware. Our teams are dedicated to helping customers apply our technologies to create success."
595,Serverless Data Analysis with Google BigQuery and Cloud Dataflow へようこそ,3,https://www.coursera.org/learn/serverless-data-analysis-bigquery-cloud-dataflow-gcp-jp?specialization=gcp-data-machine-learning-jp,
596,BigQuery によるサーバーレス データ分析,3,https://www.coursera.org/learn/serverless-data-analysis-bigquery-cloud-dataflow-gcp-jp?specialization=gcp-data-machine-learning-jp,
597,Dataflow によるデータ処理パイプラインの自動スケーリング,3,https://www.coursera.org/learn/serverless-data-analysis-bigquery-cloud-dataflow-gcp-jp?specialization=gcp-data-machine-learning-jp,"We help millions of organizations empower their employees, serve their customers, and build what’s next for their businesses with innovative technology created in—and for—the cloud. Our products are engineered for security, reliability, and scalability, running the full stack from infrastructure to applications to devices and hardware. Our teams are dedicated to helping customers apply our technologies to create success."
598,"Introducción al programa de especialización Data Engineering, Big Data, and Machine Learning on GCP",6,https://www.coursera.org/learn/gcp-big-data-ml-fundamentals-es?specialization=gcp-data-machine-learning-es,"En este módulo, tendrá un modelo de recomendación existente de Apache Spark ML que se ejecuta de manera local. Aprenderá acerca de los modelos de recomendación y cómo puede ejecutarlos en la nube con Cloud Dataproc y Cloud SQL."
599,Recomendación de productos con Cloud SQL y Spark,6,https://www.coursera.org/learn/gcp-big-data-ml-fundamentals-es?specialization=gcp-data-machine-learning-es,"En este módulo, aprenderá los conceptos básicos de BigQuery y del análisis de macrodatos a gran escala. Luego, aprenderá a compilar su propio modelo personalizado de aprendizaje automático para predecir las compras de visitantes usando solamente SQL con BigQuery ML."
600,Prediga las compras de visitantes con BigQuery ML,6,https://www.coursera.org/learn/gcp-big-data-ml-fundamentals-es?specialization=gcp-data-machine-learning-es,"En este módulo, diseñará y compilará una canalización de datos de transmisión con ajuste de escala automático para transferir, procesar y visualizar datos en un panel. Antes de compilar su canalización, aprenderá los conceptos básicos de la arquitectura orientada a los mensajes y los errores que debe evitar al diseñar y al implementar canalizaciones de datos modernas."
601,Cree canalizaciones de datos de transmisión con Cloud Pub/Sub y Cloud Dataflow,6,https://www.coursera.org/learn/gcp-big-data-ml-fundamentals-es?specialization=gcp-data-machine-learning-es,"¿No quiere crear un modelo personalizado de AA desde cero? Aprenda a aprovechar y extender los modelos de AA previamente compilados, como la API de Vision y Cloud AutoML, para la clasificación de imágenes."
602,Clasifique imágenes con modelos previamente compilados mediante la API de Vision y Cloud AutoML,6,https://www.coursera.org/learn/gcp-big-data-ml-fundamentals-es?specialization=gcp-data-machine-learning-es,"En este último módulo, revisaremos los desafíos clave, las soluciones y los temas abordados como parte de este curso sobre aspectos básicos. También revisaremos los recursos adicionales y los pasos que puede seguir para obtener la certificación Data Engineer de Google Cloud."
603,Resumen,6,https://www.coursera.org/learn/gcp-big-data-ml-fundamentals-es?specialization=gcp-data-machine-learning-es,"We help millions of organizations empower their employees, serve their customers, and build what’s next for their businesses with innovative technology created in—and for—the cloud. Our products are engineered for security, reliability, and scalability, running the full stack from infrastructure to applications to devices and hardware. Our teams are dedicated to helping customers apply our technologies to create success."
604,Bienvenido a Serverless Machine Learning on Google Cloud Platform,5,https://www.coursera.org/learn/serverless-machine-learning-gcp-es?specialization=gcp-data-machine-learning-es,
605,Módulo 1: Cómo comenzar a usar el aprendizaje automático,5,https://www.coursera.org/learn/serverless-machine-learning-gcp-es?specialization=gcp-data-machine-learning-es,
606,Módulo 2: Cómo crear modelos de AA con TensorFlow,5,https://www.coursera.org/learn/serverless-machine-learning-gcp-es?specialization=gcp-data-machine-learning-es,
607,Módulo 3: Cómo escalar modelos de AA con Cloud ML Engine,5,https://www.coursera.org/learn/serverless-machine-learning-gcp-es?specialization=gcp-data-machine-learning-es,
608,Módulo 4: Ingeniería de atributos,5,https://www.coursera.org/learn/serverless-machine-learning-gcp-es?specialization=gcp-data-machine-learning-es,"We help millions of organizations empower their employees, serve their customers, and build what’s next for their businesses with innovative technology created in—and for—the cloud. Our products are engineered for security, reliability, and scalability, running the full stack from infrastructure to applications to devices and hardware. Our teams are dedicated to helping customers apply our technologies to create success."
609,Módulo 1: Introducción a Cloud Dataproc,4,https://www.coursera.org/learn/leveraging-unstructured-data-dataproc-gcp-es?specialization=gcp-data-machine-learning-es,
610,Módulo 2: Ejecución de trabajos de Dataproc,4,https://www.coursera.org/learn/leveraging-unstructured-data-dataproc-gcp-es?specialization=gcp-data-machine-learning-es,
611,Módulo 3: Aproveche GCP,4,https://www.coursera.org/learn/leveraging-unstructured-data-dataproc-gcp-es?specialization=gcp-data-machine-learning-es,
612,Módulo 4: Análisis de datos no estructurados,4,https://www.coursera.org/learn/leveraging-unstructured-data-dataproc-gcp-es?specialization=gcp-data-machine-learning-es,"We help millions of organizations empower their employees, serve their customers, and build what’s next for their businesses with innovative technology created in—and for—the cloud. Our products are engineered for security, reliability, and scalability, running the full stack from infrastructure to applications to devices and hardware. Our teams are dedicated to helping customers apply our technologies to create success."
613,Le damos la bienvenida a Serverless Data Analysis with Google BigQuery and Cloud Dataflow,3,https://www.coursera.org/learn/serverless-data-analysis-bigquery-cloud-dataflow-gcp-es?specialization=gcp-data-machine-learning-es,
614,Module 1: Análisis de datos sin servidores con BigQuery,3,https://www.coursera.org/learn/serverless-data-analysis-bigquery-cloud-dataflow-gcp-es?specialization=gcp-data-machine-learning-es,
615,Module 2: Ajuste de escala automático de canalizaciones de procesamiento de datos con Dataflow,3,https://www.coursera.org/learn/serverless-data-analysis-bigquery-cloud-dataflow-gcp-es?specialization=gcp-data-machine-learning-es,"We help millions of organizations empower their employees, serve their customers, and build what’s next for their businesses with innovative technology created in—and for—the cloud. Our products are engineered for security, reliability, and scalability, running the full stack from infrastructure to applications to devices and hardware. Our teams are dedicated to helping customers apply our technologies to create success."
616,Information Systems,6,https://www.coursera.org/learn/relational-database,The present module is focused on Conceptual Design. The learner will be able to create an Entity Relationship Diagram through the Conceptual Design from business requirements.
617,Entity Relationship Theory and Conceptual Design,6,https://www.coursera.org/learn/relational-database,The present module is focused on Logical Design. The learner will be able to create an Relational Model from the entity-relationship diagram
618,Relational Database Theory and Logical Design,6,https://www.coursera.org/learn/relational-database,The present module is focused on Physical Design. The learner will be able to create database objects with data definition language from the Structured Query Language.
619,Structured Query Language Data Manipulation Language,6,https://www.coursera.org/learn/relational-database,The present module is focused on Data Manipulation Language on SQL programming to feed and query relational database objects.
620,Structured Query Language and Advanced SQL Programming,6,https://www.coursera.org/learn/relational-database,The present module is focused on query optimization according to type of information systems.
621,Transactions and query optimization,6,https://www.coursera.org/learn/relational-database,"La Universidad Nacional Autónoma de México fue fundada el 21 de septiembre de 1551 con el nombre de la Real y Pontificia Universidad de México. Es la más grande e importante universidad de México e Iberoamérica. Tiene como propósito primordial estar al servicio del país y de la humanidad, formar profesionistas útiles a la sociedad, organizar y realizar investigaciones, principalmente acerca de las condiciones y problemas nacionales, y extender con la mayor amplitud posible, los beneficios de la cultura."
622,Introduction to Business Intelligence as Analytical System,6,https://www.coursera.org/learn/business-intelligence-data-warehousing,"After completing this module, a learner will be able to identify the entire process of datawarehousing, which consist on OLAP design concepts and multidimensional modelling. The learner will be able to design and create a data warehouse from OLAP requirements."
623,Designing a Data Warehouse,6,https://www.coursera.org/learn/business-intelligence-data-warehousing,"After completing this module, a learner will differentiate from structured and unstructured data and will be able to extract, transform and load data into a datawarehouse. The student will also be able to program and execute OLAP queries with SQL."
624,The ETL process and Analytical queries with SQL,6,https://www.coursera.org/learn/business-intelligence-data-warehousing,"After completing this module, a learner will identify the main data mining tasks and some algorithms for classification, regression and clustering  for predictive and descriptive analysis on business intelligence. "
625, Predictive Analytics with Data mining,6,https://www.coursera.org/learn/business-intelligence-data-warehousing,"After completing this module, a learner will learn the types of data according to structure and how to integrate, store and analyze unstructured data."
626,The problem of integration and analysis of unstructured data ,6,https://www.coursera.org/learn/business-intelligence-data-warehousing,"After completing this module, a learner will understand the problem of big data, a possible solution to the analysis of big data with the Hadoop ecosystem and under which conditions should be apply each element of this ecosystem."
627,Big Data and Hadoop Framework,6,https://www.coursera.org/learn/business-intelligence-data-warehousing,"La Universidad Nacional Autónoma de México fue fundada el 21 de septiembre de 1551 con el nombre de la Real y Pontificia Universidad de México. Es la más grande e importante universidad de México e Iberoamérica. Tiene como propósito primordial estar al servicio del país y de la humanidad, formar profesionistas útiles a la sociedad, organizar y realizar investigaciones, principalmente acerca de las condiciones y problemas nacionales, y extender con la mayor amplitud posible, los beneficios de la cultura."
628,NOSQL Systems,6,https://www.coursera.org/learn/nosql-databases,"Welcome to the module key-value database. We will learn the components and types of a key-value database, its properties, scalability and indexing. Let's start!"
629,Key-value database ,6,https://www.coursera.org/learn/nosql-databases,Welcome to the session columnar databases from the NoSQL course.The learner will understand why a columnar database performs better than a relational in the case of analytical queries.
630,Columnar Databases,6,https://www.coursera.org/learn/nosql-databases,Welcome to the session document databases with MongoDB.The learner will identify the advantages of storing semistructured data with MongoDB.
631,Document databases with MongoDB ,6,https://www.coursera.org/learn/nosql-databases,Welcome to the session graph databases from the NoSQL course.The learner will understand that a graph database is a perfect solution for information systems where the relationships between entities are more like graphs or trees which are structures more flexibles.
632,Graph Databases,6,https://www.coursera.org/learn/nosql-databases,"Welcome to the session How to design reliable, scalable and maintainable applications. The student will identify which database or repository is the best option according to response time, amount of data, type of data and analysis. The student will learn the last database technologies such as in-memory database, multi-model database, etc. and how these approaches can help to design reliable, scalable and maintainable applications."
633,"How to design reliable, scalable and maintainable applications",6,https://www.coursera.org/learn/nosql-databases,"La Universidad Nacional Autónoma de México fue fundada el 21 de septiembre de 1551 con el nombre de la Real y Pontificia Universidad de México. Es la más grande e importante universidad de México e Iberoamérica. Tiene como propósito primordial estar al servicio del país y de la humanidad, formar profesionistas útiles a la sociedad, organizar y realizar investigaciones, principalmente acerca de las condiciones y problemas nacionales, y extender con la mayor amplitud posible, los beneficios de la cultura."
634,Designing a transaccional system,4,https://www.coursera.org/learn/data-intensive-applications,"After completing this module, a learner will learn how to distinguish a transactional from an analytical information system according to the queries required on a huge amount of historical structured data that requires fast processing."
635,Designing an analytical system,4,https://www.coursera.org/learn/data-intensive-applications,"After completing this module, a learner will learn how to distinguish which database technology to use to suit the user requirements, detect frauds and support ACID properties."
636,Designing an alternative to relational databases,4,https://www.coursera.org/learn/data-intensive-applications,"After completing this module, a learner will identify the architecture and technologies required to analyse a huge volume of structured and semistructured data."
637,Designing an analytical system within a data lake,4,https://www.coursera.org/learn/data-intensive-applications,"La Universidad Nacional Autónoma de México fue fundada el 21 de septiembre de 1551 con el nombre de la Real y Pontificia Universidad de México. Es la más grande e importante universidad de México e Iberoamérica. Tiene como propósito primordial estar al servicio del país y de la humanidad, formar profesionistas útiles a la sociedad, organizar y realizar investigaciones, principalmente acerca de las condiciones y problemas nacionales, y extender con la mayor amplitud posible, los beneficios de la cultura."
638,"Introdução à especialização Data Engineering, Big Data, and Machine Learning no Google Cloud Platform",6,https://www.coursera.org/learn/gcp-big-data-ml-fundamentals-br?specialization=gcp-data-machine-learning-br,"Neste módulo, você terá um modelo de recomendação Apache SparkML atual em execução no local. Você conhecerá os modelos de recomendação e aprenderá a executá-los na nuvem com o Cloud Dataproc e o Cloud SQL."
639,Recomendação de produtos com o Cloud SQL e o Spark,6,https://www.coursera.org/learn/gcp-big-data-ml-fundamentals-br?specialization=gcp-data-machine-learning-br,"Neste módulo, você conhecerá os aspectos básicos do BigQuery e da análise de Big Data em escala. Você aprenderá como criar seu próprio modelo de machine learning personalizado para predizer as compras dos visitantes usando apenas o SQL com BigQuery ML."
640,Faça a predição das compras de visitantes com o BigQuery ML,6,https://www.coursera.org/learn/gcp-big-data-ml-fundamentals-br?specialization=gcp-data-machine-learning-br,"Neste módulo, você projetará e criará um pipeline de dados de streaming com escalonamento automático para ingerir, processar e visualizar dados em um painel. Antes de gerar o pipeline, você conhecerá os conceitos básicos da arquitetura orientada a mensagens e as armadilhas a serem evitadas ao criar e implementar pipelines de dados modernos."
641,Crie pipelines de dados de streaming com o Cloud Pub/Sub e Cloud Dataflow,6,https://www.coursera.org/learn/gcp-big-data-ml-fundamentals-br?specialization=gcp-data-machine-learning-br,"Não quer criar um modelo de ML personalizado do zero? Saiba como aproveitar e ampliar modelos de ML pré-criados, como a API Vision e o Cloud AutoML, para a classificação de imagens."
642,Classifique imagens com modelos pré-criados usando a API Vision e o Cloud AutoML,6,https://www.coursera.org/learn/gcp-big-data-ml-fundamentals-br?specialization=gcp-data-machine-learning-br,"Neste módulo final, analisaremos os principais desafios, soluções e tópicos abordados como parte deste curso básico. Também analisaremos os recursos adicionais e as etapas que você pode executar para ter a certificação como engenheiro de dados do Google Cloud."
643,Resumo,6,https://www.coursera.org/learn/gcp-big-data-ml-fundamentals-br?specialization=gcp-data-machine-learning-br,"We help millions of organizations empower their employees, serve their customers, and build what’s next for their businesses with innovative technology created in—and for—the cloud. Our products are engineered for security, reliability, and scalability, running the full stack from infrastructure to applications to devices and hardware. Our teams are dedicated to helping customers apply our technologies to create success."
644,"Este é o ""Serverless Machine Learning on Google Cloud Platform""",5,https://www.coursera.org/learn/serverless-machine-learning-gcp-br?specialization=gcp-data-machine-learning-br,
645,Módulo 1: Primeiros passos com machine learning,5,https://www.coursera.org/learn/serverless-machine-learning-gcp-br?specialization=gcp-data-machine-learning-br,
646,Módulo 2: Criação de modelos de ML com o TensorFlow,5,https://www.coursera.org/learn/serverless-machine-learning-gcp-br?specialization=gcp-data-machine-learning-br,
647,Módulo 3: Escalonamento de modelos de ML com o Cloud ML Engine,5,https://www.coursera.org/learn/serverless-machine-learning-gcp-br?specialization=gcp-data-machine-learning-br,
648,Módulo 4: Engenharia de atributos,5,https://www.coursera.org/learn/serverless-machine-learning-gcp-br?specialization=gcp-data-machine-learning-br,"We help millions of organizations empower their employees, serve their customers, and build what’s next for their businesses with innovative technology created in—and for—the cloud. Our products are engineered for security, reliability, and scalability, running the full stack from infrastructure to applications to devices and hardware. Our teams are dedicated to helping customers apply our technologies to create success."
649,Módulo 1: introdução ao Cloud Dataproc,4,https://www.coursera.org/learn/leveraging-unstructured-data-dataproc-gcp-br?specialization=gcp-data-machine-learning-br,
650,Módulo 2: como executar jobs do Dataproc,4,https://www.coursera.org/learn/leveraging-unstructured-data-dataproc-gcp-br?specialization=gcp-data-machine-learning-br,
651,Módulo 3: como usar o GCP,4,https://www.coursera.org/learn/leveraging-unstructured-data-dataproc-gcp-br?specialization=gcp-data-machine-learning-br,
652,Módulo 4: como analisar dados não estruturados,4,https://www.coursera.org/learn/leveraging-unstructured-data-dataproc-gcp-br?specialization=gcp-data-machine-learning-br,"We help millions of organizations empower their employees, serve their customers, and build what’s next for their businesses with innovative technology created in—and for—the cloud. Our products are engineered for security, reliability, and scalability, running the full stack from infrastructure to applications to devices and hardware. Our teams are dedicated to helping customers apply our technologies to create success."
653,Introdução ao curso Serverless Data Analysis with Google BigQuery and Cloud Dataflow,3,https://www.coursera.org/learn/serverless-data-analysis-bigquery-cloud-dataflow-gcp-br?specialization=gcp-data-machine-learning-br,
654,Module 1: Análise de dados sem servidor com o BigQuery,3,https://www.coursera.org/learn/serverless-data-analysis-bigquery-cloud-dataflow-gcp-br?specialization=gcp-data-machine-learning-br,
655,Module 2: Escalonamento automático de canais de processamento de dados com o Dataflow,3,https://www.coursera.org/learn/serverless-data-analysis-bigquery-cloud-dataflow-gcp-br?specialization=gcp-data-machine-learning-br,"We help millions of organizations empower their employees, serve their customers, and build what’s next for their businesses with innovative technology created in—and for—the cloud. Our products are engineered for security, reliability, and scalability, running the full stack from infrastructure to applications to devices and hardware. Our teams are dedicated to helping customers apply our technologies to create success."
